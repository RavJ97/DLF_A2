{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Model Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1 - Loss: 1.4980, Training Accuracy: 47.60%\n",
      "Epoch 2 - Loss: 1.2719, Training Accuracy: 55.33%\n",
      "Epoch 3 - Loss: 1.1959, Training Accuracy: 58.41%\n",
      "Epoch 4 - Loss: 1.1317, Training Accuracy: 60.86%\n",
      "Epoch 5 - Loss: 1.0833, Training Accuracy: 62.25%\n",
      "Epoch 6 - Loss: 1.0502, Training Accuracy: 63.69%\n",
      "Epoch 7 - Loss: 1.0225, Training Accuracy: 64.57%\n",
      "Epoch 8 - Loss: 1.0041, Training Accuracy: 65.24%\n",
      "Epoch 9 - Loss: 0.9887, Training Accuracy: 65.75%\n",
      "Epoch 10 - Loss: 0.9749, Training Accuracy: 66.12%\n",
      "Epoch 11 - Loss: 0.9668, Training Accuracy: 66.55%\n",
      "Epoch 12 - Loss: 0.9589, Training Accuracy: 66.92%\n",
      "Epoch 13 - Loss: 0.9499, Training Accuracy: 67.16%\n",
      "Epoch 14 - Loss: 0.9401, Training Accuracy: 67.47%\n",
      "Epoch 15 - Loss: 0.9352, Training Accuracy: 67.79%\n",
      "Epoch 16 - Loss: 0.9315, Training Accuracy: 67.85%\n",
      "Epoch 17 - Loss: 0.9242, Training Accuracy: 68.13%\n",
      "Epoch 18 - Loss: 0.9194, Training Accuracy: 68.18%\n",
      "Epoch 19 - Loss: 0.9148, Training Accuracy: 68.38%\n",
      "Epoch 20 - Loss: 0.9117, Training Accuracy: 68.41%\n",
      "Epoch 21 - Loss: 0.9060, Training Accuracy: 68.79%\n",
      "Epoch 22 - Loss: 0.9049, Training Accuracy: 68.78%\n",
      "Epoch 23 - Loss: 0.9012, Training Accuracy: 68.64%\n",
      "Epoch 24 - Loss: 0.8961, Training Accuracy: 69.07%\n",
      "Epoch 25 - Loss: 0.8940, Training Accuracy: 68.95%\n",
      "Epoch 26 - Loss: 0.8914, Training Accuracy: 68.91%\n",
      "Epoch 27 - Loss: 0.8882, Training Accuracy: 69.38%\n",
      "Epoch 28 - Loss: 0.8867, Training Accuracy: 69.13%\n",
      "Epoch 29 - Loss: 0.8848, Training Accuracy: 69.34%\n",
      "Epoch 30 - Loss: 0.8812, Training Accuracy: 69.54%\n",
      "Epoch 31 - Loss: 0.8791, Training Accuracy: 69.53%\n",
      "Epoch 32 - Loss: 0.8774, Training Accuracy: 69.65%\n",
      "Epoch 33 - Loss: 0.8758, Training Accuracy: 69.58%\n",
      "Epoch 34 - Loss: 0.8748, Training Accuracy: 69.51%\n",
      "Epoch 35 - Loss: 0.8736, Training Accuracy: 69.49%\n",
      "Epoch 36 - Loss: 0.8721, Training Accuracy: 69.73%\n",
      "Epoch 37 - Loss: 0.8675, Training Accuracy: 69.77%\n",
      "Epoch 38 - Loss: 0.8666, Training Accuracy: 69.82%\n",
      "Epoch 39 - Loss: 0.8667, Training Accuracy: 69.77%\n",
      "Epoch 40 - Loss: 0.8607, Training Accuracy: 70.01%\n",
      "Epoch 41 - Loss: 0.8626, Training Accuracy: 69.99%\n",
      "Epoch 42 - Loss: 0.8609, Training Accuracy: 70.02%\n",
      "Epoch 43 - Loss: 0.8597, Training Accuracy: 69.90%\n",
      "Epoch 44 - Loss: 0.8580, Training Accuracy: 70.13%\n",
      "Epoch 45 - Loss: 0.8564, Training Accuracy: 70.24%\n",
      "Epoch 46 - Loss: 0.8546, Training Accuracy: 70.11%\n",
      "Epoch 47 - Loss: 0.8539, Training Accuracy: 70.27%\n",
      "Epoch 48 - Loss: 0.8533, Training Accuracy: 70.44%\n",
      "Epoch 49 - Loss: 0.8522, Training Accuracy: 70.35%\n",
      "Epoch 50 - Loss: 0.8513, Training Accuracy: 70.35%\n",
      "Model Training Finished\n",
      "Test Accuracy : 60.73%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 10, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.classifier = nn.Sequential(nn.Linear(10 * 15 * 15, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "model = SimpleCNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, trainloader, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1} - Loss: {running_loss / (i + 1):.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    print(\"Model Training Finished\")\n",
    "\n",
    "train_model(model, trainloader, optimizer, criterion, num_epochs=50)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy : {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moderate Model Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1 - 100] training loss : 1.872\n",
      "[1 - 200] training loss : 1.568\n",
      "[1 - 300] training loss : 1.470\n",
      "[1 - 400] training loss : 1.395\n",
      "[1 - 500] training loss : 1.376\n",
      "[1 - 600] training loss : 1.303\n",
      "[1 - 700] training loss : 1.258\n",
      "[1 - 800] training loss : 1.259\n",
      "[1 - 900] training loss : 1.187\n",
      "[1 - 1000] training loss : 1.192\n",
      "[1 - 1100] training loss : 1.155\n",
      "[1 - 1200] training loss : 1.151\n",
      "[1 - 1300] training loss : 1.121\n",
      "[1 - 1400] training loss : 1.128\n",
      "[1 - 1500] training loss : 1.119\n",
      "Epoch 1 - Training Loss : 69.990, Training Accuracy : 53.50%\n",
      "[2 - 100] training loss : 1.058\n",
      "[2 - 200] training loss : 1.035\n",
      "[2 - 300] training loss : 1.097\n",
      "[2 - 400] training loss : 1.040\n",
      "[2 - 500] training loss : 1.045\n",
      "[2 - 600] training loss : 1.032\n",
      "[2 - 700] training loss : 1.018\n",
      "[2 - 800] training loss : 1.015\n",
      "[2 - 900] training loss : 0.994\n",
      "[2 - 1000] training loss : 0.975\n",
      "[2 - 1100] training loss : 0.983\n",
      "[2 - 1200] training loss : 0.978\n",
      "[2 - 1300] training loss : 0.969\n",
      "[2 - 1400] training loss : 0.977\n",
      "[2 - 1500] training loss : 0.958\n",
      "Epoch 2 - Training Loss : 62.450, Training Accuracy : 63.94%\n",
      "[3 - 100] training loss : 0.942\n",
      "[3 - 200] training loss : 0.972\n",
      "[3 - 300] training loss : 0.885\n",
      "[3 - 400] training loss : 0.916\n",
      "[3 - 500] training loss : 0.909\n",
      "[3 - 600] training loss : 0.889\n",
      "[3 - 700] training loss : 0.899\n",
      "[3 - 800] training loss : 0.904\n",
      "[3 - 900] training loss : 0.913\n",
      "[3 - 1000] training loss : 0.862\n",
      "[3 - 1100] training loss : 0.862\n",
      "[3 - 1200] training loss : 0.890\n",
      "[3 - 1300] training loss : 0.862\n",
      "[3 - 1400] training loss : 0.909\n",
      "[3 - 1500] training loss : 0.848\n",
      "Epoch 3 - Training Loss : 56.139, Training Accuracy : 68.70%\n",
      "[4 - 100] training loss : 0.801\n",
      "[4 - 200] training loss : 0.847\n",
      "[4 - 300] training loss : 0.806\n",
      "[4 - 400] training loss : 0.837\n",
      "[4 - 500] training loss : 0.803\n",
      "[4 - 600] training loss : 0.825\n",
      "[4 - 700] training loss : 0.786\n",
      "[4 - 800] training loss : 0.831\n",
      "[4 - 900] training loss : 0.825\n",
      "[4 - 1000] training loss : 0.825\n",
      "[4 - 1100] training loss : 0.814\n",
      "[4 - 1200] training loss : 0.825\n",
      "[4 - 1300] training loss : 0.821\n",
      "[4 - 1400] training loss : 0.817\n",
      "[4 - 1500] training loss : 0.826\n",
      "Epoch 4 - Training Loss : 51.080, Training Accuracy : 71.30%\n",
      "[5 - 100] training loss : 0.787\n",
      "[5 - 200] training loss : 0.771\n",
      "[5 - 300] training loss : 0.758\n",
      "[5 - 400] training loss : 0.750\n",
      "[5 - 500] training loss : 0.788\n",
      "[5 - 600] training loss : 0.773\n",
      "[5 - 700] training loss : 0.756\n",
      "[5 - 800] training loss : 0.730\n",
      "[5 - 900] training loss : 0.792\n",
      "[5 - 1000] training loss : 0.757\n",
      "[5 - 1100] training loss : 0.794\n",
      "[5 - 1200] training loss : 0.754\n",
      "[5 - 1300] training loss : 0.776\n",
      "[5 - 1400] training loss : 0.735\n",
      "[5 - 1500] training loss : 0.732\n",
      "Epoch 5 - Training Loss : 47.685, Training Accuracy : 73.27%\n",
      "[6 - 100] training loss : 0.728\n",
      "[6 - 200] training loss : 0.740\n",
      "[6 - 300] training loss : 0.671\n",
      "[6 - 400] training loss : 0.725\n",
      "[6 - 500] training loss : 0.721\n",
      "[6 - 600] training loss : 0.699\n",
      "[6 - 700] training loss : 0.697\n",
      "[6 - 800] training loss : 0.700\n",
      "[6 - 900] training loss : 0.726\n",
      "[6 - 1000] training loss : 0.727\n",
      "[6 - 1100] training loss : 0.721\n",
      "[6 - 1200] training loss : 0.746\n",
      "[6 - 1300] training loss : 0.719\n",
      "[6 - 1400] training loss : 0.748\n",
      "[6 - 1500] training loss : 0.714\n",
      "Epoch 6 - Training Loss : 45.982, Training Accuracy : 74.72%\n",
      "[7 - 100] training loss : 0.701\n",
      "[7 - 200] training loss : 0.674\n",
      "[7 - 300] training loss : 0.677\n",
      "[7 - 400] training loss : 0.646\n",
      "[7 - 500] training loss : 0.688\n",
      "[7 - 600] training loss : 0.728\n",
      "[7 - 700] training loss : 0.668\n",
      "[7 - 800] training loss : 0.668\n",
      "[7 - 900] training loss : 0.683\n",
      "[7 - 1000] training loss : 0.676\n",
      "[7 - 1100] training loss : 0.713\n",
      "[7 - 1200] training loss : 0.658\n",
      "[7 - 1300] training loss : 0.651\n",
      "[7 - 1400] training loss : 0.639\n",
      "[7 - 1500] training loss : 0.685\n",
      "Epoch 7 - Training Loss : 43.200, Training Accuracy : 76.42%\n",
      "[8 - 100] training loss : 0.664\n",
      "[8 - 200] training loss : 0.658\n",
      "[8 - 300] training loss : 0.657\n",
      "[8 - 400] training loss : 0.661\n",
      "[8 - 500] training loss : 0.657\n",
      "[8 - 600] training loss : 0.617\n",
      "[8 - 700] training loss : 0.666\n",
      "[8 - 800] training loss : 0.670\n",
      "[8 - 900] training loss : 0.640\n",
      "[8 - 1000] training loss : 0.669\n",
      "[8 - 1100] training loss : 0.630\n",
      "[8 - 1200] training loss : 0.639\n",
      "[8 - 1300] training loss : 0.655\n",
      "[8 - 1400] training loss : 0.617\n",
      "[8 - 1500] training loss : 0.638\n",
      "Epoch 8 - Training Loss : 40.271, Training Accuracy : 77.43%\n",
      "[9 - 100] training loss : 0.634\n",
      "[9 - 200] training loss : 0.627\n",
      "[9 - 300] training loss : 0.651\n",
      "[9 - 400] training loss : 0.626\n",
      "[9 - 500] training loss : 0.612\n",
      "[9 - 600] training loss : 0.599\n",
      "[9 - 700] training loss : 0.592\n",
      "[9 - 800] training loss : 0.613\n",
      "[9 - 900] training loss : 0.583\n",
      "[9 - 1000] training loss : 0.612\n",
      "[9 - 1100] training loss : 0.607\n",
      "[9 - 1200] training loss : 0.615\n",
      "[9 - 1300] training loss : 0.623\n",
      "[9 - 1400] training loss : 0.639\n",
      "[9 - 1500] training loss : 0.585\n",
      "Epoch 9 - Training Loss : 38.979, Training Accuracy : 78.62%\n",
      "[10 - 100] training loss : 0.603\n",
      "[10 - 200] training loss : 0.608\n",
      "[10 - 300] training loss : 0.579\n",
      "[10 - 400] training loss : 0.639\n",
      "[10 - 500] training loss : 0.561\n",
      "[10 - 600] training loss : 0.557\n",
      "[10 - 700] training loss : 0.620\n",
      "[10 - 800] training loss : 0.571\n",
      "[10 - 900] training loss : 0.567\n",
      "[10 - 1000] training loss : 0.597\n",
      "[10 - 1100] training loss : 0.640\n",
      "[10 - 1200] training loss : 0.625\n",
      "[10 - 1300] training loss : 0.594\n",
      "[10 - 1400] training loss : 0.555\n",
      "[10 - 1500] training loss : 0.597\n",
      "Epoch 10 - Training Loss : 38.910, Training Accuracy : 79.24%\n",
      "[11 - 100] training loss : 0.572\n",
      "[11 - 200] training loss : 0.524\n",
      "[11 - 300] training loss : 0.545\n",
      "[11 - 400] training loss : 0.574\n",
      "[11 - 500] training loss : 0.530\n",
      "[11 - 600] training loss : 0.538\n",
      "[11 - 700] training loss : 0.534\n",
      "[11 - 800] training loss : 0.592\n",
      "[11 - 900] training loss : 0.600\n",
      "[11 - 1000] training loss : 0.567\n",
      "[11 - 1100] training loss : 0.590\n",
      "[11 - 1200] training loss : 0.573\n",
      "[11 - 1300] training loss : 0.567\n",
      "[11 - 1400] training loss : 0.571\n",
      "[11 - 1500] training loss : 0.566\n",
      "Epoch 11 - Training Loss : 34.534, Training Accuracy : 80.33%\n",
      "[12 - 100] training loss : 0.553\n",
      "[12 - 200] training loss : 0.544\n",
      "[12 - 300] training loss : 0.564\n",
      "[12 - 400] training loss : 0.514\n",
      "[12 - 500] training loss : 0.586\n",
      "[12 - 600] training loss : 0.530\n",
      "[12 - 700] training loss : 0.518\n",
      "[12 - 800] training loss : 0.554\n",
      "[12 - 900] training loss : 0.552\n",
      "[12 - 1000] training loss : 0.564\n",
      "[12 - 1100] training loss : 0.538\n",
      "[12 - 1200] training loss : 0.537\n",
      "[12 - 1300] training loss : 0.552\n",
      "[12 - 1400] training loss : 0.537\n",
      "[12 - 1500] training loss : 0.583\n",
      "Epoch 12 - Training Loss : 36.406, Training Accuracy : 80.87%\n",
      "[13 - 100] training loss : 0.504\n",
      "[13 - 200] training loss : 0.511\n",
      "[13 - 300] training loss : 0.522\n",
      "[13 - 400] training loss : 0.565\n",
      "[13 - 500] training loss : 0.523\n",
      "[13 - 600] training loss : 0.511\n",
      "[13 - 700] training loss : 0.528\n",
      "[13 - 800] training loss : 0.520\n",
      "[13 - 900] training loss : 0.541\n",
      "[13 - 1000] training loss : 0.530\n",
      "[13 - 1100] training loss : 0.515\n",
      "[13 - 1200] training loss : 0.525\n",
      "[13 - 1300] training loss : 0.546\n",
      "[13 - 1400] training loss : 0.515\n",
      "[13 - 1500] training loss : 0.551\n",
      "Epoch 13 - Training Loss : 32.766, Training Accuracy : 81.70%\n",
      "[14 - 100] training loss : 0.466\n",
      "[14 - 200] training loss : 0.510\n",
      "[14 - 300] training loss : 0.520\n",
      "[14 - 400] training loss : 0.502\n",
      "[14 - 500] training loss : 0.510\n",
      "[14 - 600] training loss : 0.533\n",
      "[14 - 700] training loss : 0.507\n",
      "[14 - 800] training loss : 0.512\n",
      "[14 - 900] training loss : 0.497\n",
      "[14 - 1000] training loss : 0.527\n",
      "[14 - 1100] training loss : 0.533\n",
      "[14 - 1200] training loss : 0.516\n",
      "[14 - 1300] training loss : 0.506\n",
      "[14 - 1400] training loss : 0.530\n",
      "[14 - 1500] training loss : 0.537\n",
      "Epoch 14 - Training Loss : 31.330, Training Accuracy : 82.24%\n",
      "[15 - 100] training loss : 0.507\n",
      "[15 - 200] training loss : 0.487\n",
      "[15 - 300] training loss : 0.479\n",
      "[15 - 400] training loss : 0.495\n",
      "[15 - 500] training loss : 0.500\n",
      "[15 - 600] training loss : 0.523\n",
      "[15 - 700] training loss : 0.480\n",
      "[15 - 800] training loss : 0.497\n",
      "[15 - 900] training loss : 0.483\n",
      "[15 - 1000] training loss : 0.503\n",
      "[15 - 1100] training loss : 0.472\n",
      "[15 - 1200] training loss : 0.516\n",
      "[15 - 1300] training loss : 0.504\n",
      "[15 - 1400] training loss : 0.501\n",
      "[15 - 1500] training loss : 0.496\n",
      "Epoch 15 - Training Loss : 29.934, Training Accuracy : 82.86%\n",
      "[16 - 100] training loss : 0.467\n",
      "[16 - 200] training loss : 0.464\n",
      "[16 - 300] training loss : 0.484\n",
      "[16 - 400] training loss : 0.497\n",
      "[16 - 500] training loss : 0.495\n",
      "[16 - 600] training loss : 0.495\n",
      "[16 - 700] training loss : 0.480\n",
      "[16 - 800] training loss : 0.462\n",
      "[16 - 900] training loss : 0.468\n",
      "[16 - 1000] training loss : 0.487\n",
      "[16 - 1100] training loss : 0.536\n",
      "[16 - 1200] training loss : 0.521\n",
      "[16 - 1300] training loss : 0.467\n",
      "[16 - 1400] training loss : 0.469\n",
      "[16 - 1500] training loss : 0.468\n",
      "Epoch 16 - Training Loss : 30.374, Training Accuracy : 83.38%\n",
      "[17 - 100] training loss : 0.464\n",
      "[17 - 200] training loss : 0.467\n",
      "[17 - 300] training loss : 0.432\n",
      "[17 - 400] training loss : 0.457\n",
      "[17 - 500] training loss : 0.501\n",
      "[17 - 600] training loss : 0.453\n",
      "[17 - 700] training loss : 0.466\n",
      "[17 - 800] training loss : 0.460\n",
      "[17 - 900] training loss : 0.459\n",
      "[17 - 1000] training loss : 0.511\n",
      "[17 - 1100] training loss : 0.462\n",
      "[17 - 1200] training loss : 0.451\n",
      "[17 - 1300] training loss : 0.475\n",
      "[17 - 1400] training loss : 0.476\n",
      "[17 - 1500] training loss : 0.464\n",
      "Epoch 17 - Training Loss : 29.823, Training Accuracy : 83.64%\n",
      "[18 - 100] training loss : 0.433\n",
      "[18 - 200] training loss : 0.444\n",
      "[18 - 300] training loss : 0.428\n",
      "[18 - 400] training loss : 0.468\n",
      "[18 - 500] training loss : 0.441\n",
      "[18 - 600] training loss : 0.463\n",
      "[18 - 700] training loss : 0.460\n",
      "[18 - 800] training loss : 0.496\n",
      "[18 - 900] training loss : 0.437\n",
      "[18 - 1000] training loss : 0.483\n",
      "[18 - 1100] training loss : 0.438\n",
      "[18 - 1200] training loss : 0.468\n",
      "[18 - 1300] training loss : 0.462\n",
      "[18 - 1400] training loss : 0.454\n",
      "[18 - 1500] training loss : 0.462\n",
      "Epoch 18 - Training Loss : 29.777, Training Accuracy : 84.07%\n",
      "[19 - 100] training loss : 0.418\n",
      "[19 - 200] training loss : 0.421\n",
      "[19 - 300] training loss : 0.417\n",
      "[19 - 400] training loss : 0.406\n",
      "[19 - 500] training loss : 0.460\n",
      "[19 - 600] training loss : 0.429\n",
      "[19 - 700] training loss : 0.449\n",
      "[19 - 800] training loss : 0.447\n",
      "[19 - 900] training loss : 0.438\n",
      "[19 - 1000] training loss : 0.435\n",
      "[19 - 1100] training loss : 0.424\n",
      "[19 - 1200] training loss : 0.449\n",
      "[19 - 1300] training loss : 0.444\n",
      "[19 - 1400] training loss : 0.469\n",
      "[19 - 1500] training loss : 0.456\n",
      "Epoch 19 - Training Loss : 30.335, Training Accuracy : 84.77%\n",
      "[20 - 100] training loss : 0.435\n",
      "[20 - 200] training loss : 0.407\n",
      "[20 - 300] training loss : 0.412\n",
      "[20 - 400] training loss : 0.434\n",
      "[20 - 500] training loss : 0.426\n",
      "[20 - 600] training loss : 0.415\n",
      "[20 - 700] training loss : 0.449\n",
      "[20 - 800] training loss : 0.412\n",
      "[20 - 900] training loss : 0.423\n",
      "[20 - 1000] training loss : 0.447\n",
      "[20 - 1100] training loss : 0.408\n",
      "[20 - 1200] training loss : 0.429\n",
      "[20 - 1300] training loss : 0.440\n",
      "[20 - 1400] training loss : 0.420\n",
      "[20 - 1500] training loss : 0.431\n",
      "Epoch 20 - Training Loss : 29.055, Training Accuracy : 85.03%\n",
      "[21 - 100] training loss : 0.420\n",
      "[21 - 200] training loss : 0.428\n",
      "[21 - 300] training loss : 0.413\n",
      "[21 - 400] training loss : 0.403\n",
      "[21 - 500] training loss : 0.411\n",
      "[21 - 600] training loss : 0.404\n",
      "[21 - 700] training loss : 0.403\n",
      "[21 - 800] training loss : 0.413\n",
      "[21 - 900] training loss : 0.416\n",
      "[21 - 1000] training loss : 0.440\n",
      "[21 - 1100] training loss : 0.426\n",
      "[21 - 1200] training loss : 0.406\n",
      "[21 - 1300] training loss : 0.414\n",
      "[21 - 1400] training loss : 0.425\n",
      "[21 - 1500] training loss : 0.446\n",
      "Epoch 21 - Training Loss : 28.551, Training Accuracy : 85.55%\n",
      "[22 - 100] training loss : 0.378\n",
      "[22 - 200] training loss : 0.395\n",
      "[22 - 300] training loss : 0.433\n",
      "[22 - 400] training loss : 0.413\n",
      "[22 - 500] training loss : 0.414\n",
      "[22 - 600] training loss : 0.412\n",
      "[22 - 700] training loss : 0.419\n",
      "[22 - 800] training loss : 0.426\n",
      "[22 - 900] training loss : 0.402\n",
      "[22 - 1000] training loss : 0.385\n",
      "[22 - 1100] training loss : 0.427\n",
      "[22 - 1200] training loss : 0.422\n",
      "[22 - 1300] training loss : 0.423\n",
      "[22 - 1400] training loss : 0.429\n",
      "[22 - 1500] training loss : 0.418\n",
      "Epoch 22 - Training Loss : 26.242, Training Accuracy : 85.57%\n",
      "[23 - 100] training loss : 0.435\n",
      "[23 - 200] training loss : 0.388\n",
      "[23 - 300] training loss : 0.419\n",
      "[23 - 400] training loss : 0.402\n",
      "[23 - 500] training loss : 0.389\n",
      "[23 - 600] training loss : 0.396\n",
      "[23 - 700] training loss : 0.393\n",
      "[23 - 800] training loss : 0.395\n",
      "[23 - 900] training loss : 0.383\n",
      "[23 - 1000] training loss : 0.394\n",
      "[23 - 1100] training loss : 0.402\n",
      "[23 - 1200] training loss : 0.423\n",
      "[23 - 1300] training loss : 0.383\n",
      "[23 - 1400] training loss : 0.409\n",
      "[23 - 1500] training loss : 0.388\n",
      "Epoch 23 - Training Loss : 24.654, Training Accuracy : 85.96%\n",
      "[24 - 100] training loss : 0.370\n",
      "[24 - 200] training loss : 0.392\n",
      "[24 - 300] training loss : 0.403\n",
      "[24 - 400] training loss : 0.394\n",
      "[24 - 500] training loss : 0.409\n",
      "[24 - 600] training loss : 0.391\n",
      "[24 - 700] training loss : 0.376\n",
      "[24 - 800] training loss : 0.415\n",
      "[24 - 900] training loss : 0.406\n",
      "[24 - 1000] training loss : 0.419\n",
      "[24 - 1100] training loss : 0.373\n",
      "[24 - 1200] training loss : 0.381\n",
      "[24 - 1300] training loss : 0.406\n",
      "[24 - 1400] training loss : 0.413\n",
      "[24 - 1500] training loss : 0.402\n",
      "Epoch 24 - Training Loss : 26.717, Training Accuracy : 86.11%\n",
      "[25 - 100] training loss : 0.353\n",
      "[25 - 200] training loss : 0.342\n",
      "[25 - 300] training loss : 0.380\n",
      "[25 - 400] training loss : 0.413\n",
      "[25 - 500] training loss : 0.405\n",
      "[25 - 600] training loss : 0.381\n",
      "[25 - 700] training loss : 0.385\n",
      "[25 - 800] training loss : 0.394\n",
      "[25 - 900] training loss : 0.387\n",
      "[25 - 1000] training loss : 0.386\n",
      "[25 - 1100] training loss : 0.386\n",
      "[25 - 1200] training loss : 0.396\n",
      "[25 - 1300] training loss : 0.402\n",
      "[25 - 1400] training loss : 0.375\n",
      "[25 - 1500] training loss : 0.406\n",
      "Epoch 25 - Training Loss : 23.380, Training Accuracy : 86.69%\n",
      "[26 - 100] training loss : 0.353\n",
      "[26 - 200] training loss : 0.351\n",
      "[26 - 300] training loss : 0.389\n",
      "[26 - 400] training loss : 0.373\n",
      "[26 - 500] training loss : 0.368\n",
      "[26 - 600] training loss : 0.377\n",
      "[26 - 700] training loss : 0.384\n",
      "[26 - 800] training loss : 0.406\n",
      "[26 - 900] training loss : 0.359\n",
      "[26 - 1000] training loss : 0.370\n",
      "[26 - 1100] training loss : 0.378\n",
      "[26 - 1200] training loss : 0.403\n",
      "[26 - 1300] training loss : 0.400\n",
      "[26 - 1400] training loss : 0.387\n",
      "[26 - 1500] training loss : 0.371\n",
      "Epoch 26 - Training Loss : 22.129, Training Accuracy : 86.91%\n",
      "[27 - 100] training loss : 0.367\n",
      "[27 - 200] training loss : 0.347\n",
      "[27 - 300] training loss : 0.352\n",
      "[27 - 400] training loss : 0.368\n",
      "[27 - 500] training loss : 0.371\n",
      "[27 - 600] training loss : 0.357\n",
      "[27 - 700] training loss : 0.368\n",
      "[27 - 800] training loss : 0.357\n",
      "[27 - 900] training loss : 0.382\n",
      "[27 - 1000] training loss : 0.391\n",
      "[27 - 1100] training loss : 0.371\n",
      "[27 - 1200] training loss : 0.387\n",
      "[27 - 1300] training loss : 0.315\n",
      "[27 - 1400] training loss : 0.373\n",
      "[27 - 1500] training loss : 0.380\n",
      "Epoch 27 - Training Loss : 26.022, Training Accuracy : 87.13%\n",
      "[28 - 100] training loss : 0.361\n",
      "[28 - 200] training loss : 0.355\n",
      "[28 - 300] training loss : 0.328\n",
      "[28 - 400] training loss : 0.354\n",
      "[28 - 500] training loss : 0.361\n",
      "[28 - 600] training loss : 0.325\n",
      "[28 - 700] training loss : 0.359\n",
      "[28 - 800] training loss : 0.361\n",
      "[28 - 900] training loss : 0.356\n",
      "[28 - 1000] training loss : 0.379\n",
      "[28 - 1100] training loss : 0.378\n",
      "[28 - 1200] training loss : 0.385\n",
      "[28 - 1300] training loss : 0.380\n",
      "[28 - 1400] training loss : 0.377\n",
      "[28 - 1500] training loss : 0.370\n",
      "Epoch 28 - Training Loss : 21.784, Training Accuracy : 87.40%\n",
      "[29 - 100] training loss : 0.341\n",
      "[29 - 200] training loss : 0.308\n",
      "[29 - 300] training loss : 0.362\n",
      "[29 - 400] training loss : 0.349\n",
      "[29 - 500] training loss : 0.382\n",
      "[29 - 600] training loss : 0.342\n",
      "[29 - 700] training loss : 0.357\n",
      "[29 - 800] training loss : 0.315\n",
      "[29 - 900] training loss : 0.327\n",
      "[29 - 1000] training loss : 0.352\n",
      "[29 - 1100] training loss : 0.391\n",
      "[29 - 1200] training loss : 0.343\n",
      "[29 - 1300] training loss : 0.349\n",
      "[29 - 1400] training loss : 0.364\n",
      "[29 - 1500] training loss : 0.345\n",
      "Epoch 29 - Training Loss : 24.796, Training Accuracy : 87.84%\n",
      "[30 - 100] training loss : 0.298\n",
      "[30 - 200] training loss : 0.345\n",
      "[30 - 300] training loss : 0.317\n",
      "[30 - 400] training loss : 0.314\n",
      "[30 - 500] training loss : 0.359\n",
      "[30 - 600] training loss : 0.350\n",
      "[30 - 700] training loss : 0.349\n",
      "[30 - 800] training loss : 0.395\n",
      "[30 - 900] training loss : 0.355\n",
      "[30 - 1000] training loss : 0.342\n",
      "[30 - 1100] training loss : 0.362\n",
      "[30 - 1200] training loss : 0.360\n",
      "[30 - 1300] training loss : 0.359\n",
      "[30 - 1400] training loss : 0.371\n",
      "[30 - 1500] training loss : 0.368\n",
      "Epoch 30 - Training Loss : 22.661, Training Accuracy : 87.79%\n",
      "[31 - 100] training loss : 0.338\n",
      "[31 - 200] training loss : 0.352\n",
      "[31 - 300] training loss : 0.301\n",
      "[31 - 400] training loss : 0.325\n",
      "[31 - 500] training loss : 0.345\n",
      "[31 - 600] training loss : 0.320\n",
      "[31 - 700] training loss : 0.349\n",
      "[31 - 800] training loss : 0.344\n",
      "[31 - 900] training loss : 0.369\n",
      "[31 - 1000] training loss : 0.359\n",
      "[31 - 1100] training loss : 0.343\n",
      "[31 - 1200] training loss : 0.310\n",
      "[31 - 1300] training loss : 0.373\n",
      "[31 - 1400] training loss : 0.341\n",
      "[31 - 1500] training loss : 0.341\n",
      "Epoch 31 - Training Loss : 20.856, Training Accuracy : 88.07%\n",
      "[32 - 100] training loss : 0.324\n",
      "[32 - 200] training loss : 0.331\n",
      "[32 - 300] training loss : 0.305\n",
      "[32 - 400] training loss : 0.324\n",
      "[32 - 500] training loss : 0.337\n",
      "[32 - 600] training loss : 0.343\n",
      "[32 - 700] training loss : 0.330\n",
      "[32 - 800] training loss : 0.361\n",
      "[32 - 900] training loss : 0.347\n",
      "[32 - 1000] training loss : 0.355\n",
      "[32 - 1100] training loss : 0.329\n",
      "[32 - 1200] training loss : 0.315\n",
      "[32 - 1300] training loss : 0.342\n",
      "[32 - 1400] training loss : 0.340\n",
      "[32 - 1500] training loss : 0.349\n",
      "Epoch 32 - Training Loss : 20.723, Training Accuracy : 88.35%\n",
      "[33 - 100] training loss : 0.318\n",
      "[33 - 200] training loss : 0.329\n",
      "[33 - 300] training loss : 0.323\n",
      "[33 - 400] training loss : 0.317\n",
      "[33 - 500] training loss : 0.315\n",
      "[33 - 600] training loss : 0.300\n",
      "[33 - 700] training loss : 0.327\n",
      "[33 - 800] training loss : 0.321\n",
      "[33 - 900] training loss : 0.357\n",
      "[33 - 1000] training loss : 0.329\n",
      "[33 - 1100] training loss : 0.353\n",
      "[33 - 1200] training loss : 0.314\n",
      "[33 - 1300] training loss : 0.322\n",
      "[33 - 1400] training loss : 0.354\n",
      "[33 - 1500] training loss : 0.350\n",
      "Epoch 33 - Training Loss : 20.029, Training Accuracy : 88.49%\n",
      "[34 - 100] training loss : 0.325\n",
      "[34 - 200] training loss : 0.336\n",
      "[34 - 300] training loss : 0.310\n",
      "[34 - 400] training loss : 0.310\n",
      "[34 - 500] training loss : 0.317\n",
      "[34 - 600] training loss : 0.330\n",
      "[34 - 700] training loss : 0.321\n",
      "[34 - 800] training loss : 0.320\n",
      "[34 - 900] training loss : 0.335\n",
      "[34 - 1000] training loss : 0.327\n",
      "[34 - 1100] training loss : 0.328\n",
      "[34 - 1200] training loss : 0.347\n",
      "[34 - 1300] training loss : 0.319\n",
      "[34 - 1400] training loss : 0.347\n",
      "[34 - 1500] training loss : 0.323\n",
      "Epoch 34 - Training Loss : 19.515, Training Accuracy : 88.75%\n",
      "[35 - 100] training loss : 0.279\n",
      "[35 - 200] training loss : 0.320\n",
      "[35 - 300] training loss : 0.300\n",
      "[35 - 400] training loss : 0.312\n",
      "[35 - 500] training loss : 0.336\n",
      "[35 - 600] training loss : 0.329\n",
      "[35 - 700] training loss : 0.319\n",
      "[35 - 800] training loss : 0.324\n",
      "[35 - 900] training loss : 0.325\n",
      "[35 - 1000] training loss : 0.328\n",
      "[35 - 1100] training loss : 0.282\n",
      "[35 - 1200] training loss : 0.302\n",
      "[35 - 1300] training loss : 0.327\n",
      "[35 - 1400] training loss : 0.302\n",
      "[35 - 1500] training loss : 0.317\n",
      "Epoch 35 - Training Loss : 19.625, Training Accuracy : 88.99%\n",
      "[36 - 100] training loss : 0.309\n",
      "[36 - 200] training loss : 0.322\n",
      "[36 - 300] training loss : 0.291\n",
      "[36 - 400] training loss : 0.309\n",
      "[36 - 500] training loss : 0.270\n",
      "[36 - 600] training loss : 0.322\n",
      "[36 - 700] training loss : 0.291\n",
      "[36 - 800] training loss : 0.300\n",
      "[36 - 900] training loss : 0.337\n",
      "[36 - 1000] training loss : 0.317\n",
      "[36 - 1100] training loss : 0.310\n",
      "[36 - 1200] training loss : 0.294\n",
      "[36 - 1300] training loss : 0.326\n",
      "[36 - 1400] training loss : 0.335\n",
      "[36 - 1500] training loss : 0.310\n",
      "Epoch 36 - Training Loss : 21.160, Training Accuracy : 89.04%\n",
      "[37 - 100] training loss : 0.292\n",
      "[37 - 200] training loss : 0.314\n",
      "[37 - 300] training loss : 0.322\n",
      "[37 - 400] training loss : 0.298\n",
      "[37 - 500] training loss : 0.322\n",
      "[37 - 600] training loss : 0.303\n",
      "[37 - 700] training loss : 0.300\n",
      "[37 - 800] training loss : 0.290\n",
      "[37 - 900] training loss : 0.283\n",
      "[37 - 1000] training loss : 0.301\n",
      "[37 - 1100] training loss : 0.307\n",
      "[37 - 1200] training loss : 0.307\n",
      "[37 - 1300] training loss : 0.321\n",
      "[37 - 1400] training loss : 0.332\n",
      "[37 - 1500] training loss : 0.299\n",
      "Epoch 37 - Training Loss : 17.926, Training Accuracy : 89.42%\n",
      "[38 - 100] training loss : 0.287\n",
      "[38 - 200] training loss : 0.300\n",
      "[38 - 300] training loss : 0.260\n",
      "[38 - 400] training loss : 0.296\n",
      "[38 - 500] training loss : 0.288\n",
      "[38 - 600] training loss : 0.298\n",
      "[38 - 700] training loss : 0.304\n",
      "[38 - 800] training loss : 0.294\n",
      "[38 - 900] training loss : 0.311\n",
      "[38 - 1000] training loss : 0.314\n",
      "[38 - 1100] training loss : 0.315\n",
      "[38 - 1200] training loss : 0.335\n",
      "[38 - 1300] training loss : 0.298\n",
      "[38 - 1400] training loss : 0.306\n",
      "[38 - 1500] training loss : 0.303\n",
      "Epoch 38 - Training Loss : 20.499, Training Accuracy : 89.48%\n",
      "[39 - 100] training loss : 0.280\n",
      "[39 - 200] training loss : 0.277\n",
      "[39 - 300] training loss : 0.289\n",
      "[39 - 400] training loss : 0.291\n",
      "[39 - 500] training loss : 0.291\n",
      "[39 - 600] training loss : 0.294\n",
      "[39 - 700] training loss : 0.282\n",
      "[39 - 800] training loss : 0.300\n",
      "[39 - 900] training loss : 0.288\n",
      "[39 - 1000] training loss : 0.307\n",
      "[39 - 1100] training loss : 0.310\n",
      "[39 - 1200] training loss : 0.295\n",
      "[39 - 1300] training loss : 0.297\n",
      "[39 - 1400] training loss : 0.295\n",
      "[39 - 1500] training loss : 0.289\n",
      "Epoch 39 - Training Loss : 18.184, Training Accuracy : 89.68%\n",
      "[40 - 100] training loss : 0.270\n",
      "[40 - 200] training loss : 0.280\n",
      "[40 - 300] training loss : 0.282\n",
      "[40 - 400] training loss : 0.284\n",
      "[40 - 500] training loss : 0.291\n",
      "[40 - 600] training loss : 0.298\n",
      "[40 - 700] training loss : 0.284\n",
      "[40 - 800] training loss : 0.277\n",
      "[40 - 900] training loss : 0.311\n",
      "[40 - 1000] training loss : 0.315\n",
      "[40 - 1100] training loss : 0.295\n",
      "[40 - 1200] training loss : 0.283\n",
      "[40 - 1300] training loss : 0.310\n",
      "[40 - 1400] training loss : 0.299\n",
      "[40 - 1500] training loss : 0.280\n",
      "Epoch 40 - Training Loss : 19.992, Training Accuracy : 89.89%\n",
      "[41 - 100] training loss : 0.279\n",
      "[41 - 200] training loss : 0.294\n",
      "[41 - 300] training loss : 0.296\n",
      "[41 - 400] training loss : 0.282\n",
      "[41 - 500] training loss : 0.269\n",
      "[41 - 600] training loss : 0.293\n",
      "[41 - 700] training loss : 0.297\n",
      "[41 - 800] training loss : 0.299\n",
      "[41 - 900] training loss : 0.277\n",
      "[41 - 1000] training loss : 0.306\n",
      "[41 - 1100] training loss : 0.272\n",
      "[41 - 1200] training loss : 0.290\n",
      "[41 - 1300] training loss : 0.269\n",
      "[41 - 1400] training loss : 0.290\n",
      "[41 - 1500] training loss : 0.292\n",
      "Epoch 41 - Training Loss : 19.673, Training Accuracy : 89.99%\n",
      "[42 - 100] training loss : 0.286\n",
      "[42 - 200] training loss : 0.271\n",
      "[42 - 300] training loss : 0.276\n",
      "[42 - 400] training loss : 0.285\n",
      "[42 - 500] training loss : 0.269\n",
      "[42 - 600] training loss : 0.301\n",
      "[42 - 700] training loss : 0.284\n",
      "[42 - 800] training loss : 0.297\n",
      "[42 - 900] training loss : 0.292\n",
      "[42 - 1000] training loss : 0.311\n",
      "[42 - 1100] training loss : 0.282\n",
      "[42 - 1200] training loss : 0.273\n",
      "[42 - 1300] training loss : 0.260\n",
      "[42 - 1400] training loss : 0.286\n",
      "[42 - 1500] training loss : 0.290\n",
      "Epoch 42 - Training Loss : 18.654, Training Accuracy : 90.10%\n",
      "[43 - 100] training loss : 0.276\n",
      "[43 - 200] training loss : 0.268\n",
      "[43 - 300] training loss : 0.283\n",
      "[43 - 400] training loss : 0.277\n",
      "[43 - 500] training loss : 0.284\n",
      "[43 - 600] training loss : 0.268\n",
      "[43 - 700] training loss : 0.301\n",
      "[43 - 800] training loss : 0.251\n",
      "[43 - 900] training loss : 0.285\n",
      "[43 - 1000] training loss : 0.298\n",
      "[43 - 1100] training loss : 0.300\n",
      "[43 - 1200] training loss : 0.289\n",
      "[43 - 1300] training loss : 0.272\n",
      "[43 - 1400] training loss : 0.283\n",
      "[43 - 1500] training loss : 0.271\n",
      "Epoch 43 - Training Loss : 17.273, Training Accuracy : 90.25%\n",
      "[44 - 100] training loss : 0.245\n",
      "[44 - 200] training loss : 0.281\n",
      "[44 - 300] training loss : 0.281\n",
      "[44 - 400] training loss : 0.269\n",
      "[44 - 500] training loss : 0.280\n",
      "[44 - 600] training loss : 0.272\n",
      "[44 - 700] training loss : 0.269\n",
      "[44 - 800] training loss : 0.268\n",
      "[44 - 900] training loss : 0.285\n",
      "[44 - 1000] training loss : 0.280\n",
      "[44 - 1100] training loss : 0.276\n",
      "[44 - 1200] training loss : 0.276\n",
      "[44 - 1300] training loss : 0.272\n",
      "[44 - 1400] training loss : 0.266\n",
      "[44 - 1500] training loss : 0.288\n",
      "Epoch 44 - Training Loss : 17.352, Training Accuracy : 90.36%\n",
      "[45 - 100] training loss : 0.258\n",
      "[45 - 200] training loss : 0.244\n",
      "[45 - 300] training loss : 0.261\n",
      "[45 - 400] training loss : 0.262\n",
      "[45 - 500] training loss : 0.254\n",
      "[45 - 600] training loss : 0.275\n",
      "[45 - 700] training loss : 0.270\n",
      "[45 - 800] training loss : 0.245\n",
      "[45 - 900] training loss : 0.256\n",
      "[45 - 1000] training loss : 0.272\n",
      "[45 - 1100] training loss : 0.281\n",
      "[45 - 1200] training loss : 0.275\n",
      "[45 - 1300] training loss : 0.270\n",
      "[45 - 1400] training loss : 0.268\n",
      "[45 - 1500] training loss : 0.296\n",
      "Epoch 45 - Training Loss : 17.627, Training Accuracy : 90.74%\n",
      "[46 - 100] training loss : 0.273\n",
      "[46 - 200] training loss : 0.252\n",
      "[46 - 300] training loss : 0.257\n",
      "[46 - 400] training loss : 0.255\n",
      "[46 - 500] training loss : 0.267\n",
      "[46 - 600] training loss : 0.268\n",
      "[46 - 700] training loss : 0.260\n",
      "[46 - 800] training loss : 0.273\n",
      "[46 - 900] training loss : 0.286\n",
      "[46 - 1000] training loss : 0.270\n",
      "[46 - 1100] training loss : 0.274\n",
      "[46 - 1200] training loss : 0.273\n",
      "[46 - 1300] training loss : 0.258\n",
      "[46 - 1400] training loss : 0.242\n",
      "[46 - 1500] training loss : 0.290\n",
      "Epoch 46 - Training Loss : 18.279, Training Accuracy : 90.60%\n",
      "[47 - 100] training loss : 0.246\n",
      "[47 - 200] training loss : 0.255\n",
      "[47 - 300] training loss : 0.260\n",
      "[47 - 400] training loss : 0.275\n",
      "[47 - 500] training loss : 0.246\n",
      "[47 - 600] training loss : 0.268\n",
      "[47 - 700] training loss : 0.268\n",
      "[47 - 800] training loss : 0.269\n",
      "[47 - 900] training loss : 0.292\n",
      "[47 - 1000] training loss : 0.256\n",
      "[47 - 1100] training loss : 0.261\n",
      "[47 - 1200] training loss : 0.259\n",
      "[47 - 1300] training loss : 0.257\n",
      "[47 - 1400] training loss : 0.272\n",
      "[47 - 1500] training loss : 0.254\n",
      "Epoch 47 - Training Loss : 16.382, Training Accuracy : 90.82%\n",
      "[48 - 100] training loss : 0.245\n",
      "[48 - 200] training loss : 0.254\n",
      "[48 - 300] training loss : 0.272\n",
      "[48 - 400] training loss : 0.252\n",
      "[48 - 500] training loss : 0.266\n",
      "[48 - 600] training loss : 0.265\n",
      "[48 - 700] training loss : 0.270\n",
      "[48 - 800] training loss : 0.286\n",
      "[48 - 900] training loss : 0.262\n",
      "[48 - 1000] training loss : 0.262\n",
      "[48 - 1100] training loss : 0.252\n",
      "[48 - 1200] training loss : 0.240\n",
      "[48 - 1300] training loss : 0.268\n",
      "[48 - 1400] training loss : 0.257\n",
      "[48 - 1500] training loss : 0.272\n",
      "Epoch 48 - Training Loss : 18.065, Training Accuracy : 90.78%\n",
      "[49 - 100] training loss : 0.263\n",
      "[49 - 200] training loss : 0.255\n",
      "[49 - 300] training loss : 0.259\n",
      "[49 - 400] training loss : 0.230\n",
      "[49 - 500] training loss : 0.238\n",
      "[49 - 600] training loss : 0.259\n",
      "[49 - 700] training loss : 0.276\n",
      "[49 - 800] training loss : 0.235\n",
      "[49 - 900] training loss : 0.246\n",
      "[49 - 1000] training loss : 0.257\n",
      "[49 - 1100] training loss : 0.246\n",
      "[49 - 1200] training loss : 0.232\n",
      "[49 - 1300] training loss : 0.254\n",
      "[49 - 1400] training loss : 0.250\n",
      "[49 - 1500] training loss : 0.272\n",
      "Epoch 49 - Training Loss : 18.329, Training Accuracy : 91.17%\n",
      "[50 - 100] training loss : 0.256\n",
      "[50 - 200] training loss : 0.268\n",
      "[50 - 300] training loss : 0.240\n",
      "[50 - 400] training loss : 0.233\n",
      "[50 - 500] training loss : 0.235\n",
      "[50 - 600] training loss : 0.263\n",
      "[50 - 700] training loss : 0.238\n",
      "[50 - 800] training loss : 0.280\n",
      "[50 - 900] training loss : 0.230\n",
      "[50 - 1000] training loss : 0.244\n",
      "[50 - 1100] training loss : 0.262\n",
      "[50 - 1200] training loss : 0.266\n",
      "[50 - 1300] training loss : 0.239\n",
      "[50 - 1400] training loss : 0.276\n",
      "[50 - 1500] training loss : 0.268\n",
      "Epoch 50 - Training Loss : 16.046, Training Accuracy : 91.13%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 84.07%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.bn3(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "for epoch in range(50):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1} - {i + 1}] training loss : {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_loss_history.append(running_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - Training Loss : {train_loss_history[-1]:.3f}, Training Accuracy : {train_accuracy:.2f}%\")\n",
    "\n",
    "def plot_loss_and_accuracy(train_loss, train_accuracy):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label=\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracy, label=\"Training Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training loss and accuracy curves\n",
    "plot_loss_and_accuracy(train_loss_history, train_accuracy_history)\n",
    "\n",
    "# Test the model on the test dataset for evaluation\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy : {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex Model Initial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 - 100] training loss : 2.111\n",
      "[1 - 200] training loss : 1.800\n",
      "[1 - 300] training loss : 1.628\n",
      "[1 - 400] training loss : 1.548\n",
      "[1 - 500] training loss : 1.519\n",
      "[1 - 600] training loss : 1.491\n",
      "[1 - 700] training loss : 1.429\n",
      "[1 - 800] training loss : 1.351\n",
      "[1 - 900] training loss : 1.333\n",
      "[1 - 1000] training loss : 1.294\n",
      "[1 - 1100] training loss : 1.272\n",
      "[1 - 1200] training loss : 1.224\n",
      "[1 - 1300] training loss : 1.197\n",
      "[1 - 1400] training loss : 1.228\n",
      "[1 - 1500] training loss : 1.149\n",
      "Epoch 1 - Training Loss : 70.836, Training Accuracy : 48.07%\n",
      "[2 - 100] training loss : 1.114\n",
      "[2 - 200] training loss : 1.105\n",
      "[2 - 300] training loss : 1.039\n",
      "[2 - 400] training loss : 1.041\n",
      "[2 - 500] training loss : 1.012\n",
      "[2 - 600] training loss : 0.985\n",
      "[2 - 700] training loss : 0.977\n",
      "[2 - 800] training loss : 1.007\n",
      "[2 - 900] training loss : 0.987\n",
      "[2 - 1000] training loss : 0.937\n",
      "[2 - 1100] training loss : 0.951\n",
      "[2 - 1200] training loss : 0.934\n",
      "[2 - 1300] training loss : 0.919\n",
      "[2 - 1400] training loss : 0.915\n",
      "[2 - 1500] training loss : 0.886\n",
      "Epoch 2 - Training Loss : 58.459, Training Accuracy : 65.05%\n",
      "[3 - 100] training loss : 0.871\n",
      "[3 - 200] training loss : 0.831\n",
      "[3 - 300] training loss : 0.853\n",
      "[3 - 400] training loss : 0.835\n",
      "[3 - 500] training loss : 0.849\n",
      "[3 - 600] training loss : 0.858\n",
      "[3 - 700] training loss : 0.848\n",
      "[3 - 800] training loss : 0.769\n",
      "[3 - 900] training loss : 0.767\n",
      "[3 - 1000] training loss : 0.850\n",
      "[3 - 1100] training loss : 0.780\n",
      "[3 - 1200] training loss : 0.798\n",
      "[3 - 1300] training loss : 0.789\n",
      "[3 - 1400] training loss : 0.775\n",
      "[3 - 1500] training loss : 0.778\n",
      "Epoch 3 - Training Loss : 49.597, Training Accuracy : 71.24%\n",
      "[4 - 100] training loss : 0.725\n",
      "[4 - 200] training loss : 0.750\n",
      "[4 - 300] training loss : 0.751\n",
      "[4 - 400] training loss : 0.739\n",
      "[4 - 500] training loss : 0.738\n",
      "[4 - 600] training loss : 0.716\n",
      "[4 - 700] training loss : 0.692\n",
      "[4 - 800] training loss : 0.734\n",
      "[4 - 900] training loss : 0.726\n",
      "[4 - 1000] training loss : 0.689\n",
      "[4 - 1100] training loss : 0.704\n",
      "[4 - 1200] training loss : 0.702\n",
      "[4 - 1300] training loss : 0.698\n",
      "[4 - 1400] training loss : 0.674\n",
      "[4 - 1500] training loss : 0.694\n",
      "Epoch 4 - Training Loss : 42.498, Training Accuracy : 75.17%\n",
      "[5 - 100] training loss : 0.620\n",
      "[5 - 200] training loss : 0.639\n",
      "[5 - 300] training loss : 0.625\n",
      "[5 - 400] training loss : 0.646\n",
      "[5 - 500] training loss : 0.640\n",
      "[5 - 600] training loss : 0.646\n",
      "[5 - 700] training loss : 0.662\n",
      "[5 - 800] training loss : 0.617\n",
      "[5 - 900] training loss : 0.663\n",
      "[5 - 1000] training loss : 0.661\n",
      "[5 - 1100] training loss : 0.624\n",
      "[5 - 1200] training loss : 0.642\n",
      "[5 - 1300] training loss : 0.633\n",
      "[5 - 1400] training loss : 0.613\n",
      "[5 - 1500] training loss : 0.626\n",
      "Epoch 5 - Training Loss : 37.180, Training Accuracy : 77.90%\n",
      "[6 - 100] training loss : 0.563\n",
      "[6 - 200] training loss : 0.578\n",
      "[6 - 300] training loss : 0.564\n",
      "[6 - 400] training loss : 0.597\n",
      "[6 - 500] training loss : 0.625\n",
      "[6 - 600] training loss : 0.558\n",
      "[6 - 700] training loss : 0.580\n",
      "[6 - 800] training loss : 0.571\n",
      "[6 - 900] training loss : 0.581\n",
      "[6 - 1000] training loss : 0.561\n",
      "[6 - 1100] training loss : 0.608\n",
      "[6 - 1200] training loss : 0.572\n",
      "[6 - 1300] training loss : 0.564\n",
      "[6 - 1400] training loss : 0.561\n",
      "[6 - 1500] training loss : 0.588\n",
      "Epoch 6 - Training Loss : 37.637, Training Accuracy : 80.07%\n",
      "[7 - 100] training loss : 0.509\n",
      "[7 - 200] training loss : 0.552\n",
      "[7 - 300] training loss : 0.553\n",
      "[7 - 400] training loss : 0.537\n",
      "[7 - 500] training loss : 0.513\n",
      "[7 - 600] training loss : 0.519\n",
      "[7 - 700] training loss : 0.528\n",
      "[7 - 800] training loss : 0.521\n",
      "[7 - 900] training loss : 0.553\n",
      "[7 - 1000] training loss : 0.506\n",
      "[7 - 1100] training loss : 0.546\n",
      "[7 - 1200] training loss : 0.560\n",
      "[7 - 1300] training loss : 0.504\n",
      "[7 - 1400] training loss : 0.548\n",
      "[7 - 1500] training loss : 0.540\n",
      "Epoch 7 - Training Loss : 32.222, Training Accuracy : 81.68%\n",
      "[8 - 100] training loss : 0.504\n",
      "[8 - 200] training loss : 0.512\n",
      "[8 - 300] training loss : 0.491\n",
      "[8 - 400] training loss : 0.500\n",
      "[8 - 500] training loss : 0.508\n",
      "[8 - 600] training loss : 0.470\n",
      "[8 - 700] training loss : 0.485\n",
      "[8 - 800] training loss : 0.462\n",
      "[8 - 900] training loss : 0.482\n",
      "[8 - 1000] training loss : 0.514\n",
      "[8 - 1100] training loss : 0.497\n",
      "[8 - 1200] training loss : 0.492\n",
      "[8 - 1300] training loss : 0.518\n",
      "[8 - 1400] training loss : 0.505\n",
      "[8 - 1500] training loss : 0.485\n",
      "Epoch 8 - Training Loss : 32.388, Training Accuracy : 82.94%\n",
      "[9 - 100] training loss : 0.448\n",
      "[9 - 200] training loss : 0.438\n",
      "[9 - 300] training loss : 0.478\n",
      "[9 - 400] training loss : 0.458\n",
      "[9 - 500] training loss : 0.437\n",
      "[9 - 600] training loss : 0.440\n",
      "[9 - 700] training loss : 0.477\n",
      "[9 - 800] training loss : 0.457\n",
      "[9 - 900] training loss : 0.461\n",
      "[9 - 1000] training loss : 0.474\n",
      "[9 - 1100] training loss : 0.486\n",
      "[9 - 1200] training loss : 0.473\n",
      "[9 - 1300] training loss : 0.447\n",
      "[9 - 1400] training loss : 0.455\n",
      "[9 - 1500] training loss : 0.412\n",
      "Epoch 9 - Training Loss : 29.299, Training Accuracy : 84.37%\n",
      "[10 - 100] training loss : 0.410\n",
      "[10 - 200] training loss : 0.399\n",
      "[10 - 300] training loss : 0.458\n",
      "[10 - 400] training loss : 0.448\n",
      "[10 - 500] training loss : 0.404\n",
      "[10 - 600] training loss : 0.427\n",
      "[10 - 700] training loss : 0.429\n",
      "[10 - 800] training loss : 0.412\n",
      "[10 - 900] training loss : 0.421\n",
      "[10 - 1000] training loss : 0.404\n",
      "[10 - 1100] training loss : 0.470\n",
      "[10 - 1200] training loss : 0.408\n",
      "[10 - 1300] training loss : 0.466\n",
      "[10 - 1400] training loss : 0.426\n",
      "[10 - 1500] training loss : 0.429\n",
      "Epoch 10 - Training Loss : 27.929, Training Accuracy : 85.11%\n",
      "[11 - 100] training loss : 0.379\n",
      "[11 - 200] training loss : 0.379\n",
      "[11 - 300] training loss : 0.419\n",
      "[11 - 400] training loss : 0.416\n",
      "[11 - 500] training loss : 0.408\n",
      "[11 - 600] training loss : 0.384\n",
      "[11 - 700] training loss : 0.417\n",
      "[11 - 800] training loss : 0.403\n",
      "[11 - 900] training loss : 0.426\n",
      "[11 - 1000] training loss : 0.414\n",
      "[11 - 1100] training loss : 0.380\n",
      "[11 - 1200] training loss : 0.357\n",
      "[11 - 1300] training loss : 0.411\n",
      "[11 - 1400] training loss : 0.377\n",
      "[11 - 1500] training loss : 0.379\n",
      "Epoch 11 - Training Loss : 26.293, Training Accuracy : 86.36%\n",
      "[12 - 100] training loss : 0.329\n",
      "[12 - 200] training loss : 0.382\n",
      "[12 - 300] training loss : 0.388\n",
      "[12 - 400] training loss : 0.355\n",
      "[12 - 500] training loss : 0.355\n",
      "[12 - 600] training loss : 0.369\n",
      "[12 - 700] training loss : 0.352\n",
      "[12 - 800] training loss : 0.382\n",
      "[12 - 900] training loss : 0.364\n",
      "[12 - 1000] training loss : 0.377\n",
      "[12 - 1100] training loss : 0.388\n",
      "[12 - 1200] training loss : 0.377\n",
      "[12 - 1300] training loss : 0.376\n",
      "[12 - 1400] training loss : 0.393\n",
      "[12 - 1500] training loss : 0.398\n",
      "Epoch 12 - Training Loss : 23.082, Training Accuracy : 87.08%\n",
      "[13 - 100] training loss : 0.329\n",
      "[13 - 200] training loss : 0.326\n",
      "[13 - 300] training loss : 0.356\n",
      "[13 - 400] training loss : 0.345\n",
      "[13 - 500] training loss : 0.323\n",
      "[13 - 600] training loss : 0.329\n",
      "[13 - 700] training loss : 0.363\n",
      "[13 - 800] training loss : 0.367\n",
      "[13 - 900] training loss : 0.396\n",
      "[13 - 1000] training loss : 0.348\n",
      "[13 - 1100] training loss : 0.355\n",
      "[13 - 1200] training loss : 0.365\n",
      "[13 - 1300] training loss : 0.376\n",
      "[13 - 1400] training loss : 0.371\n",
      "[13 - 1500] training loss : 0.373\n",
      "Epoch 13 - Training Loss : 20.974, Training Accuracy : 87.60%\n",
      "[14 - 100] training loss : 0.300\n",
      "[14 - 200] training loss : 0.321\n",
      "[14 - 300] training loss : 0.310\n",
      "[14 - 400] training loss : 0.341\n",
      "[14 - 500] training loss : 0.336\n",
      "[14 - 600] training loss : 0.343\n",
      "[14 - 700] training loss : 0.345\n",
      "[14 - 800] training loss : 0.344\n",
      "[14 - 900] training loss : 0.335\n",
      "[14 - 1000] training loss : 0.334\n",
      "[14 - 1100] training loss : 0.346\n",
      "[14 - 1200] training loss : 0.343\n",
      "[14 - 1300] training loss : 0.310\n",
      "[14 - 1400] training loss : 0.340\n",
      "[14 - 1500] training loss : 0.336\n",
      "Epoch 14 - Training Loss : 21.950, Training Accuracy : 88.38%\n",
      "[15 - 100] training loss : 0.295\n",
      "[15 - 200] training loss : 0.295\n",
      "[15 - 300] training loss : 0.335\n",
      "[15 - 400] training loss : 0.287\n",
      "[15 - 500] training loss : 0.342\n",
      "[15 - 600] training loss : 0.325\n",
      "[15 - 700] training loss : 0.293\n",
      "[15 - 800] training loss : 0.314\n",
      "[15 - 900] training loss : 0.310\n",
      "[15 - 1000] training loss : 0.330\n",
      "[15 - 1100] training loss : 0.324\n",
      "[15 - 1200] training loss : 0.295\n",
      "[15 - 1300] training loss : 0.286\n",
      "[15 - 1400] training loss : 0.336\n",
      "[15 - 1500] training loss : 0.328\n",
      "Epoch 15 - Training Loss : 20.605, Training Accuracy : 89.15%\n",
      "[16 - 100] training loss : 0.276\n",
      "[16 - 200] training loss : 0.294\n",
      "[16 - 300] training loss : 0.311\n",
      "[16 - 400] training loss : 0.291\n",
      "[16 - 500] training loss : 0.281\n",
      "[16 - 600] training loss : 0.295\n",
      "[16 - 700] training loss : 0.300\n",
      "[16 - 800] training loss : 0.298\n",
      "[16 - 900] training loss : 0.294\n",
      "[16 - 1000] training loss : 0.299\n",
      "[16 - 1100] training loss : 0.301\n",
      "[16 - 1200] training loss : 0.300\n",
      "[16 - 1300] training loss : 0.291\n",
      "[16 - 1400] training loss : 0.318\n",
      "[16 - 1500] training loss : 0.350\n",
      "Epoch 16 - Training Loss : 20.336, Training Accuracy : 89.55%\n",
      "[17 - 100] training loss : 0.283\n",
      "[17 - 200] training loss : 0.276\n",
      "[17 - 300] training loss : 0.265\n",
      "[17 - 400] training loss : 0.281\n",
      "[17 - 500] training loss : 0.273\n",
      "[17 - 600] training loss : 0.296\n",
      "[17 - 700] training loss : 0.292\n",
      "[17 - 800] training loss : 0.271\n",
      "[17 - 900] training loss : 0.275\n",
      "[17 - 1000] training loss : 0.254\n",
      "[17 - 1100] training loss : 0.271\n",
      "[17 - 1200] training loss : 0.303\n",
      "[17 - 1300] training loss : 0.302\n",
      "[17 - 1400] training loss : 0.293\n",
      "[17 - 1500] training loss : 0.287\n",
      "Epoch 17 - Training Loss : 17.273, Training Accuracy : 90.25%\n",
      "[18 - 100] training loss : 0.251\n",
      "[18 - 200] training loss : 0.252\n",
      "[18 - 300] training loss : 0.247\n",
      "[18 - 400] training loss : 0.275\n",
      "[18 - 500] training loss : 0.261\n",
      "[18 - 600] training loss : 0.263\n",
      "[18 - 700] training loss : 0.267\n",
      "[18 - 800] training loss : 0.278\n",
      "[18 - 900] training loss : 0.275\n",
      "[18 - 1000] training loss : 0.268\n",
      "[18 - 1100] training loss : 0.262\n",
      "[18 - 1200] training loss : 0.271\n",
      "[18 - 1300] training loss : 0.280\n",
      "[18 - 1400] training loss : 0.302\n",
      "[18 - 1500] training loss : 0.290\n",
      "Epoch 18 - Training Loss : 17.595, Training Accuracy : 90.51%\n",
      "[19 - 100] training loss : 0.229\n",
      "[19 - 200] training loss : 0.241\n",
      "[19 - 300] training loss : 0.272\n",
      "[19 - 400] training loss : 0.246\n",
      "[19 - 500] training loss : 0.246\n",
      "[19 - 600] training loss : 0.259\n",
      "[19 - 700] training loss : 0.256\n",
      "[19 - 800] training loss : 0.251\n",
      "[19 - 900] training loss : 0.263\n",
      "[19 - 1000] training loss : 0.257\n",
      "[19 - 1100] training loss : 0.268\n",
      "[19 - 1200] training loss : 0.275\n",
      "[19 - 1300] training loss : 0.246\n",
      "[19 - 1400] training loss : 0.269\n",
      "[19 - 1500] training loss : 0.258\n",
      "Epoch 19 - Training Loss : 16.210, Training Accuracy : 91.13%\n",
      "[20 - 100] training loss : 0.221\n",
      "[20 - 200] training loss : 0.240\n",
      "[20 - 300] training loss : 0.234\n",
      "[20 - 400] training loss : 0.267\n",
      "[20 - 500] training loss : 0.255\n",
      "[20 - 600] training loss : 0.240\n",
      "[20 - 700] training loss : 0.252\n",
      "[20 - 800] training loss : 0.245\n",
      "[20 - 900] training loss : 0.231\n",
      "[20 - 1000] training loss : 0.244\n",
      "[20 - 1100] training loss : 0.250\n",
      "[20 - 1200] training loss : 0.241\n",
      "[20 - 1300] training loss : 0.229\n",
      "[20 - 1400] training loss : 0.268\n",
      "[20 - 1500] training loss : 0.243\n",
      "Epoch 20 - Training Loss : 17.944, Training Accuracy : 91.51%\n",
      "[21 - 100] training loss : 0.230\n",
      "[21 - 200] training loss : 0.206\n",
      "[21 - 300] training loss : 0.240\n",
      "[21 - 400] training loss : 0.217\n",
      "[21 - 500] training loss : 0.247\n",
      "[21 - 600] training loss : 0.223\n",
      "[21 - 700] training loss : 0.234\n",
      "[21 - 800] training loss : 0.209\n",
      "[21 - 900] training loss : 0.238\n",
      "[21 - 1000] training loss : 0.236\n",
      "[21 - 1100] training loss : 0.237\n",
      "[21 - 1200] training loss : 0.247\n",
      "[21 - 1300] training loss : 0.246\n",
      "[21 - 1400] training loss : 0.241\n",
      "[21 - 1500] training loss : 0.232\n",
      "Epoch 21 - Training Loss : 15.476, Training Accuracy : 91.84%\n",
      "[22 - 100] training loss : 0.188\n",
      "[22 - 200] training loss : 0.213\n",
      "[22 - 300] training loss : 0.213\n",
      "[22 - 400] training loss : 0.212\n",
      "[22 - 500] training loss : 0.235\n",
      "[22 - 600] training loss : 0.235\n",
      "[22 - 700] training loss : 0.211\n",
      "[22 - 800] training loss : 0.218\n",
      "[22 - 900] training loss : 0.222\n",
      "[22 - 1000] training loss : 0.253\n",
      "[22 - 1100] training loss : 0.248\n",
      "[22 - 1200] training loss : 0.223\n",
      "[22 - 1300] training loss : 0.237\n",
      "[22 - 1400] training loss : 0.227\n",
      "[22 - 1500] training loss : 0.241\n",
      "Epoch 22 - Training Loss : 12.893, Training Accuracy : 92.31%\n",
      "[23 - 100] training loss : 0.203\n",
      "[23 - 200] training loss : 0.209\n",
      "[23 - 300] training loss : 0.204\n",
      "[23 - 400] training loss : 0.183\n",
      "[23 - 500] training loss : 0.219\n",
      "[23 - 600] training loss : 0.212\n",
      "[23 - 700] training loss : 0.220\n",
      "[23 - 800] training loss : 0.212\n",
      "[23 - 900] training loss : 0.189\n",
      "[23 - 1000] training loss : 0.210\n",
      "[23 - 1100] training loss : 0.218\n",
      "[23 - 1200] training loss : 0.210\n",
      "[23 - 1300] training loss : 0.248\n",
      "[23 - 1400] training loss : 0.222\n",
      "[23 - 1500] training loss : 0.209\n",
      "Epoch 23 - Training Loss : 13.746, Training Accuracy : 92.60%\n",
      "[24 - 100] training loss : 0.199\n",
      "[24 - 200] training loss : 0.219\n",
      "[24 - 300] training loss : 0.216\n",
      "[24 - 400] training loss : 0.204\n",
      "[24 - 500] training loss : 0.194\n",
      "[24 - 600] training loss : 0.209\n",
      "[24 - 700] training loss : 0.228\n",
      "[24 - 800] training loss : 0.213\n",
      "[24 - 900] training loss : 0.190\n",
      "[24 - 1000] training loss : 0.219\n",
      "[24 - 1100] training loss : 0.205\n",
      "[24 - 1200] training loss : 0.201\n",
      "[24 - 1300] training loss : 0.210\n",
      "[24 - 1400] training loss : 0.246\n",
      "[24 - 1500] training loss : 0.217\n",
      "Epoch 24 - Training Loss : 14.021, Training Accuracy : 92.59%\n",
      "[25 - 100] training loss : 0.186\n",
      "[25 - 200] training loss : 0.190\n",
      "[25 - 300] training loss : 0.194\n",
      "[25 - 400] training loss : 0.197\n",
      "[25 - 500] training loss : 0.206\n",
      "[25 - 600] training loss : 0.215\n",
      "[25 - 700] training loss : 0.205\n",
      "[25 - 800] training loss : 0.196\n",
      "[25 - 900] training loss : 0.205\n",
      "[25 - 1000] training loss : 0.201\n",
      "[25 - 1100] training loss : 0.199\n",
      "[25 - 1200] training loss : 0.212\n",
      "[25 - 1300] training loss : 0.193\n",
      "[25 - 1400] training loss : 0.203\n",
      "[25 - 1500] training loss : 0.211\n",
      "Epoch 25 - Training Loss : 13.351, Training Accuracy : 93.06%\n",
      "[26 - 100] training loss : 0.187\n",
      "[26 - 200] training loss : 0.175\n",
      "[26 - 300] training loss : 0.180\n",
      "[26 - 400] training loss : 0.164\n",
      "[26 - 500] training loss : 0.190\n",
      "[26 - 600] training loss : 0.204\n",
      "[26 - 700] training loss : 0.192\n",
      "[26 - 800] training loss : 0.217\n",
      "[26 - 900] training loss : 0.178\n",
      "[26 - 1000] training loss : 0.181\n",
      "[26 - 1100] training loss : 0.197\n",
      "[26 - 1200] training loss : 0.199\n",
      "[26 - 1300] training loss : 0.225\n",
      "[26 - 1400] training loss : 0.204\n",
      "[26 - 1500] training loss : 0.199\n",
      "Epoch 26 - Training Loss : 13.485, Training Accuracy : 93.21%\n",
      "[27 - 100] training loss : 0.189\n",
      "[27 - 200] training loss : 0.169\n",
      "[27 - 300] training loss : 0.185\n",
      "[27 - 400] training loss : 0.184\n",
      "[27 - 500] training loss : 0.210\n",
      "[27 - 600] training loss : 0.182\n",
      "[27 - 700] training loss : 0.195\n",
      "[27 - 800] training loss : 0.180\n",
      "[27 - 900] training loss : 0.170\n",
      "[27 - 1000] training loss : 0.199\n",
      "[27 - 1100] training loss : 0.189\n",
      "[27 - 1200] training loss : 0.210\n",
      "[27 - 1300] training loss : 0.196\n",
      "[27 - 1400] training loss : 0.182\n",
      "[27 - 1500] training loss : 0.200\n",
      "Epoch 27 - Training Loss : 14.601, Training Accuracy : 93.27%\n",
      "[28 - 100] training loss : 0.155\n",
      "[28 - 200] training loss : 0.168\n",
      "[28 - 300] training loss : 0.184\n",
      "[28 - 400] training loss : 0.185\n",
      "[28 - 500] training loss : 0.176\n",
      "[28 - 600] training loss : 0.205\n",
      "[28 - 700] training loss : 0.193\n",
      "[28 - 800] training loss : 0.192\n",
      "[28 - 900] training loss : 0.184\n",
      "[28 - 1000] training loss : 0.182\n",
      "[28 - 1100] training loss : 0.186\n",
      "[28 - 1200] training loss : 0.183\n",
      "[28 - 1300] training loss : 0.191\n",
      "[28 - 1400] training loss : 0.185\n",
      "[28 - 1500] training loss : 0.193\n",
      "Epoch 28 - Training Loss : 11.113, Training Accuracy : 93.58%\n",
      "[29 - 100] training loss : 0.162\n",
      "[29 - 200] training loss : 0.165\n",
      "[29 - 300] training loss : 0.164\n",
      "[29 - 400] training loss : 0.169\n",
      "[29 - 500] training loss : 0.168\n",
      "[29 - 600] training loss : 0.168\n",
      "[29 - 700] training loss : 0.166\n",
      "[29 - 800] training loss : 0.167\n",
      "[29 - 900] training loss : 0.167\n",
      "[29 - 1000] training loss : 0.193\n",
      "[29 - 1100] training loss : 0.184\n",
      "[29 - 1200] training loss : 0.192\n",
      "[29 - 1300] training loss : 0.187\n",
      "[29 - 1400] training loss : 0.163\n",
      "[29 - 1500] training loss : 0.196\n",
      "Epoch 29 - Training Loss : 11.096, Training Accuracy : 93.80%\n",
      "[30 - 100] training loss : 0.167\n",
      "[30 - 200] training loss : 0.170\n",
      "[30 - 300] training loss : 0.162\n",
      "[30 - 400] training loss : 0.184\n",
      "[30 - 500] training loss : 0.158\n",
      "[30 - 600] training loss : 0.166\n",
      "[30 - 700] training loss : 0.154\n",
      "[30 - 800] training loss : 0.159\n",
      "[30 - 900] training loss : 0.152\n",
      "[30 - 1000] training loss : 0.190\n",
      "[30 - 1100] training loss : 0.192\n",
      "[30 - 1200] training loss : 0.178\n",
      "[30 - 1300] training loss : 0.160\n",
      "[30 - 1400] training loss : 0.181\n",
      "[30 - 1500] training loss : 0.181\n",
      "Epoch 30 - Training Loss : 11.264, Training Accuracy : 94.06%\n",
      "[31 - 100] training loss : 0.142\n",
      "[31 - 200] training loss : 0.159\n",
      "[31 - 300] training loss : 0.147\n",
      "[31 - 400] training loss : 0.156\n",
      "[31 - 500] training loss : 0.164\n",
      "[31 - 600] training loss : 0.158\n",
      "[31 - 700] training loss : 0.160\n",
      "[31 - 800] training loss : 0.165\n",
      "[31 - 900] training loss : 0.164\n",
      "[31 - 1000] training loss : 0.177\n",
      "[31 - 1100] training loss : 0.177\n",
      "[31 - 1200] training loss : 0.154\n",
      "[31 - 1300] training loss : 0.160\n",
      "[31 - 1400] training loss : 0.162\n",
      "[31 - 1500] training loss : 0.176\n",
      "Epoch 31 - Training Loss : 10.195, Training Accuracy : 94.36%\n",
      "[32 - 100] training loss : 0.138\n",
      "[32 - 200] training loss : 0.151\n",
      "[32 - 300] training loss : 0.155\n",
      "[32 - 400] training loss : 0.138\n",
      "[32 - 500] training loss : 0.164\n",
      "[32 - 600] training loss : 0.162\n",
      "[32 - 700] training loss : 0.164\n",
      "[32 - 800] training loss : 0.146\n",
      "[32 - 900] training loss : 0.144\n",
      "[32 - 1000] training loss : 0.160\n",
      "[32 - 1100] training loss : 0.163\n",
      "[32 - 1200] training loss : 0.174\n",
      "[32 - 1300] training loss : 0.176\n",
      "[32 - 1400] training loss : 0.169\n",
      "[32 - 1500] training loss : 0.165\n",
      "Epoch 32 - Training Loss : 11.349, Training Accuracy : 94.38%\n",
      "[33 - 100] training loss : 0.138\n",
      "[33 - 200] training loss : 0.145\n",
      "[33 - 300] training loss : 0.146\n",
      "[33 - 400] training loss : 0.138\n",
      "[33 - 500] training loss : 0.157\n",
      "[33 - 600] training loss : 0.148\n",
      "[33 - 700] training loss : 0.145\n",
      "[33 - 800] training loss : 0.154\n",
      "[33 - 900] training loss : 0.168\n",
      "[33 - 1000] training loss : 0.132\n",
      "[33 - 1100] training loss : 0.163\n",
      "[33 - 1200] training loss : 0.166\n",
      "[33 - 1300] training loss : 0.168\n",
      "[33 - 1400] training loss : 0.151\n",
      "[33 - 1500] training loss : 0.171\n",
      "Epoch 33 - Training Loss : 9.741, Training Accuracy : 94.65%\n",
      "[34 - 100] training loss : 0.123\n",
      "[34 - 200] training loss : 0.149\n",
      "[34 - 300] training loss : 0.136\n",
      "[34 - 400] training loss : 0.162\n",
      "[34 - 500] training loss : 0.165\n",
      "[34 - 600] training loss : 0.165\n",
      "[34 - 700] training loss : 0.149\n",
      "[34 - 800] training loss : 0.135\n",
      "[34 - 900] training loss : 0.172\n",
      "[34 - 1000] training loss : 0.155\n",
      "[34 - 1100] training loss : 0.173\n",
      "[34 - 1200] training loss : 0.156\n",
      "[34 - 1300] training loss : 0.144\n",
      "[34 - 1400] training loss : 0.164\n",
      "[34 - 1500] training loss : 0.132\n",
      "Epoch 34 - Training Loss : 9.445, Training Accuracy : 94.77%\n",
      "[35 - 100] training loss : 0.142\n",
      "[35 - 200] training loss : 0.158\n",
      "[35 - 300] training loss : 0.131\n",
      "[35 - 400] training loss : 0.142\n",
      "[35 - 500] training loss : 0.153\n",
      "[35 - 600] training loss : 0.150\n",
      "[35 - 700] training loss : 0.146\n",
      "[35 - 800] training loss : 0.148\n",
      "[35 - 900] training loss : 0.153\n",
      "[35 - 1000] training loss : 0.159\n",
      "[35 - 1100] training loss : 0.149\n",
      "[35 - 1200] training loss : 0.143\n",
      "[35 - 1300] training loss : 0.144\n",
      "[35 - 1400] training loss : 0.159\n",
      "[35 - 1500] training loss : 0.129\n",
      "Epoch 35 - Training Loss : 9.269, Training Accuracy : 94.81%\n",
      "[36 - 100] training loss : 0.133\n",
      "[36 - 200] training loss : 0.138\n",
      "[36 - 300] training loss : 0.152\n",
      "[36 - 400] training loss : 0.139\n",
      "[36 - 500] training loss : 0.129\n",
      "[36 - 600] training loss : 0.132\n",
      "[36 - 700] training loss : 0.138\n",
      "[36 - 800] training loss : 0.148\n",
      "[36 - 900] training loss : 0.142\n",
      "[36 - 1000] training loss : 0.145\n",
      "[36 - 1100] training loss : 0.152\n",
      "[36 - 1200] training loss : 0.138\n",
      "[36 - 1300] training loss : 0.150\n",
      "[36 - 1400] training loss : 0.134\n",
      "[36 - 1500] training loss : 0.157\n",
      "Epoch 36 - Training Loss : 9.419, Training Accuracy : 95.06%\n",
      "[37 - 100] training loss : 0.130\n",
      "[37 - 200] training loss : 0.133\n",
      "[37 - 300] training loss : 0.120\n",
      "[37 - 400] training loss : 0.122\n",
      "[37 - 500] training loss : 0.136\n",
      "[37 - 600] training loss : 0.134\n",
      "[37 - 700] training loss : 0.138\n",
      "[37 - 800] training loss : 0.110\n",
      "[37 - 900] training loss : 0.130\n",
      "[37 - 1000] training loss : 0.133\n",
      "[37 - 1100] training loss : 0.165\n",
      "[37 - 1200] training loss : 0.152\n",
      "[37 - 1300] training loss : 0.141\n",
      "[37 - 1400] training loss : 0.138\n",
      "[37 - 1500] training loss : 0.140\n",
      "Epoch 37 - Training Loss : 10.036, Training Accuracy : 95.27%\n",
      "[38 - 100] training loss : 0.124\n",
      "[38 - 200] training loss : 0.126\n",
      "[38 - 300] training loss : 0.116\n",
      "[38 - 400] training loss : 0.137\n",
      "[38 - 500] training loss : 0.141\n",
      "[38 - 600] training loss : 0.134\n",
      "[38 - 700] training loss : 0.140\n",
      "[38 - 800] training loss : 0.126\n",
      "[38 - 900] training loss : 0.150\n",
      "[38 - 1000] training loss : 0.125\n",
      "[38 - 1100] training loss : 0.146\n",
      "[38 - 1200] training loss : 0.129\n",
      "[38 - 1300] training loss : 0.132\n",
      "[38 - 1400] training loss : 0.146\n",
      "[38 - 1500] training loss : 0.134\n",
      "Epoch 38 - Training Loss : 9.588, Training Accuracy : 95.29%\n",
      "[39 - 100] training loss : 0.124\n",
      "[39 - 200] training loss : 0.127\n",
      "[39 - 300] training loss : 0.109\n",
      "[39 - 400] training loss : 0.124\n",
      "[39 - 500] training loss : 0.126\n",
      "[39 - 600] training loss : 0.147\n",
      "[39 - 700] training loss : 0.124\n",
      "[39 - 800] training loss : 0.151\n",
      "[39 - 900] training loss : 0.133\n",
      "[39 - 1000] training loss : 0.137\n",
      "[39 - 1100] training loss : 0.141\n",
      "[39 - 1200] training loss : 0.123\n",
      "[39 - 1300] training loss : 0.147\n",
      "[39 - 1400] training loss : 0.160\n",
      "[39 - 1500] training loss : 0.145\n",
      "Epoch 39 - Training Loss : 7.422, Training Accuracy : 95.34%\n",
      "[40 - 100] training loss : 0.128\n",
      "[40 - 200] training loss : 0.104\n",
      "[40 - 300] training loss : 0.114\n",
      "[40 - 400] training loss : 0.124\n",
      "[40 - 500] training loss : 0.133\n",
      "[40 - 600] training loss : 0.127\n",
      "[40 - 700] training loss : 0.114\n",
      "[40 - 800] training loss : 0.138\n",
      "[40 - 900] training loss : 0.130\n",
      "[40 - 1000] training loss : 0.133\n",
      "[40 - 1100] training loss : 0.111\n",
      "[40 - 1200] training loss : 0.138\n",
      "[40 - 1300] training loss : 0.112\n",
      "[40 - 1400] training loss : 0.132\n",
      "[40 - 1500] training loss : 0.154\n",
      "Epoch 40 - Training Loss : 8.816, Training Accuracy : 95.56%\n",
      "[41 - 100] training loss : 0.114\n",
      "[41 - 200] training loss : 0.122\n",
      "[41 - 300] training loss : 0.126\n",
      "[41 - 400] training loss : 0.123\n",
      "[41 - 500] training loss : 0.099\n",
      "[41 - 600] training loss : 0.115\n",
      "[41 - 700] training loss : 0.117\n",
      "[41 - 800] training loss : 0.126\n",
      "[41 - 900] training loss : 0.134\n",
      "[41 - 1000] training loss : 0.128\n",
      "[41 - 1100] training loss : 0.134\n",
      "[41 - 1200] training loss : 0.135\n",
      "[41 - 1300] training loss : 0.139\n",
      "[41 - 1400] training loss : 0.125\n",
      "[41 - 1500] training loss : 0.136\n",
      "Epoch 41 - Training Loss : 8.010, Training Accuracy : 95.64%\n",
      "[42 - 100] training loss : 0.104\n",
      "[42 - 200] training loss : 0.140\n",
      "[42 - 300] training loss : 0.122\n",
      "[42 - 400] training loss : 0.117\n",
      "[42 - 500] training loss : 0.118\n",
      "[42 - 600] training loss : 0.136\n",
      "[42 - 700] training loss : 0.143\n",
      "[42 - 800] training loss : 0.118\n",
      "[42 - 900] training loss : 0.125\n",
      "[42 - 1000] training loss : 0.117\n",
      "[42 - 1100] training loss : 0.150\n",
      "[42 - 1200] training loss : 0.133\n",
      "[42 - 1300] training loss : 0.124\n",
      "[42 - 1400] training loss : 0.125\n",
      "[42 - 1500] training loss : 0.132\n",
      "Epoch 42 - Training Loss : 8.882, Training Accuracy : 95.48%\n",
      "[43 - 100] training loss : 0.107\n",
      "[43 - 200] training loss : 0.128\n",
      "[43 - 300] training loss : 0.115\n",
      "[43 - 400] training loss : 0.118\n",
      "[43 - 500] training loss : 0.106\n",
      "[43 - 600] training loss : 0.104\n",
      "[43 - 700] training loss : 0.128\n",
      "[43 - 800] training loss : 0.123\n",
      "[43 - 900] training loss : 0.121\n",
      "[43 - 1000] training loss : 0.136\n",
      "[43 - 1100] training loss : 0.128\n",
      "[43 - 1200] training loss : 0.133\n",
      "[43 - 1300] training loss : 0.108\n",
      "[43 - 1400] training loss : 0.121\n",
      "[43 - 1500] training loss : 0.125\n",
      "Epoch 43 - Training Loss : 6.309, Training Accuracy : 95.84%\n",
      "[44 - 100] training loss : 0.124\n",
      "[44 - 200] training loss : 0.106\n",
      "[44 - 300] training loss : 0.110\n",
      "[44 - 400] training loss : 0.107\n",
      "[44 - 500] training loss : 0.115\n",
      "[44 - 600] training loss : 0.092\n",
      "[44 - 700] training loss : 0.105\n",
      "[44 - 800] training loss : 0.135\n",
      "[44 - 900] training loss : 0.117\n",
      "[44 - 1000] training loss : 0.121\n",
      "[44 - 1100] training loss : 0.116\n",
      "[44 - 1200] training loss : 0.128\n",
      "[44 - 1300] training loss : 0.113\n",
      "[44 - 1400] training loss : 0.129\n",
      "[44 - 1500] training loss : 0.137\n",
      "Epoch 44 - Training Loss : 8.439, Training Accuracy : 95.95%\n",
      "[45 - 100] training loss : 0.099\n",
      "[45 - 200] training loss : 0.102\n",
      "[45 - 300] training loss : 0.107\n",
      "[45 - 400] training loss : 0.114\n",
      "[45 - 500] training loss : 0.124\n",
      "[45 - 600] training loss : 0.109\n",
      "[45 - 700] training loss : 0.099\n",
      "[45 - 800] training loss : 0.113\n",
      "[45 - 900] training loss : 0.116\n",
      "[45 - 1000] training loss : 0.115\n",
      "[45 - 1100] training loss : 0.116\n",
      "[45 - 1200] training loss : 0.125\n",
      "[45 - 1300] training loss : 0.107\n",
      "[45 - 1400] training loss : 0.128\n",
      "[45 - 1500] training loss : 0.119\n",
      "Epoch 45 - Training Loss : 8.029, Training Accuracy : 96.10%\n",
      "[46 - 100] training loss : 0.114\n",
      "[46 - 200] training loss : 0.112\n",
      "[46 - 300] training loss : 0.120\n",
      "[46 - 400] training loss : 0.107\n",
      "[46 - 500] training loss : 0.115\n",
      "[46 - 600] training loss : 0.126\n",
      "[46 - 700] training loss : 0.118\n",
      "[46 - 800] training loss : 0.106\n",
      "[46 - 900] training loss : 0.139\n",
      "[46 - 1000] training loss : 0.113\n",
      "[46 - 1100] training loss : 0.111\n",
      "[46 - 1200] training loss : 0.123\n",
      "[46 - 1300] training loss : 0.097\n",
      "[46 - 1400] training loss : 0.109\n",
      "[46 - 1500] training loss : 0.116\n",
      "Epoch 46 - Training Loss : 8.295, Training Accuracy : 96.00%\n",
      "[47 - 100] training loss : 0.097\n",
      "[47 - 200] training loss : 0.095\n",
      "[47 - 300] training loss : 0.087\n",
      "[47 - 400] training loss : 0.109\n",
      "[47 - 500] training loss : 0.096\n",
      "[47 - 600] training loss : 0.089\n",
      "[47 - 700] training loss : 0.109\n",
      "[47 - 800] training loss : 0.127\n",
      "[47 - 900] training loss : 0.113\n",
      "[47 - 1000] training loss : 0.127\n",
      "[47 - 1100] training loss : 0.099\n",
      "[47 - 1200] training loss : 0.115\n",
      "[47 - 1300] training loss : 0.119\n",
      "[47 - 1400] training loss : 0.123\n",
      "[47 - 1500] training loss : 0.127\n",
      "Epoch 47 - Training Loss : 8.157, Training Accuracy : 96.16%\n",
      "[48 - 100] training loss : 0.100\n",
      "[48 - 200] training loss : 0.094\n",
      "[48 - 300] training loss : 0.090\n",
      "[48 - 400] training loss : 0.111\n",
      "[48 - 500] training loss : 0.102\n",
      "[48 - 600] training loss : 0.106\n",
      "[48 - 700] training loss : 0.110\n",
      "[48 - 800] training loss : 0.103\n",
      "[48 - 900] training loss : 0.113\n",
      "[48 - 1000] training loss : 0.119\n",
      "[48 - 1100] training loss : 0.111\n",
      "[48 - 1200] training loss : 0.109\n",
      "[48 - 1300] training loss : 0.101\n",
      "[48 - 1400] training loss : 0.129\n",
      "[48 - 1500] training loss : 0.092\n",
      "Epoch 48 - Training Loss : 7.741, Training Accuracy : 96.33%\n",
      "[49 - 100] training loss : 0.091\n",
      "[49 - 200] training loss : 0.090\n",
      "[49 - 300] training loss : 0.099\n",
      "[49 - 400] training loss : 0.091\n",
      "[49 - 500] training loss : 0.109\n",
      "[49 - 600] training loss : 0.123\n",
      "[49 - 700] training loss : 0.109\n",
      "[49 - 800] training loss : 0.120\n",
      "[49 - 900] training loss : 0.127\n",
      "[49 - 1000] training loss : 0.104\n",
      "[49 - 1100] training loss : 0.112\n",
      "[49 - 1200] training loss : 0.104\n",
      "[49 - 1300] training loss : 0.098\n",
      "[49 - 1400] training loss : 0.116\n",
      "[49 - 1500] training loss : 0.113\n",
      "Epoch 49 - Training Loss : 6.258, Training Accuracy : 96.21%\n",
      "[50 - 100] training loss : 0.093\n",
      "[50 - 200] training loss : 0.102\n",
      "[50 - 300] training loss : 0.107\n",
      "[50 - 400] training loss : 0.110\n",
      "[50 - 500] training loss : 0.110\n",
      "[50 - 600] training loss : 0.095\n",
      "[50 - 700] training loss : 0.095\n",
      "[50 - 800] training loss : 0.101\n",
      "[50 - 900] training loss : 0.107\n",
      "[50 - 1000] training loss : 0.120\n",
      "[50 - 1100] training loss : 0.114\n",
      "[50 - 1200] training loss : 0.107\n",
      "[50 - 1300] training loss : 0.093\n",
      "[50 - 1400] training loss : 0.128\n",
      "[50 - 1500] training loss : 0.114\n",
      "Epoch 50 - Training Loss : 6.711, Training Accuracy : 96.33%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 87.64%\n"
     ]
    }
   ],
   "source": [
    "class ComplexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = ComplexNet()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "\n",
    "for epoch in range(50):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1} - {i + 1}] training loss : {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_loss_history.append(running_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - Training Loss : {train_loss_history[-1]:.3f}, Training Accuracy : {train_accuracy:.2f}%\")\n",
    "\n",
    "# Plot training loss and accuracy curves\n",
    "plot_loss_and_accuracy(train_loss_history, train_accuracy_history)\n",
    "\n",
    "# Test the model on the test dataset for evaluation\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy : {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning on the Complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with learning rate 0.001, num_epochs 5, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.859\n",
      "[1, 200] training loss: 1.575\n",
      "[1, 300] training loss: 1.528\n",
      "[1, 400] training loss: 1.430\n",
      "[1, 500] training loss: 1.391\n",
      "[1, 600] training loss: 1.293\n",
      "[1, 700] training loss: 1.254\n",
      "[1, 800] training loss: 1.266\n",
      "[1, 900] training loss: 1.219\n",
      "[1, 1000] training loss: 1.174\n",
      "[1, 1100] training loss: 1.192\n",
      "[1, 1200] training loss: 1.163\n",
      "[2, 100] training loss: 1.122\n",
      "[2, 200] training loss: 1.100\n",
      "[2, 300] training loss: 1.065\n",
      "[2, 400] training loss: 1.108\n",
      "[2, 500] training loss: 1.075\n",
      "[2, 600] training loss: 1.057\n",
      "[2, 700] training loss: 1.040\n",
      "[2, 800] training loss: 1.056\n",
      "[2, 900] training loss: 1.057\n",
      "[2, 1000] training loss: 1.047\n",
      "[2, 1100] training loss: 1.048\n",
      "[2, 1200] training loss: 0.991\n",
      "[3, 100] training loss: 0.974\n",
      "[3, 200] training loss: 0.968\n",
      "[3, 300] training loss: 0.964\n",
      "[3, 400] training loss: 0.959\n",
      "[3, 500] training loss: 0.942\n",
      "[3, 600] training loss: 0.949\n",
      "[3, 700] training loss: 0.940\n",
      "[3, 800] training loss: 0.919\n",
      "[3, 900] training loss: 0.902\n",
      "[3, 1000] training loss: 0.923\n",
      "[3, 1100] training loss: 0.884\n",
      "[3, 1200] training loss: 0.931\n",
      "[4, 100] training loss: 0.864\n",
      "[4, 200] training loss: 0.874\n",
      "[4, 300] training loss: 0.878\n",
      "[4, 400] training loss: 0.883\n",
      "[4, 500] training loss: 0.869\n",
      "[4, 600] training loss: 0.876\n",
      "[4, 700] training loss: 0.867\n",
      "[4, 800] training loss: 0.873\n",
      "[4, 900] training loss: 0.843\n",
      "[4, 1000] training loss: 0.864\n",
      "[4, 1100] training loss: 0.847\n",
      "[4, 1200] training loss: 0.818\n",
      "[5, 100] training loss: 0.826\n",
      "[5, 200] training loss: 0.801\n",
      "[5, 300] training loss: 0.816\n",
      "[5, 400] training loss: 0.795\n",
      "[5, 500] training loss: 0.810\n",
      "[5, 600] training loss: 0.808\n",
      "[5, 700] training loss: 0.796\n",
      "[5, 800] training loss: 0.772\n",
      "[5, 900] training loss: 0.852\n",
      "[5, 1000] training loss: 0.778\n",
      "[5, 1100] training loss: 0.826\n",
      "[5, 1200] training loss: 0.785\n",
      "Training model with learning rate 0.001, num_epochs 5, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.693\n",
      "[1, 200] training loss: 1.451\n",
      "[1, 300] training loss: 1.312\n",
      "[1, 400] training loss: 1.218\n",
      "[1, 500] training loss: 1.174\n",
      "[1, 600] training loss: 1.142\n",
      "[2, 100] training loss: 1.075\n",
      "[2, 200] training loss: 1.055\n",
      "[2, 300] training loss: 1.025\n",
      "[2, 400] training loss: 1.019\n",
      "[2, 500] training loss: 0.981\n",
      "[2, 600] training loss: 0.990\n",
      "[3, 100] training loss: 0.926\n",
      "[3, 200] training loss: 0.929\n",
      "[3, 300] training loss: 0.927\n",
      "[3, 400] training loss: 0.919\n",
      "[3, 500] training loss: 0.894\n",
      "[3, 600] training loss: 0.883\n",
      "[4, 100] training loss: 0.855\n",
      "[4, 200] training loss: 0.853\n",
      "[4, 300] training loss: 0.866\n",
      "[4, 400] training loss: 0.833\n",
      "[4, 500] training loss: 0.836\n",
      "[4, 600] training loss: 0.806\n",
      "[5, 100] training loss: 0.801\n",
      "[5, 200] training loss: 0.770\n",
      "[5, 300] training loss: 0.787\n",
      "[5, 400] training loss: 0.797\n",
      "[5, 500] training loss: 0.790\n",
      "[5, 600] training loss: 0.763\n",
      "Training model with learning rate 0.001, num_epochs 5, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.603\n",
      "[1, 200] training loss: 1.274\n",
      "[1, 300] training loss: 1.151\n",
      "[2, 100] training loss: 1.061\n",
      "[2, 200] training loss: 1.020\n",
      "[2, 300] training loss: 0.993\n",
      "[3, 100] training loss: 0.933\n",
      "[3, 200] training loss: 0.909\n",
      "[3, 300] training loss: 0.895\n",
      "[4, 100] training loss: 0.832\n",
      "[4, 200] training loss: 0.840\n",
      "[4, 300] training loss: 0.834\n",
      "[5, 100] training loss: 0.779\n",
      "[5, 200] training loss: 0.756\n",
      "[5, 300] training loss: 0.757\n",
      "Training model with learning rate 0.001, num_epochs 10, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.864\n",
      "[1, 200] training loss: 1.575\n",
      "[1, 300] training loss: 1.470\n",
      "[1, 400] training loss: 1.409\n",
      "[1, 500] training loss: 1.365\n",
      "[1, 600] training loss: 1.354\n",
      "[1, 700] training loss: 1.291\n",
      "[1, 800] training loss: 1.245\n",
      "[1, 900] training loss: 1.189\n",
      "[1, 1000] training loss: 1.212\n",
      "[1, 1100] training loss: 1.159\n",
      "[1, 1200] training loss: 1.186\n",
      "[2, 100] training loss: 1.108\n",
      "[2, 200] training loss: 1.114\n",
      "[2, 300] training loss: 1.075\n",
      "[2, 400] training loss: 1.070\n",
      "[2, 500] training loss: 1.057\n",
      "[2, 600] training loss: 1.065\n",
      "[2, 700] training loss: 1.049\n",
      "[2, 800] training loss: 1.002\n",
      "[2, 900] training loss: 1.007\n",
      "[2, 1000] training loss: 1.028\n",
      "[2, 1100] training loss: 0.989\n",
      "[2, 1200] training loss: 1.024\n",
      "[3, 100] training loss: 0.965\n",
      "[3, 200] training loss: 0.955\n",
      "[3, 300] training loss: 0.968\n",
      "[3, 400] training loss: 0.931\n",
      "[3, 500] training loss: 0.955\n",
      "[3, 600] training loss: 0.947\n",
      "[3, 700] training loss: 0.952\n",
      "[3, 800] training loss: 0.938\n",
      "[3, 900] training loss: 0.938\n",
      "[3, 1000] training loss: 0.901\n",
      "[3, 1100] training loss: 0.893\n",
      "[3, 1200] training loss: 0.890\n",
      "[4, 100] training loss: 0.873\n",
      "[4, 200] training loss: 0.862\n",
      "[4, 300] training loss: 0.898\n",
      "[4, 400] training loss: 0.890\n",
      "[4, 500] training loss: 0.856\n",
      "[4, 600] training loss: 0.806\n",
      "[4, 700] training loss: 0.853\n",
      "[4, 800] training loss: 0.874\n",
      "[4, 900] training loss: 0.872\n",
      "[4, 1000] training loss: 0.868\n",
      "[4, 1100] training loss: 0.843\n",
      "[4, 1200] training loss: 0.832\n",
      "[5, 100] training loss: 0.864\n",
      "[5, 200] training loss: 0.803\n",
      "[5, 300] training loss: 0.787\n",
      "[5, 400] training loss: 0.808\n",
      "[5, 500] training loss: 0.788\n",
      "[5, 600] training loss: 0.825\n",
      "[5, 700] training loss: 0.816\n",
      "[5, 800] training loss: 0.768\n",
      "[5, 900] training loss: 0.810\n",
      "[5, 1000] training loss: 0.796\n",
      "[5, 1100] training loss: 0.762\n",
      "[5, 1200] training loss: 0.763\n",
      "[6, 100] training loss: 0.759\n",
      "[6, 200] training loss: 0.796\n",
      "[6, 300] training loss: 0.767\n",
      "[6, 400] training loss: 0.746\n",
      "[6, 500] training loss: 0.749\n",
      "[6, 600] training loss: 0.753\n",
      "[6, 700] training loss: 0.727\n",
      "[6, 800] training loss: 0.718\n",
      "[6, 900] training loss: 0.771\n",
      "[6, 1000] training loss: 0.768\n",
      "[6, 1100] training loss: 0.745\n",
      "[6, 1200] training loss: 0.733\n",
      "[7, 100] training loss: 0.671\n",
      "[7, 200] training loss: 0.727\n",
      "[7, 300] training loss: 0.730\n",
      "[7, 400] training loss: 0.684\n",
      "[7, 500] training loss: 0.694\n",
      "[7, 600] training loss: 0.724\n",
      "[7, 700] training loss: 0.732\n",
      "[7, 800] training loss: 0.708\n",
      "[7, 900] training loss: 0.719\n",
      "[7, 1000] training loss: 0.725\n",
      "[7, 1100] training loss: 0.709\n",
      "[7, 1200] training loss: 0.722\n",
      "[8, 100] training loss: 0.695\n",
      "[8, 200] training loss: 0.680\n",
      "[8, 300] training loss: 0.672\n",
      "[8, 400] training loss: 0.663\n",
      "[8, 500] training loss: 0.682\n",
      "[8, 600] training loss: 0.688\n",
      "[8, 700] training loss: 0.662\n",
      "[8, 800] training loss: 0.641\n",
      "[8, 900] training loss: 0.692\n",
      "[8, 1000] training loss: 0.696\n",
      "[8, 1100] training loss: 0.694\n",
      "[8, 1200] training loss: 0.671\n",
      "[9, 100] training loss: 0.636\n",
      "[9, 200] training loss: 0.676\n",
      "[9, 300] training loss: 0.618\n",
      "[9, 400] training loss: 0.631\n",
      "[9, 500] training loss: 0.633\n",
      "[9, 600] training loss: 0.644\n",
      "[9, 700] training loss: 0.655\n",
      "[9, 800] training loss: 0.644\n",
      "[9, 900] training loss: 0.627\n",
      "[9, 1000] training loss: 0.644\n",
      "[9, 1100] training loss: 0.651\n",
      "[9, 1200] training loss: 0.666\n",
      "[10, 100] training loss: 0.597\n",
      "[10, 200] training loss: 0.577\n",
      "[10, 300] training loss: 0.600\n",
      "[10, 400] training loss: 0.648\n",
      "[10, 500] training loss: 0.648\n",
      "[10, 600] training loss: 0.629\n",
      "[10, 700] training loss: 0.625\n",
      "[10, 800] training loss: 0.617\n",
      "[10, 900] training loss: 0.663\n",
      "[10, 1000] training loss: 0.599\n",
      "[10, 1100] training loss: 0.638\n",
      "[10, 1200] training loss: 0.618\n",
      "Training model with learning rate 0.001, num_epochs 10, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.689\n",
      "[1, 200] training loss: 1.430\n",
      "[1, 300] training loss: 1.311\n",
      "[1, 400] training loss: 1.229\n",
      "[1, 500] training loss: 1.160\n",
      "[1, 600] training loss: 1.101\n",
      "[2, 100] training loss: 1.074\n",
      "[2, 200] training loss: 1.034\n",
      "[2, 300] training loss: 1.020\n",
      "[2, 400] training loss: 1.015\n",
      "[2, 500] training loss: 1.011\n",
      "[2, 600] training loss: 0.949\n",
      "[3, 100] training loss: 0.948\n",
      "[3, 200] training loss: 0.895\n",
      "[3, 300] training loss: 0.906\n",
      "[3, 400] training loss: 0.870\n",
      "[3, 500] training loss: 0.904\n",
      "[3, 600] training loss: 0.851\n",
      "[4, 100] training loss: 0.852\n",
      "[4, 200] training loss: 0.841\n",
      "[4, 300] training loss: 0.840\n",
      "[4, 400] training loss: 0.836\n",
      "[4, 500] training loss: 0.821\n",
      "[4, 600] training loss: 0.802\n",
      "[5, 100] training loss: 0.768\n",
      "[5, 200] training loss: 0.789\n",
      "[5, 300] training loss: 0.780\n",
      "[5, 400] training loss: 0.772\n",
      "[5, 500] training loss: 0.759\n",
      "[5, 600] training loss: 0.745\n",
      "[6, 100] training loss: 0.701\n",
      "[6, 200] training loss: 0.743\n",
      "[6, 300] training loss: 0.733\n",
      "[6, 400] training loss: 0.739\n",
      "[6, 500] training loss: 0.714\n",
      "[6, 600] training loss: 0.714\n",
      "[7, 100] training loss: 0.676\n",
      "[7, 200] training loss: 0.690\n",
      "[7, 300] training loss: 0.661\n",
      "[7, 400] training loss: 0.709\n",
      "[7, 500] training loss: 0.673\n",
      "[7, 600] training loss: 0.686\n",
      "[8, 100] training loss: 0.642\n",
      "[8, 200] training loss: 0.667\n",
      "[8, 300] training loss: 0.670\n",
      "[8, 400] training loss: 0.640\n",
      "[8, 500] training loss: 0.657\n",
      "[8, 600] training loss: 0.656\n",
      "[9, 100] training loss: 0.625\n",
      "[9, 200] training loss: 0.639\n",
      "[9, 300] training loss: 0.612\n",
      "[9, 400] training loss: 0.627\n",
      "[9, 500] training loss: 0.627\n",
      "[9, 600] training loss: 0.600\n",
      "[10, 100] training loss: 0.607\n",
      "[10, 200] training loss: 0.599\n",
      "[10, 300] training loss: 0.611\n",
      "[10, 400] training loss: 0.579\n",
      "[10, 500] training loss: 0.603\n",
      "[10, 600] training loss: 0.594\n",
      "Training model with learning rate 0.001, num_epochs 10, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.570\n",
      "[1, 200] training loss: 1.289\n",
      "[1, 300] training loss: 1.179\n",
      "[2, 100] training loss: 1.048\n",
      "[2, 200] training loss: 1.022\n",
      "[2, 300] training loss: 0.988\n",
      "[3, 100] training loss: 0.932\n",
      "[3, 200] training loss: 0.900\n",
      "[3, 300] training loss: 0.880\n",
      "[4, 100] training loss: 0.831\n",
      "[4, 200] training loss: 0.844\n",
      "[4, 300] training loss: 0.819\n",
      "[5, 100] training loss: 0.782\n",
      "[5, 200] training loss: 0.778\n",
      "[5, 300] training loss: 0.768\n",
      "[6, 100] training loss: 0.728\n",
      "[6, 200] training loss: 0.732\n",
      "[6, 300] training loss: 0.725\n",
      "[7, 100] training loss: 0.693\n",
      "[7, 200] training loss: 0.690\n",
      "[7, 300] training loss: 0.690\n",
      "[8, 100] training loss: 0.647\n",
      "[8, 200] training loss: 0.652\n",
      "[8, 300] training loss: 0.664\n",
      "[9, 100] training loss: 0.616\n",
      "[9, 200] training loss: 0.635\n",
      "[9, 300] training loss: 0.630\n",
      "[10, 100] training loss: 0.600\n",
      "[10, 200] training loss: 0.606\n",
      "[10, 300] training loss: 0.608\n",
      "Training model with learning rate 0.001, num_epochs 15, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.866\n",
      "[1, 200] training loss: 1.609\n",
      "[1, 300] training loss: 1.540\n",
      "[1, 400] training loss: 1.428\n",
      "[1, 500] training loss: 1.373\n",
      "[1, 600] training loss: 1.336\n",
      "[1, 700] training loss: 1.283\n",
      "[1, 800] training loss: 1.243\n",
      "[1, 900] training loss: 1.252\n",
      "[1, 1000] training loss: 1.207\n",
      "[1, 1100] training loss: 1.196\n",
      "[1, 1200] training loss: 1.168\n",
      "[2, 100] training loss: 1.107\n",
      "[2, 200] training loss: 1.100\n",
      "[2, 300] training loss: 1.092\n",
      "[2, 400] training loss: 1.096\n",
      "[2, 500] training loss: 1.067\n",
      "[2, 600] training loss: 1.053\n",
      "[2, 700] training loss: 1.062\n",
      "[2, 800] training loss: 1.033\n",
      "[2, 900] training loss: 1.002\n",
      "[2, 1000] training loss: 1.061\n",
      "[2, 1100] training loss: 1.012\n",
      "[2, 1200] training loss: 1.034\n",
      "[3, 100] training loss: 0.955\n",
      "[3, 200] training loss: 0.966\n",
      "[3, 300] training loss: 0.940\n",
      "[3, 400] training loss: 0.921\n",
      "[3, 500] training loss: 0.966\n",
      "[3, 600] training loss: 0.940\n",
      "[3, 700] training loss: 0.928\n",
      "[3, 800] training loss: 0.949\n",
      "[3, 900] training loss: 0.932\n",
      "[3, 1000] training loss: 0.890\n",
      "[3, 1100] training loss: 0.935\n",
      "[3, 1200] training loss: 0.920\n",
      "[4, 100] training loss: 0.872\n",
      "[4, 200] training loss: 0.852\n",
      "[4, 300] training loss: 0.853\n",
      "[4, 400] training loss: 0.854\n",
      "[4, 500] training loss: 0.848\n",
      "[4, 600] training loss: 0.892\n",
      "[4, 700] training loss: 0.887\n",
      "[4, 800] training loss: 0.846\n",
      "[4, 900] training loss: 0.889\n",
      "[4, 1000] training loss: 0.853\n",
      "[4, 1100] training loss: 0.840\n",
      "[4, 1200] training loss: 0.823\n",
      "[5, 100] training loss: 0.803\n",
      "[5, 200] training loss: 0.792\n",
      "[5, 300] training loss: 0.798\n",
      "[5, 400] training loss: 0.837\n",
      "[5, 500] training loss: 0.813\n",
      "[5, 600] training loss: 0.798\n",
      "[5, 700] training loss: 0.799\n",
      "[5, 800] training loss: 0.766\n",
      "[5, 900] training loss: 0.799\n",
      "[5, 1000] training loss: 0.789\n",
      "[5, 1100] training loss: 0.784\n",
      "[5, 1200] training loss: 0.824\n",
      "[6, 100] training loss: 0.708\n",
      "[6, 200] training loss: 0.784\n",
      "[6, 300] training loss: 0.756\n",
      "[6, 400] training loss: 0.757\n",
      "[6, 500] training loss: 0.737\n",
      "[6, 600] training loss: 0.769\n",
      "[6, 700] training loss: 0.746\n",
      "[6, 800] training loss: 0.799\n",
      "[6, 900] training loss: 0.740\n",
      "[6, 1000] training loss: 0.750\n",
      "[6, 1100] training loss: 0.737\n",
      "[6, 1200] training loss: 0.729\n",
      "[7, 100] training loss: 0.719\n",
      "[7, 200] training loss: 0.709\n",
      "[7, 300] training loss: 0.750\n",
      "[7, 400] training loss: 0.694\n",
      "[7, 500] training loss: 0.700\n",
      "[7, 600] training loss: 0.743\n",
      "[7, 700] training loss: 0.688\n",
      "[7, 800] training loss: 0.740\n",
      "[7, 900] training loss: 0.712\n",
      "[7, 1000] training loss: 0.703\n",
      "[7, 1100] training loss: 0.768\n",
      "[7, 1200] training loss: 0.670\n",
      "[8, 100] training loss: 0.667\n",
      "[8, 200] training loss: 0.656\n",
      "[8, 300] training loss: 0.711\n",
      "[8, 400] training loss: 0.681\n",
      "[8, 500] training loss: 0.685\n",
      "[8, 600] training loss: 0.641\n",
      "[8, 700] training loss: 0.703\n",
      "[8, 800] training loss: 0.679\n",
      "[8, 900] training loss: 0.698\n",
      "[8, 1000] training loss: 0.700\n",
      "[8, 1100] training loss: 0.673\n",
      "[8, 1200] training loss: 0.701\n",
      "[9, 100] training loss: 0.658\n",
      "[9, 200] training loss: 0.655\n",
      "[9, 300] training loss: 0.612\n",
      "[9, 400] training loss: 0.684\n",
      "[9, 500] training loss: 0.642\n",
      "[9, 600] training loss: 0.632\n",
      "[9, 700] training loss: 0.679\n",
      "[9, 800] training loss: 0.631\n",
      "[9, 900] training loss: 0.643\n",
      "[9, 1000] training loss: 0.680\n",
      "[9, 1100] training loss: 0.656\n",
      "[9, 1200] training loss: 0.648\n",
      "[10, 100] training loss: 0.656\n",
      "[10, 200] training loss: 0.639\n",
      "[10, 300] training loss: 0.602\n",
      "[10, 400] training loss: 0.608\n",
      "[10, 500] training loss: 0.609\n",
      "[10, 600] training loss: 0.603\n",
      "[10, 700] training loss: 0.611\n",
      "[10, 800] training loss: 0.608\n",
      "[10, 900] training loss: 0.617\n",
      "[10, 1000] training loss: 0.602\n",
      "[10, 1100] training loss: 0.615\n",
      "[10, 1200] training loss: 0.623\n",
      "[11, 100] training loss: 0.551\n",
      "[11, 200] training loss: 0.593\n",
      "[11, 300] training loss: 0.560\n",
      "[11, 400] training loss: 0.590\n",
      "[11, 500] training loss: 0.589\n",
      "[11, 600] training loss: 0.620\n",
      "[11, 700] training loss: 0.583\n",
      "[11, 800] training loss: 0.587\n",
      "[11, 900] training loss: 0.608\n",
      "[11, 1000] training loss: 0.605\n",
      "[11, 1100] training loss: 0.613\n",
      "[11, 1200] training loss: 0.609\n",
      "[12, 100] training loss: 0.572\n",
      "[12, 200] training loss: 0.611\n",
      "[12, 300] training loss: 0.583\n",
      "[12, 400] training loss: 0.583\n",
      "[12, 500] training loss: 0.563\n",
      "[12, 600] training loss: 0.579\n",
      "[12, 700] training loss: 0.584\n",
      "[12, 800] training loss: 0.593\n",
      "[12, 900] training loss: 0.565\n",
      "[12, 1000] training loss: 0.575\n",
      "[12, 1100] training loss: 0.561\n",
      "[12, 1200] training loss: 0.575\n",
      "[13, 100] training loss: 0.536\n",
      "[13, 200] training loss: 0.560\n",
      "[13, 300] training loss: 0.561\n",
      "[13, 400] training loss: 0.564\n",
      "[13, 500] training loss: 0.565\n",
      "[13, 600] training loss: 0.568\n",
      "[13, 700] training loss: 0.532\n",
      "[13, 800] training loss: 0.566\n",
      "[13, 900] training loss: 0.598\n",
      "[13, 1000] training loss: 0.518\n",
      "[13, 1100] training loss: 0.589\n",
      "[13, 1200] training loss: 0.549\n",
      "[14, 100] training loss: 0.549\n",
      "[14, 200] training loss: 0.529\n",
      "[14, 300] training loss: 0.544\n",
      "[14, 400] training loss: 0.543\n",
      "[14, 500] training loss: 0.534\n",
      "[14, 600] training loss: 0.524\n",
      "[14, 700] training loss: 0.520\n",
      "[14, 800] training loss: 0.520\n",
      "[14, 900] training loss: 0.548\n",
      "[14, 1000] training loss: 0.538\n",
      "[14, 1100] training loss: 0.551\n",
      "[14, 1200] training loss: 0.512\n",
      "[15, 100] training loss: 0.507\n",
      "[15, 200] training loss: 0.503\n",
      "[15, 300] training loss: 0.529\n",
      "[15, 400] training loss: 0.500\n",
      "[15, 500] training loss: 0.518\n",
      "[15, 600] training loss: 0.508\n",
      "[15, 700] training loss: 0.528\n",
      "[15, 800] training loss: 0.525\n",
      "[15, 900] training loss: 0.522\n",
      "[15, 1000] training loss: 0.536\n",
      "[15, 1100] training loss: 0.532\n",
      "[15, 1200] training loss: 0.489\n",
      "Training model with learning rate 0.001, num_epochs 15, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.699\n",
      "[1, 200] training loss: 1.429\n",
      "[1, 300] training loss: 1.304\n",
      "[1, 400] training loss: 1.240\n",
      "[1, 500] training loss: 1.176\n",
      "[1, 600] training loss: 1.149\n",
      "[2, 100] training loss: 1.073\n",
      "[2, 200] training loss: 1.052\n",
      "[2, 300] training loss: 1.042\n",
      "[2, 400] training loss: 0.983\n",
      "[2, 500] training loss: 0.984\n",
      "[2, 600] training loss: 0.990\n",
      "[3, 100] training loss: 0.924\n",
      "[3, 200] training loss: 0.936\n",
      "[3, 300] training loss: 0.939\n",
      "[3, 400] training loss: 0.883\n",
      "[3, 500] training loss: 0.901\n",
      "[3, 600] training loss: 0.888\n",
      "[4, 100] training loss: 0.833\n",
      "[4, 200] training loss: 0.833\n",
      "[4, 300] training loss: 0.826\n",
      "[4, 400] training loss: 0.845\n",
      "[4, 500] training loss: 0.829\n",
      "[4, 600] training loss: 0.828\n",
      "[5, 100] training loss: 0.793\n",
      "[5, 200] training loss: 0.769\n",
      "[5, 300] training loss: 0.773\n",
      "[5, 400] training loss: 0.777\n",
      "[5, 500] training loss: 0.776\n",
      "[5, 600] training loss: 0.748\n",
      "[6, 100] training loss: 0.740\n",
      "[6, 200] training loss: 0.729\n",
      "[6, 300] training loss: 0.733\n",
      "[6, 400] training loss: 0.713\n",
      "[6, 500] training loss: 0.710\n",
      "[6, 600] training loss: 0.747\n",
      "[7, 100] training loss: 0.705\n",
      "[7, 200] training loss: 0.696\n",
      "[7, 300] training loss: 0.711\n",
      "[7, 400] training loss: 0.706\n",
      "[7, 500] training loss: 0.684\n",
      "[7, 600] training loss: 0.687\n",
      "[8, 100] training loss: 0.645\n",
      "[8, 200] training loss: 0.686\n",
      "[8, 300] training loss: 0.665\n",
      "[8, 400] training loss: 0.667\n",
      "[8, 500] training loss: 0.652\n",
      "[8, 600] training loss: 0.652\n",
      "[9, 100] training loss: 0.612\n",
      "[9, 200] training loss: 0.640\n",
      "[9, 300] training loss: 0.624\n",
      "[9, 400] training loss: 0.621\n",
      "[9, 500] training loss: 0.640\n",
      "[9, 600] training loss: 0.620\n",
      "[10, 100] training loss: 0.602\n",
      "[10, 200] training loss: 0.594\n",
      "[10, 300] training loss: 0.629\n",
      "[10, 400] training loss: 0.609\n",
      "[10, 500] training loss: 0.601\n",
      "[10, 600] training loss: 0.595\n",
      "[11, 100] training loss: 0.565\n",
      "[11, 200] training loss: 0.576\n",
      "[11, 300] training loss: 0.585\n",
      "[11, 400] training loss: 0.590\n",
      "[11, 500] training loss: 0.599\n",
      "[11, 600] training loss: 0.547\n",
      "[12, 100] training loss: 0.551\n",
      "[12, 200] training loss: 0.565\n",
      "[12, 300] training loss: 0.555\n",
      "[12, 400] training loss: 0.562\n",
      "[12, 500] training loss: 0.558\n",
      "[12, 600] training loss: 0.534\n",
      "[13, 100] training loss: 0.527\n",
      "[13, 200] training loss: 0.530\n",
      "[13, 300] training loss: 0.525\n",
      "[13, 400] training loss: 0.540\n",
      "[13, 500] training loss: 0.547\n",
      "[13, 600] training loss: 0.516\n",
      "[14, 100] training loss: 0.506\n",
      "[14, 200] training loss: 0.487\n",
      "[14, 300] training loss: 0.521\n",
      "[14, 400] training loss: 0.519\n",
      "[14, 500] training loss: 0.503\n",
      "[14, 600] training loss: 0.524\n",
      "[15, 100] training loss: 0.449\n",
      "[15, 200] training loss: 0.501\n",
      "[15, 300] training loss: 0.519\n",
      "[15, 400] training loss: 0.498\n",
      "[15, 500] training loss: 0.499\n",
      "[15, 600] training loss: 0.529\n",
      "Training model with learning rate 0.001, num_epochs 15, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.586\n",
      "[1, 200] training loss: 1.285\n",
      "[1, 300] training loss: 1.189\n",
      "[2, 100] training loss: 1.063\n",
      "[2, 200] training loss: 1.042\n",
      "[2, 300] training loss: 0.990\n",
      "[3, 100] training loss: 0.930\n",
      "[3, 200] training loss: 0.935\n",
      "[3, 300] training loss: 0.880\n",
      "[4, 100] training loss: 0.850\n",
      "[4, 200] training loss: 0.853\n",
      "[4, 300] training loss: 0.824\n",
      "[5, 100] training loss: 0.781\n",
      "[5, 200] training loss: 0.787\n",
      "[5, 300] training loss: 0.776\n",
      "[6, 100] training loss: 0.723\n",
      "[6, 200] training loss: 0.752\n",
      "[6, 300] training loss: 0.735\n",
      "[7, 100] training loss: 0.705\n",
      "[7, 200] training loss: 0.698\n",
      "[7, 300] training loss: 0.691\n",
      "[8, 100] training loss: 0.661\n",
      "[8, 200] training loss: 0.666\n",
      "[8, 300] training loss: 0.652\n",
      "[9, 100] training loss: 0.617\n",
      "[9, 200] training loss: 0.648\n",
      "[9, 300] training loss: 0.631\n",
      "[10, 100] training loss: 0.613\n",
      "[10, 200] training loss: 0.611\n",
      "[10, 300] training loss: 0.608\n",
      "[11, 100] training loss: 0.570\n",
      "[11, 200] training loss: 0.608\n",
      "[11, 300] training loss: 0.583\n",
      "[12, 100] training loss: 0.556\n",
      "[12, 200] training loss: 0.564\n",
      "[12, 300] training loss: 0.564\n",
      "[13, 100] training loss: 0.539\n",
      "[13, 200] training loss: 0.538\n",
      "[13, 300] training loss: 0.550\n",
      "[14, 100] training loss: 0.507\n",
      "[14, 200] training loss: 0.521\n",
      "[14, 300] training loss: 0.533\n",
      "[15, 100] training loss: 0.492\n",
      "[15, 200] training loss: 0.506\n",
      "[15, 300] training loss: 0.518\n",
      "Training model with learning rate 0.01, num_epochs 5, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.156\n",
      "[1, 200] training loss: 1.767\n",
      "[1, 300] training loss: 1.653\n",
      "[1, 400] training loss: 1.574\n",
      "[1, 500] training loss: 1.540\n",
      "[1, 600] training loss: 1.479\n",
      "[1, 700] training loss: 1.476\n",
      "[1, 800] training loss: 1.393\n",
      "[1, 900] training loss: 1.360\n",
      "[1, 1000] training loss: 1.364\n",
      "[1, 1100] training loss: 1.310\n",
      "[1, 1200] training loss: 1.298\n",
      "[2, 100] training loss: 1.219\n",
      "[2, 200] training loss: 1.245\n",
      "[2, 300] training loss: 1.244\n",
      "[2, 400] training loss: 1.224\n",
      "[2, 500] training loss: 1.204\n",
      "[2, 600] training loss: 1.158\n",
      "[2, 700] training loss: 1.166\n",
      "[2, 800] training loss: 1.138\n",
      "[2, 900] training loss: 1.170\n",
      "[2, 1000] training loss: 1.106\n",
      "[2, 1100] training loss: 1.096\n",
      "[2, 1200] training loss: 1.095\n",
      "[3, 100] training loss: 1.096\n",
      "[3, 200] training loss: 1.066\n",
      "[3, 300] training loss: 1.076\n",
      "[3, 400] training loss: 1.058\n",
      "[3, 500] training loss: 1.011\n",
      "[3, 600] training loss: 1.017\n",
      "[3, 700] training loss: 1.019\n",
      "[3, 800] training loss: 1.030\n",
      "[3, 900] training loss: 1.068\n",
      "[3, 1000] training loss: 0.988\n",
      "[3, 1100] training loss: 1.018\n",
      "[3, 1200] training loss: 1.018\n",
      "[4, 100] training loss: 0.999\n",
      "[4, 200] training loss: 0.944\n",
      "[4, 300] training loss: 0.989\n",
      "[4, 400] training loss: 0.984\n",
      "[4, 500] training loss: 0.963\n",
      "[4, 600] training loss: 0.971\n",
      "[4, 700] training loss: 0.986\n",
      "[4, 800] training loss: 0.965\n",
      "[4, 900] training loss: 0.907\n",
      "[4, 1000] training loss: 0.930\n",
      "[4, 1100] training loss: 0.929\n",
      "[4, 1200] training loss: 0.967\n",
      "[5, 100] training loss: 0.935\n",
      "[5, 200] training loss: 0.920\n",
      "[5, 300] training loss: 0.875\n",
      "[5, 400] training loss: 0.875\n",
      "[5, 500] training loss: 0.890\n",
      "[5, 600] training loss: 0.877\n",
      "[5, 700] training loss: 0.898\n",
      "[5, 800] training loss: 0.937\n",
      "[5, 900] training loss: 0.940\n",
      "[5, 1000] training loss: 0.916\n",
      "[5, 1100] training loss: 0.910\n",
      "[5, 1200] training loss: 0.851\n",
      "Training model with learning rate 0.01, num_epochs 5, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.916\n",
      "[1, 200] training loss: 1.588\n",
      "[1, 300] training loss: 1.459\n",
      "[1, 400] training loss: 1.386\n",
      "[1, 500] training loss: 1.297\n",
      "[1, 600] training loss: 1.276\n",
      "[2, 100] training loss: 1.180\n",
      "[2, 200] training loss: 1.169\n",
      "[2, 300] training loss: 1.131\n",
      "[2, 400] training loss: 1.071\n",
      "[2, 500] training loss: 1.071\n",
      "[2, 600] training loss: 1.059\n",
      "[3, 100] training loss: 1.004\n",
      "[3, 200] training loss: 1.015\n",
      "[3, 300] training loss: 0.976\n",
      "[3, 400] training loss: 0.982\n",
      "[3, 500] training loss: 0.942\n",
      "[3, 600] training loss: 0.952\n",
      "[4, 100] training loss: 0.898\n",
      "[4, 200] training loss: 0.897\n",
      "[4, 300] training loss: 0.889\n",
      "[4, 400] training loss: 0.924\n",
      "[4, 500] training loss: 0.892\n",
      "[4, 600] training loss: 0.852\n",
      "[5, 100] training loss: 0.840\n",
      "[5, 200] training loss: 0.842\n",
      "[5, 300] training loss: 0.821\n",
      "[5, 400] training loss: 0.845\n",
      "[5, 500] training loss: 0.834\n",
      "[5, 600] training loss: 0.846\n",
      "Training model with learning rate 0.01, num_epochs 5, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.762\n",
      "[1, 200] training loss: 1.422\n",
      "[1, 300] training loss: 1.290\n",
      "[2, 100] training loss: 1.164\n",
      "[2, 200] training loss: 1.082\n",
      "[2, 300] training loss: 1.039\n",
      "[3, 100] training loss: 0.996\n",
      "[3, 200] training loss: 0.932\n",
      "[3, 300] training loss: 0.921\n",
      "[4, 100] training loss: 0.873\n",
      "[4, 200] training loss: 0.864\n",
      "[4, 300] training loss: 0.861\n",
      "[5, 100] training loss: 0.801\n",
      "[5, 200] training loss: 0.816\n",
      "[5, 300] training loss: 0.791\n",
      "Training model with learning rate 0.01, num_epochs 10, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.136\n",
      "[1, 200] training loss: 1.791\n",
      "[1, 300] training loss: 1.633\n",
      "[1, 400] training loss: 1.576\n",
      "[1, 500] training loss: 1.511\n",
      "[1, 600] training loss: 1.450\n",
      "[1, 700] training loss: 1.463\n",
      "[1, 800] training loss: 1.427\n",
      "[1, 900] training loss: 1.356\n",
      "[1, 1000] training loss: 1.322\n",
      "[1, 1100] training loss: 1.308\n",
      "[1, 1200] training loss: 1.272\n",
      "[2, 100] training loss: 1.231\n",
      "[2, 200] training loss: 1.209\n",
      "[2, 300] training loss: 1.208\n",
      "[2, 400] training loss: 1.235\n",
      "[2, 500] training loss: 1.183\n",
      "[2, 600] training loss: 1.168\n",
      "[2, 700] training loss: 1.147\n",
      "[2, 800] training loss: 1.143\n",
      "[2, 900] training loss: 1.123\n",
      "[2, 1000] training loss: 1.139\n",
      "[2, 1100] training loss: 1.103\n",
      "[2, 1200] training loss: 1.147\n",
      "[3, 100] training loss: 1.079\n",
      "[3, 200] training loss: 1.053\n",
      "[3, 300] training loss: 1.066\n",
      "[3, 400] training loss: 1.049\n",
      "[3, 500] training loss: 1.061\n",
      "[3, 600] training loss: 1.039\n",
      "[3, 700] training loss: 1.080\n",
      "[3, 800] training loss: 1.030\n",
      "[3, 900] training loss: 1.024\n",
      "[3, 1000] training loss: 0.998\n",
      "[3, 1100] training loss: 1.008\n",
      "[3, 1200] training loss: 0.996\n",
      "[4, 100] training loss: 1.003\n",
      "[4, 200] training loss: 0.976\n",
      "[4, 300] training loss: 1.000\n",
      "[4, 400] training loss: 0.949\n",
      "[4, 500] training loss: 0.970\n",
      "[4, 600] training loss: 0.940\n",
      "[4, 700] training loss: 0.968\n",
      "[4, 800] training loss: 0.990\n",
      "[4, 900] training loss: 0.977\n",
      "[4, 1000] training loss: 0.997\n",
      "[4, 1100] training loss: 0.939\n",
      "[4, 1200] training loss: 0.932\n",
      "[5, 100] training loss: 0.916\n",
      "[5, 200] training loss: 0.939\n",
      "[5, 300] training loss: 0.874\n",
      "[5, 400] training loss: 0.943\n",
      "[5, 500] training loss: 0.926\n",
      "[5, 600] training loss: 0.906\n",
      "[5, 700] training loss: 0.886\n",
      "[5, 800] training loss: 0.929\n",
      "[5, 900] training loss: 0.952\n",
      "[5, 1000] training loss: 0.909\n",
      "[5, 1100] training loss: 0.912\n",
      "[5, 1200] training loss: 0.895\n",
      "[6, 100] training loss: 0.859\n",
      "[6, 200] training loss: 0.895\n",
      "[6, 300] training loss: 0.895\n",
      "[6, 400] training loss: 0.850\n",
      "[6, 500] training loss: 0.836\n",
      "[6, 600] training loss: 0.874\n",
      "[6, 700] training loss: 0.924\n",
      "[6, 800] training loss: 0.857\n",
      "[6, 900] training loss: 0.860\n",
      "[6, 1000] training loss: 0.875\n",
      "[6, 1100] training loss: 0.847\n",
      "[6, 1200] training loss: 0.856\n",
      "[7, 100] training loss: 0.879\n",
      "[7, 200] training loss: 0.884\n",
      "[7, 300] training loss: 0.811\n",
      "[7, 400] training loss: 0.825\n",
      "[7, 500] training loss: 0.851\n",
      "[7, 600] training loss: 0.819\n",
      "[7, 700] training loss: 0.823\n",
      "[7, 800] training loss: 0.854\n",
      "[7, 900] training loss: 0.842\n",
      "[7, 1000] training loss: 0.805\n",
      "[7, 1100] training loss: 0.838\n",
      "[7, 1200] training loss: 0.846\n",
      "[8, 100] training loss: 0.756\n",
      "[8, 200] training loss: 0.820\n",
      "[8, 300] training loss: 0.815\n",
      "[8, 400] training loss: 0.785\n",
      "[8, 500] training loss: 0.835\n",
      "[8, 600] training loss: 0.851\n",
      "[8, 700] training loss: 0.817\n",
      "[8, 800] training loss: 0.804\n",
      "[8, 900] training loss: 0.763\n",
      "[8, 1000] training loss: 0.798\n",
      "[8, 1100] training loss: 0.798\n",
      "[8, 1200] training loss: 0.786\n",
      "[9, 100] training loss: 0.759\n",
      "[9, 200] training loss: 0.739\n",
      "[9, 300] training loss: 0.763\n",
      "[9, 400] training loss: 0.786\n",
      "[9, 500] training loss: 0.804\n",
      "[9, 600] training loss: 0.807\n",
      "[9, 700] training loss: 0.774\n",
      "[9, 800] training loss: 0.786\n",
      "[9, 900] training loss: 0.809\n",
      "[9, 1000] training loss: 0.775\n",
      "[9, 1100] training loss: 0.793\n",
      "[9, 1200] training loss: 0.777\n",
      "[10, 100] training loss: 0.715\n",
      "[10, 200] training loss: 0.786\n",
      "[10, 300] training loss: 0.748\n",
      "[10, 400] training loss: 0.724\n",
      "[10, 500] training loss: 0.767\n",
      "[10, 600] training loss: 0.755\n",
      "[10, 700] training loss: 0.773\n",
      "[10, 800] training loss: 0.749\n",
      "[10, 900] training loss: 0.771\n",
      "[10, 1000] training loss: 0.763\n",
      "[10, 1100] training loss: 0.738\n",
      "[10, 1200] training loss: 0.711\n",
      "Training model with learning rate 0.01, num_epochs 10, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.971\n",
      "[1, 200] training loss: 1.598\n",
      "[1, 300] training loss: 1.466\n",
      "[1, 400] training loss: 1.404\n",
      "[1, 500] training loss: 1.327\n",
      "[1, 600] training loss: 1.274\n",
      "[2, 100] training loss: 1.186\n",
      "[2, 200] training loss: 1.204\n",
      "[2, 300] training loss: 1.120\n",
      "[2, 400] training loss: 1.129\n",
      "[2, 500] training loss: 1.067\n",
      "[2, 600] training loss: 1.037\n",
      "[3, 100] training loss: 1.017\n",
      "[3, 200] training loss: 0.996\n",
      "[3, 300] training loss: 0.980\n",
      "[3, 400] training loss: 0.994\n",
      "[3, 500] training loss: 0.958\n",
      "[3, 600] training loss: 0.938\n",
      "[4, 100] training loss: 0.903\n",
      "[4, 200] training loss: 0.917\n",
      "[4, 300] training loss: 0.902\n",
      "[4, 400] training loss: 0.874\n",
      "[4, 500] training loss: 0.892\n",
      "[4, 600] training loss: 0.879\n",
      "[5, 100] training loss: 0.814\n",
      "[5, 200] training loss: 0.848\n",
      "[5, 300] training loss: 0.851\n",
      "[5, 400] training loss: 0.849\n",
      "[5, 500] training loss: 0.816\n",
      "[5, 600] training loss: 0.822\n",
      "[6, 100] training loss: 0.773\n",
      "[6, 200] training loss: 0.792\n",
      "[6, 300] training loss: 0.803\n",
      "[6, 400] training loss: 0.803\n",
      "[6, 500] training loss: 0.790\n",
      "[6, 600] training loss: 0.784\n",
      "[7, 100] training loss: 0.718\n",
      "[7, 200] training loss: 0.786\n",
      "[7, 300] training loss: 0.752\n",
      "[7, 400] training loss: 0.747\n",
      "[7, 500] training loss: 0.734\n",
      "[7, 600] training loss: 0.742\n",
      "[8, 100] training loss: 0.716\n",
      "[8, 200] training loss: 0.727\n",
      "[8, 300] training loss: 0.712\n",
      "[8, 400] training loss: 0.719\n",
      "[8, 500] training loss: 0.734\n",
      "[8, 600] training loss: 0.712\n",
      "[9, 100] training loss: 0.703\n",
      "[9, 200] training loss: 0.687\n",
      "[9, 300] training loss: 0.696\n",
      "[9, 400] training loss: 0.689\n",
      "[9, 500] training loss: 0.673\n",
      "[9, 600] training loss: 0.710\n",
      "[10, 100] training loss: 0.658\n",
      "[10, 200] training loss: 0.650\n",
      "[10, 300] training loss: 0.675\n",
      "[10, 400] training loss: 0.664\n",
      "[10, 500] training loss: 0.686\n",
      "[10, 600] training loss: 0.671\n",
      "Training model with learning rate 0.01, num_epochs 10, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.788\n",
      "[1, 200] training loss: 1.463\n",
      "[1, 300] training loss: 1.328\n",
      "[2, 100] training loss: 1.153\n",
      "[2, 200] training loss: 1.131\n",
      "[2, 300] training loss: 1.065\n",
      "[3, 100] training loss: 0.989\n",
      "[3, 200] training loss: 0.964\n",
      "[3, 300] training loss: 0.925\n",
      "[4, 100] training loss: 0.879\n",
      "[4, 200] training loss: 0.857\n",
      "[4, 300] training loss: 0.853\n",
      "[5, 100] training loss: 0.812\n",
      "[5, 200] training loss: 0.798\n",
      "[5, 300] training loss: 0.793\n",
      "[6, 100] training loss: 0.756\n",
      "[6, 200] training loss: 0.763\n",
      "[6, 300] training loss: 0.740\n",
      "[7, 100] training loss: 0.723\n",
      "[7, 200] training loss: 0.705\n",
      "[7, 300] training loss: 0.712\n",
      "[8, 100] training loss: 0.680\n",
      "[8, 200] training loss: 0.671\n",
      "[8, 300] training loss: 0.677\n",
      "[9, 100] training loss: 0.629\n",
      "[9, 200] training loss: 0.652\n",
      "[9, 300] training loss: 0.655\n",
      "[10, 100] training loss: 0.618\n",
      "[10, 200] training loss: 0.614\n",
      "[10, 300] training loss: 0.620\n",
      "Training model with learning rate 0.01, num_epochs 15, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.156\n",
      "[1, 200] training loss: 1.720\n",
      "[1, 300] training loss: 1.615\n",
      "[1, 400] training loss: 1.561\n",
      "[1, 500] training loss: 1.506\n",
      "[1, 600] training loss: 1.491\n",
      "[1, 700] training loss: 1.435\n",
      "[1, 800] training loss: 1.377\n",
      "[1, 900] training loss: 1.399\n",
      "[1, 1000] training loss: 1.355\n",
      "[1, 1100] training loss: 1.315\n",
      "[1, 1200] training loss: 1.299\n",
      "[2, 100] training loss: 1.242\n",
      "[2, 200] training loss: 1.263\n",
      "[2, 300] training loss: 1.209\n",
      "[2, 400] training loss: 1.196\n",
      "[2, 500] training loss: 1.205\n",
      "[2, 600] training loss: 1.197\n",
      "[2, 700] training loss: 1.166\n",
      "[2, 800] training loss: 1.196\n",
      "[2, 900] training loss: 1.143\n",
      "[2, 1000] training loss: 1.145\n",
      "[2, 1100] training loss: 1.109\n",
      "[2, 1200] training loss: 1.109\n",
      "[3, 100] training loss: 1.084\n",
      "[3, 200] training loss: 1.081\n",
      "[3, 300] training loss: 1.057\n",
      "[3, 400] training loss: 1.074\n",
      "[3, 500] training loss: 1.079\n",
      "[3, 600] training loss: 1.065\n",
      "[3, 700] training loss: 1.089\n",
      "[3, 800] training loss: 1.068\n",
      "[3, 900] training loss: 1.008\n",
      "[3, 1000] training loss: 1.053\n",
      "[3, 1100] training loss: 1.019\n",
      "[3, 1200] training loss: 1.026\n",
      "[4, 100] training loss: 0.994\n",
      "[4, 200] training loss: 0.991\n",
      "[4, 300] training loss: 0.977\n",
      "[4, 400] training loss: 1.026\n",
      "[4, 500] training loss: 0.959\n",
      "[4, 600] training loss: 0.969\n",
      "[4, 700] training loss: 0.985\n",
      "[4, 800] training loss: 0.932\n",
      "[4, 900] training loss: 0.990\n",
      "[4, 1000] training loss: 0.965\n",
      "[4, 1100] training loss: 0.988\n",
      "[4, 1200] training loss: 0.960\n",
      "[5, 100] training loss: 0.954\n",
      "[5, 200] training loss: 0.957\n",
      "[5, 300] training loss: 0.930\n",
      "[5, 400] training loss: 0.919\n",
      "[5, 500] training loss: 0.941\n",
      "[5, 600] training loss: 0.913\n",
      "[5, 700] training loss: 0.924\n",
      "[5, 800] training loss: 0.932\n",
      "[5, 900] training loss: 0.934\n",
      "[5, 1000] training loss: 0.920\n",
      "[5, 1100] training loss: 0.886\n",
      "[5, 1200] training loss: 0.905\n",
      "[6, 100] training loss: 0.871\n",
      "[6, 200] training loss: 0.889\n",
      "[6, 300] training loss: 0.888\n",
      "[6, 400] training loss: 0.895\n",
      "[6, 500] training loss: 0.853\n",
      "[6, 600] training loss: 0.899\n",
      "[6, 700] training loss: 0.886\n",
      "[6, 800] training loss: 0.860\n",
      "[6, 900] training loss: 0.848\n",
      "[6, 1000] training loss: 0.912\n",
      "[6, 1100] training loss: 0.864\n",
      "[6, 1200] training loss: 0.862\n",
      "[7, 100] training loss: 0.861\n",
      "[7, 200] training loss: 0.823\n",
      "[7, 300] training loss: 0.817\n",
      "[7, 400] training loss: 0.816\n",
      "[7, 500] training loss: 0.875\n",
      "[7, 600] training loss: 0.807\n",
      "[7, 700] training loss: 0.840\n",
      "[7, 800] training loss: 0.845\n",
      "[7, 900] training loss: 0.858\n",
      "[7, 1000] training loss: 0.851\n",
      "[7, 1100] training loss: 0.839\n",
      "[7, 1200] training loss: 0.852\n",
      "[8, 100] training loss: 0.802\n",
      "[8, 200] training loss: 0.841\n",
      "[8, 300] training loss: 0.805\n",
      "[8, 400] training loss: 0.787\n",
      "[8, 500] training loss: 0.802\n",
      "[8, 600] training loss: 0.799\n",
      "[8, 700] training loss: 0.792\n",
      "[8, 800] training loss: 0.793\n",
      "[8, 900] training loss: 0.811\n",
      "[8, 1000] training loss: 0.813\n",
      "[8, 1100] training loss: 0.775\n",
      "[8, 1200] training loss: 0.857\n",
      "[9, 100] training loss: 0.753\n",
      "[9, 200] training loss: 0.814\n",
      "[9, 300] training loss: 0.802\n",
      "[9, 400] training loss: 0.741\n",
      "[9, 500] training loss: 0.759\n",
      "[9, 600] training loss: 0.822\n",
      "[9, 700] training loss: 0.747\n",
      "[9, 800] training loss: 0.784\n",
      "[9, 900] training loss: 0.816\n",
      "[9, 1000] training loss: 0.772\n",
      "[9, 1100] training loss: 0.776\n",
      "[9, 1200] training loss: 0.797\n",
      "[10, 100] training loss: 0.728\n",
      "[10, 200] training loss: 0.764\n",
      "[10, 300] training loss: 0.768\n",
      "[10, 400] training loss: 0.740\n",
      "[10, 500] training loss: 0.773\n",
      "[10, 600] training loss: 0.732\n",
      "[10, 700] training loss: 0.767\n",
      "[10, 800] training loss: 0.757\n",
      "[10, 900] training loss: 0.772\n",
      "[10, 1000] training loss: 0.757\n",
      "[10, 1100] training loss: 0.806\n",
      "[10, 1200] training loss: 0.776\n",
      "[11, 100] training loss: 0.707\n",
      "[11, 200] training loss: 0.742\n",
      "[11, 300] training loss: 0.778\n",
      "[11, 400] training loss: 0.719\n",
      "[11, 500] training loss: 0.749\n",
      "[11, 600] training loss: 0.717\n",
      "[11, 700] training loss: 0.784\n",
      "[11, 800] training loss: 0.728\n",
      "[11, 900] training loss: 0.732\n",
      "[11, 1000] training loss: 0.715\n",
      "[11, 1100] training loss: 0.741\n",
      "[11, 1200] training loss: 0.744\n",
      "[12, 100] training loss: 0.721\n",
      "[12, 200] training loss: 0.691\n",
      "[12, 300] training loss: 0.712\n",
      "[12, 400] training loss: 0.712\n",
      "[12, 500] training loss: 0.718\n",
      "[12, 600] training loss: 0.702\n",
      "[12, 700] training loss: 0.742\n",
      "[12, 800] training loss: 0.690\n",
      "[12, 900] training loss: 0.741\n",
      "[12, 1000] training loss: 0.747\n",
      "[12, 1100] training loss: 0.716\n",
      "[12, 1200] training loss: 0.749\n",
      "[13, 100] training loss: 0.697\n",
      "[13, 200] training loss: 0.702\n",
      "[13, 300] training loss: 0.672\n",
      "[13, 400] training loss: 0.745\n",
      "[13, 500] training loss: 0.710\n",
      "[13, 600] training loss: 0.712\n",
      "[13, 700] training loss: 0.710\n",
      "[13, 800] training loss: 0.705\n",
      "[13, 900] training loss: 0.694\n",
      "[13, 1000] training loss: 0.704\n",
      "[13, 1100] training loss: 0.672\n",
      "[13, 1200] training loss: 0.693\n",
      "[14, 100] training loss: 0.648\n",
      "[14, 200] training loss: 0.687\n",
      "[14, 300] training loss: 0.691\n",
      "[14, 400] training loss: 0.692\n",
      "[14, 500] training loss: 0.659\n",
      "[14, 600] training loss: 0.685\n",
      "[14, 700] training loss: 0.676\n",
      "[14, 800] training loss: 0.692\n",
      "[14, 900] training loss: 0.714\n",
      "[14, 1000] training loss: 0.655\n",
      "[14, 1100] training loss: 0.670\n",
      "[14, 1200] training loss: 0.681\n",
      "[15, 100] training loss: 0.673\n",
      "[15, 200] training loss: 0.649\n",
      "[15, 300] training loss: 0.684\n",
      "[15, 400] training loss: 0.683\n",
      "[15, 500] training loss: 0.662\n",
      "[15, 600] training loss: 0.675\n",
      "[15, 700] training loss: 0.665\n",
      "[15, 800] training loss: 0.727\n",
      "[15, 900] training loss: 0.637\n",
      "[15, 1000] training loss: 0.656\n",
      "[15, 1100] training loss: 0.665\n",
      "[15, 1200] training loss: 0.699\n",
      "Training model with learning rate 0.01, num_epochs 15, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.902\n",
      "[1, 200] training loss: 1.578\n",
      "[1, 300] training loss: 1.480\n",
      "[1, 400] training loss: 1.385\n",
      "[1, 500] training loss: 1.297\n",
      "[1, 600] training loss: 1.242\n",
      "[2, 100] training loss: 1.187\n",
      "[2, 200] training loss: 1.167\n",
      "[2, 300] training loss: 1.110\n",
      "[2, 400] training loss: 1.089\n",
      "[2, 500] training loss: 1.072\n",
      "[2, 600] training loss: 1.043\n",
      "[3, 100] training loss: 0.985\n",
      "[3, 200] training loss: 1.017\n",
      "[3, 300] training loss: 0.993\n",
      "[3, 400] training loss: 0.958\n",
      "[3, 500] training loss: 0.964\n",
      "[3, 600] training loss: 0.928\n",
      "[4, 100] training loss: 0.909\n",
      "[4, 200] training loss: 0.914\n",
      "[4, 300] training loss: 0.886\n",
      "[4, 400] training loss: 0.920\n",
      "[4, 500] training loss: 0.860\n",
      "[4, 600] training loss: 0.924\n",
      "[5, 100] training loss: 0.857\n",
      "[5, 200] training loss: 0.850\n",
      "[5, 300] training loss: 0.824\n",
      "[5, 400] training loss: 0.855\n",
      "[5, 500] training loss: 0.846\n",
      "[5, 600] training loss: 0.823\n",
      "[6, 100] training loss: 0.760\n",
      "[6, 200] training loss: 0.795\n",
      "[6, 300] training loss: 0.810\n",
      "[6, 400] training loss: 0.779\n",
      "[6, 500] training loss: 0.794\n",
      "[6, 600] training loss: 0.789\n",
      "[7, 100] training loss: 0.736\n",
      "[7, 200] training loss: 0.732\n",
      "[7, 300] training loss: 0.768\n",
      "[7, 400] training loss: 0.761\n",
      "[7, 500] training loss: 0.733\n",
      "[7, 600] training loss: 0.732\n",
      "[8, 100] training loss: 0.719\n",
      "[8, 200] training loss: 0.700\n",
      "[8, 300] training loss: 0.718\n",
      "[8, 400] training loss: 0.741\n",
      "[8, 500] training loss: 0.726\n",
      "[8, 600] training loss: 0.735\n",
      "[9, 100] training loss: 0.695\n",
      "[9, 200] training loss: 0.670\n",
      "[9, 300] training loss: 0.675\n",
      "[9, 400] training loss: 0.707\n",
      "[9, 500] training loss: 0.684\n",
      "[9, 600] training loss: 0.687\n",
      "[10, 100] training loss: 0.670\n",
      "[10, 200] training loss: 0.657\n",
      "[10, 300] training loss: 0.669\n",
      "[10, 400] training loss: 0.666\n",
      "[10, 500] training loss: 0.656\n",
      "[10, 600] training loss: 0.680\n",
      "[11, 100] training loss: 0.621\n",
      "[11, 200] training loss: 0.665\n",
      "[11, 300] training loss: 0.639\n",
      "[11, 400] training loss: 0.629\n",
      "[11, 500] training loss: 0.650\n",
      "[11, 600] training loss: 0.643\n",
      "[12, 100] training loss: 0.608\n",
      "[12, 200] training loss: 0.638\n",
      "[12, 300] training loss: 0.622\n",
      "[12, 400] training loss: 0.631\n",
      "[12, 500] training loss: 0.624\n",
      "[12, 600] training loss: 0.626\n",
      "[13, 100] training loss: 0.582\n",
      "[13, 200] training loss: 0.600\n",
      "[13, 300] training loss: 0.605\n",
      "[13, 400] training loss: 0.596\n",
      "[13, 500] training loss: 0.613\n",
      "[13, 600] training loss: 0.608\n",
      "[14, 100] training loss: 0.563\n",
      "[14, 200] training loss: 0.561\n",
      "[14, 300] training loss: 0.582\n",
      "[14, 400] training loss: 0.618\n",
      "[14, 500] training loss: 0.588\n",
      "[14, 600] training loss: 0.573\n",
      "[15, 100] training loss: 0.556\n",
      "[15, 200] training loss: 0.548\n",
      "[15, 300] training loss: 0.571\n",
      "[15, 400] training loss: 0.579\n",
      "[15, 500] training loss: 0.577\n",
      "[15, 600] training loss: 0.577\n",
      "Training model with learning rate 0.01, num_epochs 15, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 1.734\n",
      "[1, 200] training loss: 1.408\n",
      "[1, 300] training loss: 1.258\n",
      "[2, 100] training loss: 1.148\n",
      "[2, 200] training loss: 1.082\n",
      "[2, 300] training loss: 1.043\n",
      "[3, 100] training loss: 0.984\n",
      "[3, 200] training loss: 0.956\n",
      "[3, 300] training loss: 0.945\n",
      "[4, 100] training loss: 0.876\n",
      "[4, 200] training loss: 0.866\n",
      "[4, 300] training loss: 0.863\n",
      "[5, 100] training loss: 0.804\n",
      "[5, 200] training loss: 0.791\n",
      "[5, 300] training loss: 0.805\n",
      "[6, 100] training loss: 0.745\n",
      "[6, 200] training loss: 0.743\n",
      "[6, 300] training loss: 0.767\n",
      "[7, 100] training loss: 0.715\n",
      "[7, 200] training loss: 0.698\n",
      "[7, 300] training loss: 0.704\n",
      "[8, 100] training loss: 0.664\n",
      "[8, 200] training loss: 0.681\n",
      "[8, 300] training loss: 0.679\n",
      "[9, 100] training loss: 0.642\n",
      "[9, 200] training loss: 0.647\n",
      "[9, 300] training loss: 0.647\n",
      "[10, 100] training loss: 0.610\n",
      "[10, 200] training loss: 0.623\n",
      "[10, 300] training loss: 0.617\n",
      "[11, 100] training loss: 0.580\n",
      "[11, 200] training loss: 0.593\n",
      "[11, 300] training loss: 0.570\n",
      "[12, 100] training loss: 0.562\n",
      "[12, 200] training loss: 0.577\n",
      "[12, 300] training loss: 0.575\n",
      "[13, 100] training loss: 0.540\n",
      "[13, 200] training loss: 0.563\n",
      "[13, 300] training loss: 0.554\n",
      "[14, 100] training loss: 0.513\n",
      "[14, 200] training loss: 0.530\n",
      "[14, 300] training loss: 0.537\n",
      "[15, 100] training loss: 0.506\n",
      "[15, 200] training loss: 0.519\n",
      "[15, 300] training loss: 0.505\n",
      "Training model with learning rate 0.1, num_epochs 5, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.960\n",
      "[1, 200] training loss: 1.973\n",
      "[1, 300] training loss: 1.896\n",
      "[1, 400] training loss: 1.832\n",
      "[1, 500] training loss: 1.777\n",
      "[1, 600] training loss: 1.802\n",
      "[1, 700] training loss: 1.763\n",
      "[1, 800] training loss: 1.695\n",
      "[1, 900] training loss: 1.690\n",
      "[1, 1000] training loss: 1.677\n",
      "[1, 1100] training loss: 1.673\n",
      "[1, 1200] training loss: 1.670\n",
      "[2, 100] training loss: 1.596\n",
      "[2, 200] training loss: 1.596\n",
      "[2, 300] training loss: 1.559\n",
      "[2, 400] training loss: 1.588\n",
      "[2, 500] training loss: 1.572\n",
      "[2, 600] training loss: 1.530\n",
      "[2, 700] training loss: 1.519\n",
      "[2, 800] training loss: 1.549\n",
      "[2, 900] training loss: 1.543\n",
      "[2, 1000] training loss: 1.529\n",
      "[2, 1100] training loss: 1.469\n",
      "[2, 1200] training loss: 1.549\n",
      "[3, 100] training loss: 1.502\n",
      "[3, 200] training loss: 1.441\n",
      "[3, 300] training loss: 1.417\n",
      "[3, 400] training loss: 1.452\n",
      "[3, 500] training loss: 1.450\n",
      "[3, 600] training loss: 1.442\n",
      "[3, 700] training loss: 1.402\n",
      "[3, 800] training loss: 1.433\n",
      "[3, 900] training loss: 1.379\n",
      "[3, 1000] training loss: 1.408\n",
      "[3, 1100] training loss: 1.414\n",
      "[3, 1200] training loss: 1.388\n",
      "[4, 100] training loss: 1.377\n",
      "[4, 200] training loss: 1.335\n",
      "[4, 300] training loss: 1.384\n",
      "[4, 400] training loss: 1.364\n",
      "[4, 500] training loss: 1.339\n",
      "[4, 600] training loss: 1.369\n",
      "[4, 700] training loss: 1.317\n",
      "[4, 800] training loss: 1.323\n",
      "[4, 900] training loss: 1.327\n",
      "[4, 1000] training loss: 1.313\n",
      "[4, 1100] training loss: 1.387\n",
      "[4, 1200] training loss: 1.343\n",
      "[5, 100] training loss: 1.317\n",
      "[5, 200] training loss: 1.342\n",
      "[5, 300] training loss: 1.350\n",
      "[5, 400] training loss: 1.305\n",
      "[5, 500] training loss: 1.287\n",
      "[5, 600] training loss: 1.274\n",
      "[5, 700] training loss: 1.253\n",
      "[5, 800] training loss: 1.283\n",
      "[5, 900] training loss: 1.281\n",
      "[5, 1000] training loss: 1.230\n",
      "[5, 1100] training loss: 1.272\n",
      "[5, 1200] training loss: 1.246\n",
      "Training model with learning rate 0.1, num_epochs 5, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.920\n",
      "[1, 200] training loss: 1.884\n",
      "[1, 300] training loss: 1.760\n",
      "[1, 400] training loss: 1.681\n",
      "[1, 500] training loss: 1.626\n",
      "[1, 600] training loss: 1.617\n",
      "[2, 100] training loss: 1.534\n",
      "[2, 200] training loss: 1.496\n",
      "[2, 300] training loss: 1.514\n",
      "[2, 400] training loss: 1.426\n",
      "[2, 500] training loss: 1.454\n",
      "[2, 600] training loss: 1.411\n",
      "[3, 100] training loss: 1.402\n",
      "[3, 200] training loss: 1.334\n",
      "[3, 300] training loss: 1.333\n",
      "[3, 400] training loss: 1.294\n",
      "[3, 500] training loss: 1.331\n",
      "[3, 600] training loss: 1.295\n",
      "[4, 100] training loss: 1.275\n",
      "[4, 200] training loss: 1.267\n",
      "[4, 300] training loss: 1.238\n",
      "[4, 400] training loss: 1.236\n",
      "[4, 500] training loss: 1.243\n",
      "[4, 600] training loss: 1.275\n",
      "[5, 100] training loss: 1.226\n",
      "[5, 200] training loss: 1.206\n",
      "[5, 300] training loss: 1.215\n",
      "[5, 400] training loss: 1.204\n",
      "[5, 500] training loss: 1.175\n",
      "[5, 600] training loss: 1.187\n",
      "Training model with learning rate 0.1, num_epochs 5, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.867\n",
      "[1, 200] training loss: 1.710\n",
      "[1, 300] training loss: 1.577\n",
      "[2, 100] training loss: 1.522\n",
      "[2, 200] training loss: 1.478\n",
      "[2, 300] training loss: 1.457\n",
      "[3, 100] training loss: 1.387\n",
      "[3, 200] training loss: 1.346\n",
      "[3, 300] training loss: 1.356\n",
      "[4, 100] training loss: 1.278\n",
      "[4, 200] training loss: 1.253\n",
      "[4, 300] training loss: 1.248\n",
      "[5, 100] training loss: 1.205\n",
      "[5, 200] training loss: 1.180\n",
      "[5, 300] training loss: 1.178\n",
      "Training model with learning rate 0.1, num_epochs 10, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 3.184\n",
      "[1, 200] training loss: 2.005\n",
      "[1, 300] training loss: 1.930\n",
      "[1, 400] training loss: 1.877\n",
      "[1, 500] training loss: 1.857\n",
      "[1, 600] training loss: 1.793\n",
      "[1, 700] training loss: 1.802\n",
      "[1, 800] training loss: 1.754\n",
      "[1, 900] training loss: 1.775\n",
      "[1, 1000] training loss: 1.712\n",
      "[1, 1100] training loss: 1.703\n",
      "[1, 1200] training loss: 1.652\n",
      "[2, 100] training loss: 1.644\n",
      "[2, 200] training loss: 1.624\n",
      "[2, 300] training loss: 1.597\n",
      "[2, 400] training loss: 1.592\n",
      "[2, 500] training loss: 1.565\n",
      "[2, 600] training loss: 1.579\n",
      "[2, 700] training loss: 1.549\n",
      "[2, 800] training loss: 1.504\n",
      "[2, 900] training loss: 1.515\n",
      "[2, 1000] training loss: 1.500\n",
      "[2, 1100] training loss: 1.512\n",
      "[2, 1200] training loss: 1.482\n",
      "[3, 100] training loss: 1.424\n",
      "[3, 200] training loss: 1.438\n",
      "[3, 300] training loss: 1.487\n",
      "[3, 400] training loss: 1.436\n",
      "[3, 500] training loss: 1.460\n",
      "[3, 600] training loss: 1.418\n",
      "[3, 700] training loss: 1.462\n",
      "[3, 800] training loss: 1.451\n",
      "[3, 900] training loss: 1.404\n",
      "[3, 1000] training loss: 1.433\n",
      "[3, 1100] training loss: 1.353\n",
      "[3, 1200] training loss: 1.404\n",
      "[4, 100] training loss: 1.399\n",
      "[4, 200] training loss: 1.355\n",
      "[4, 300] training loss: 1.359\n",
      "[4, 400] training loss: 1.391\n",
      "[4, 500] training loss: 1.376\n",
      "[4, 600] training loss: 1.395\n",
      "[4, 700] training loss: 1.354\n",
      "[4, 800] training loss: 1.391\n",
      "[4, 900] training loss: 1.359\n",
      "[4, 1000] training loss: 1.366\n",
      "[4, 1100] training loss: 1.334\n",
      "[4, 1200] training loss: 1.343\n",
      "[5, 100] training loss: 1.293\n",
      "[5, 200] training loss: 1.301\n",
      "[5, 300] training loss: 1.325\n",
      "[5, 400] training loss: 1.348\n",
      "[5, 500] training loss: 1.325\n",
      "[5, 600] training loss: 1.332\n",
      "[5, 700] training loss: 1.307\n",
      "[5, 800] training loss: 1.285\n",
      "[5, 900] training loss: 1.321\n",
      "[5, 1000] training loss: 1.321\n",
      "[5, 1100] training loss: 1.338\n",
      "[5, 1200] training loss: 1.257\n",
      "[6, 100] training loss: 1.292\n",
      "[6, 200] training loss: 1.236\n",
      "[6, 300] training loss: 1.322\n",
      "[6, 400] training loss: 1.361\n",
      "[6, 500] training loss: 1.258\n",
      "[6, 600] training loss: 1.265\n",
      "[6, 700] training loss: 1.268\n",
      "[6, 800] training loss: 1.250\n",
      "[6, 900] training loss: 1.307\n",
      "[6, 1000] training loss: 1.266\n",
      "[6, 1100] training loss: 1.256\n",
      "[6, 1200] training loss: 1.303\n",
      "[7, 100] training loss: 1.230\n",
      "[7, 200] training loss: 1.239\n",
      "[7, 300] training loss: 1.234\n",
      "[7, 400] training loss: 1.249\n",
      "[7, 500] training loss: 1.223\n",
      "[7, 600] training loss: 1.263\n",
      "[7, 700] training loss: 1.235\n",
      "[7, 800] training loss: 1.252\n",
      "[7, 900] training loss: 1.237\n",
      "[7, 1000] training loss: 1.250\n",
      "[7, 1100] training loss: 1.234\n",
      "[7, 1200] training loss: 1.222\n",
      "[8, 100] training loss: 1.207\n",
      "[8, 200] training loss: 1.199\n",
      "[8, 300] training loss: 1.215\n",
      "[8, 400] training loss: 1.227\n",
      "[8, 500] training loss: 1.216\n",
      "[8, 600] training loss: 1.221\n",
      "[8, 700] training loss: 1.203\n",
      "[8, 800] training loss: 1.201\n",
      "[8, 900] training loss: 1.211\n",
      "[8, 1000] training loss: 1.243\n",
      "[8, 1100] training loss: 1.209\n",
      "[8, 1200] training loss: 1.219\n",
      "[9, 100] training loss: 1.199\n",
      "[9, 200] training loss: 1.205\n",
      "[9, 300] training loss: 1.197\n",
      "[9, 400] training loss: 1.208\n",
      "[9, 500] training loss: 1.225\n",
      "[9, 600] training loss: 1.147\n",
      "[9, 700] training loss: 1.214\n",
      "[9, 800] training loss: 1.171\n",
      "[9, 900] training loss: 1.189\n",
      "[9, 1000] training loss: 1.183\n",
      "[9, 1100] training loss: 1.215\n",
      "[9, 1200] training loss: 1.219\n",
      "[10, 100] training loss: 1.208\n",
      "[10, 200] training loss: 1.168\n",
      "[10, 300] training loss: 1.186\n",
      "[10, 400] training loss: 1.200\n",
      "[10, 500] training loss: 1.180\n",
      "[10, 600] training loss: 1.164\n",
      "[10, 700] training loss: 1.195\n",
      "[10, 800] training loss: 1.164\n",
      "[10, 900] training loss: 1.184\n",
      "[10, 1000] training loss: 1.147\n",
      "[10, 1100] training loss: 1.138\n",
      "[10, 1200] training loss: 1.166\n",
      "Training model with learning rate 0.1, num_epochs 10, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.897\n",
      "[1, 200] training loss: 1.858\n",
      "[1, 300] training loss: 1.751\n",
      "[1, 400] training loss: 1.685\n",
      "[1, 500] training loss: 1.619\n",
      "[1, 600] training loss: 1.581\n",
      "[2, 100] training loss: 1.525\n",
      "[2, 200] training loss: 1.500\n",
      "[2, 300] training loss: 1.477\n",
      "[2, 400] training loss: 1.446\n",
      "[2, 500] training loss: 1.447\n",
      "[2, 600] training loss: 1.448\n",
      "[3, 100] training loss: 1.391\n",
      "[3, 200] training loss: 1.392\n",
      "[3, 300] training loss: 1.379\n",
      "[3, 400] training loss: 1.360\n",
      "[3, 500] training loss: 1.341\n",
      "[3, 600] training loss: 1.355\n",
      "[4, 100] training loss: 1.308\n",
      "[4, 200] training loss: 1.314\n",
      "[4, 300] training loss: 1.293\n",
      "[4, 400] training loss: 1.296\n",
      "[4, 500] training loss: 1.251\n",
      "[4, 600] training loss: 1.272\n",
      "[5, 100] training loss: 1.246\n",
      "[5, 200] training loss: 1.241\n",
      "[5, 300] training loss: 1.240\n",
      "[5, 400] training loss: 1.217\n",
      "[5, 500] training loss: 1.243\n",
      "[5, 600] training loss: 1.209\n",
      "[6, 100] training loss: 1.206\n",
      "[6, 200] training loss: 1.216\n",
      "[6, 300] training loss: 1.186\n",
      "[6, 400] training loss: 1.162\n",
      "[6, 500] training loss: 1.175\n",
      "[6, 600] training loss: 1.174\n",
      "[7, 100] training loss: 1.144\n",
      "[7, 200] training loss: 1.177\n",
      "[7, 300] training loss: 1.133\n",
      "[7, 400] training loss: 1.153\n",
      "[7, 500] training loss: 1.184\n",
      "[7, 600] training loss: 1.136\n",
      "[8, 100] training loss: 1.106\n",
      "[8, 200] training loss: 1.109\n",
      "[8, 300] training loss: 1.143\n",
      "[8, 400] training loss: 1.119\n",
      "[8, 500] training loss: 1.100\n",
      "[8, 600] training loss: 1.078\n",
      "[9, 100] training loss: 1.096\n",
      "[9, 200] training loss: 1.114\n",
      "[9, 300] training loss: 1.068\n",
      "[9, 400] training loss: 1.099\n",
      "[9, 500] training loss: 1.103\n",
      "[9, 600] training loss: 1.089\n",
      "[10, 100] training loss: 1.086\n",
      "[10, 200] training loss: 1.055\n",
      "[10, 300] training loss: 1.093\n",
      "[10, 400] training loss: 1.076\n",
      "[10, 500] training loss: 1.060\n",
      "[10, 600] training loss: 1.028\n",
      "Training model with learning rate 0.1, num_epochs 10, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.778\n",
      "[1, 200] training loss: 1.754\n",
      "[1, 300] training loss: 1.607\n",
      "[2, 100] training loss: 1.523\n",
      "[2, 200] training loss: 1.432\n",
      "[2, 300] training loss: 1.400\n",
      "[3, 100] training loss: 1.341\n",
      "[3, 200] training loss: 1.293\n",
      "[3, 300] training loss: 1.286\n",
      "[4, 100] training loss: 1.218\n",
      "[4, 200] training loss: 1.192\n",
      "[4, 300] training loss: 1.191\n",
      "[5, 100] training loss: 1.188\n",
      "[5, 200] training loss: 1.135\n",
      "[5, 300] training loss: 1.128\n",
      "[6, 100] training loss: 1.138\n",
      "[6, 200] training loss: 1.143\n",
      "[6, 300] training loss: 1.087\n",
      "[7, 100] training loss: 1.069\n",
      "[7, 200] training loss: 1.090\n",
      "[7, 300] training loss: 1.081\n",
      "[8, 100] training loss: 1.045\n",
      "[8, 200] training loss: 1.037\n",
      "[8, 300] training loss: 1.031\n",
      "[9, 100] training loss: 1.024\n",
      "[9, 200] training loss: 1.054\n",
      "[9, 300] training loss: 1.043\n",
      "[10, 100] training loss: 1.018\n",
      "[10, 200] training loss: 1.025\n",
      "[10, 300] training loss: 0.990\n",
      "Training model with learning rate 0.1, num_epochs 15, and batch size 32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 3.266\n",
      "[1, 200] training loss: 2.030\n",
      "[1, 300] training loss: 1.934\n",
      "[1, 400] training loss: 1.904\n",
      "[1, 500] training loss: 1.840\n",
      "[1, 600] training loss: 1.822\n",
      "[1, 700] training loss: 1.789\n",
      "[1, 800] training loss: 1.777\n",
      "[1, 900] training loss: 1.758\n",
      "[1, 1000] training loss: 1.743\n",
      "[1, 1100] training loss: 1.687\n",
      "[1, 1200] training loss: 1.691\n",
      "[2, 100] training loss: 1.693\n",
      "[2, 200] training loss: 1.621\n",
      "[2, 300] training loss: 1.626\n",
      "[2, 400] training loss: 1.621\n",
      "[2, 500] training loss: 1.576\n",
      "[2, 600] training loss: 1.573\n",
      "[2, 700] training loss: 1.586\n",
      "[2, 800] training loss: 1.598\n",
      "[2, 900] training loss: 1.572\n",
      "[2, 1000] training loss: 1.520\n",
      "[2, 1100] training loss: 1.484\n",
      "[2, 1200] training loss: 1.530\n",
      "[3, 100] training loss: 1.496\n",
      "[3, 200] training loss: 1.486\n",
      "[3, 300] training loss: 1.493\n",
      "[3, 400] training loss: 1.512\n",
      "[3, 500] training loss: 1.497\n",
      "[3, 600] training loss: 1.486\n",
      "[3, 700] training loss: 1.485\n",
      "[3, 800] training loss: 1.447\n",
      "[3, 900] training loss: 1.466\n",
      "[3, 1000] training loss: 1.454\n",
      "[3, 1100] training loss: 1.408\n",
      "[3, 1200] training loss: 1.418\n",
      "[4, 100] training loss: 1.434\n",
      "[4, 200] training loss: 1.391\n",
      "[4, 300] training loss: 1.447\n",
      "[4, 400] training loss: 1.428\n",
      "[4, 500] training loss: 1.398\n",
      "[4, 600] training loss: 1.378\n",
      "[4, 700] training loss: 1.418\n",
      "[4, 800] training loss: 1.386\n",
      "[4, 900] training loss: 1.386\n",
      "[4, 1000] training loss: 1.411\n",
      "[4, 1100] training loss: 1.373\n",
      "[4, 1200] training loss: 1.411\n",
      "[5, 100] training loss: 1.378\n",
      "[5, 200] training loss: 1.419\n",
      "[5, 300] training loss: 1.396\n",
      "[5, 400] training loss: 1.374\n",
      "[5, 500] training loss: 1.370\n",
      "[5, 600] training loss: 1.364\n",
      "[5, 700] training loss: 1.329\n",
      "[5, 800] training loss: 1.383\n",
      "[5, 900] training loss: 1.312\n",
      "[5, 1000] training loss: 1.347\n",
      "[5, 1100] training loss: 1.324\n",
      "[5, 1200] training loss: 1.344\n",
      "[6, 100] training loss: 1.321\n",
      "[6, 200] training loss: 1.343\n",
      "[6, 300] training loss: 1.329\n",
      "[6, 400] training loss: 1.339\n",
      "[6, 500] training loss: 1.321\n",
      "[6, 600] training loss: 1.314\n",
      "[6, 700] training loss: 1.320\n",
      "[6, 800] training loss: 1.350\n",
      "[6, 900] training loss: 1.301\n",
      "[6, 1000] training loss: 1.312\n",
      "[6, 1100] training loss: 1.320\n",
      "[6, 1200] training loss: 1.325\n",
      "[7, 100] training loss: 1.324\n",
      "[7, 200] training loss: 1.297\n",
      "[7, 300] training loss: 1.279\n",
      "[7, 400] training loss: 1.315\n",
      "[7, 500] training loss: 1.298\n",
      "[7, 600] training loss: 1.266\n",
      "[7, 700] training loss: 1.326\n",
      "[7, 800] training loss: 1.291\n",
      "[7, 900] training loss: 1.296\n",
      "[7, 1000] training loss: 1.262\n",
      "[7, 1100] training loss: 1.275\n",
      "[7, 1200] training loss: 1.281\n",
      "[8, 100] training loss: 1.282\n",
      "[8, 200] training loss: 1.257\n",
      "[8, 300] training loss: 1.271\n",
      "[8, 400] training loss: 1.275\n",
      "[8, 500] training loss: 1.298\n",
      "[8, 600] training loss: 1.262\n",
      "[8, 700] training loss: 1.253\n",
      "[8, 800] training loss: 1.295\n",
      "[8, 900] training loss: 1.263\n",
      "[8, 1000] training loss: 1.244\n",
      "[8, 1100] training loss: 1.267\n",
      "[8, 1200] training loss: 1.261\n",
      "[9, 100] training loss: 1.266\n",
      "[9, 200] training loss: 1.270\n",
      "[9, 300] training loss: 1.253\n",
      "[9, 400] training loss: 1.217\n",
      "[9, 500] training loss: 1.261\n",
      "[9, 600] training loss: 1.270\n",
      "[9, 700] training loss: 1.179\n",
      "[9, 800] training loss: 1.264\n",
      "[9, 900] training loss: 1.261\n",
      "[9, 1000] training loss: 1.287\n",
      "[9, 1100] training loss: 1.193\n",
      "[9, 1200] training loss: 1.208\n",
      "[10, 100] training loss: 1.241\n",
      "[10, 200] training loss: 1.240\n",
      "[10, 300] training loss: 1.196\n",
      "[10, 400] training loss: 1.206\n",
      "[10, 500] training loss: 1.254\n",
      "[10, 600] training loss: 1.267\n",
      "[10, 700] training loss: 1.239\n",
      "[10, 800] training loss: 1.201\n",
      "[10, 900] training loss: 1.193\n",
      "[10, 1000] training loss: 1.231\n",
      "[10, 1100] training loss: 1.209\n",
      "[10, 1200] training loss: 1.216\n",
      "[11, 100] training loss: 1.270\n",
      "[11, 200] training loss: 1.219\n",
      "[11, 300] training loss: 1.217\n",
      "[11, 400] training loss: 1.166\n",
      "[11, 500] training loss: 1.140\n",
      "[11, 600] training loss: 1.214\n",
      "[11, 700] training loss: 1.261\n",
      "[11, 800] training loss: 1.209\n",
      "[11, 900] training loss: 1.220\n",
      "[11, 1000] training loss: 1.214\n",
      "[11, 1100] training loss: 1.245\n",
      "[11, 1200] training loss: 1.210\n",
      "[12, 100] training loss: 1.185\n",
      "[12, 200] training loss: 1.204\n",
      "[12, 300] training loss: 1.203\n",
      "[12, 400] training loss: 1.218\n",
      "[12, 500] training loss: 1.193\n",
      "[12, 600] training loss: 1.176\n",
      "[12, 700] training loss: 1.180\n",
      "[12, 800] training loss: 1.165\n",
      "[12, 900] training loss: 1.164\n",
      "[12, 1000] training loss: 1.233\n",
      "[12, 1100] training loss: 1.184\n",
      "[12, 1200] training loss: 1.150\n",
      "[13, 100] training loss: 1.185\n",
      "[13, 200] training loss: 1.156\n",
      "[13, 300] training loss: 1.153\n",
      "[13, 400] training loss: 1.151\n",
      "[13, 500] training loss: 1.218\n",
      "[13, 600] training loss: 1.195\n",
      "[13, 700] training loss: 1.216\n",
      "[13, 800] training loss: 1.230\n",
      "[13, 900] training loss: 1.164\n",
      "[13, 1000] training loss: 1.262\n",
      "[13, 1100] training loss: 1.200\n",
      "[13, 1200] training loss: 1.150\n",
      "[14, 100] training loss: 1.144\n",
      "[14, 200] training loss: 1.175\n",
      "[14, 300] training loss: 1.182\n",
      "[14, 400] training loss: 1.174\n",
      "[14, 500] training loss: 1.144\n",
      "[14, 600] training loss: 1.166\n",
      "[14, 700] training loss: 1.151\n",
      "[14, 800] training loss: 1.154\n",
      "[14, 900] training loss: 1.183\n",
      "[14, 1000] training loss: 1.148\n",
      "[14, 1100] training loss: 1.168\n",
      "[14, 1200] training loss: 1.127\n",
      "[15, 100] training loss: 1.193\n",
      "[15, 200] training loss: 1.131\n",
      "[15, 300] training loss: 1.133\n",
      "[15, 400] training loss: 1.175\n",
      "[15, 500] training loss: 1.196\n",
      "[15, 600] training loss: 1.138\n",
      "[15, 700] training loss: 1.156\n",
      "[15, 800] training loss: 1.147\n",
      "[15, 900] training loss: 1.123\n",
      "[15, 1000] training loss: 1.183\n",
      "[15, 1100] training loss: 1.189\n",
      "[15, 1200] training loss: 1.155\n",
      "Training model with learning rate 0.1, num_epochs 15, and batch size 64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.764\n",
      "[1, 200] training loss: 1.804\n",
      "[1, 300] training loss: 1.724\n",
      "[1, 400] training loss: 1.676\n",
      "[1, 500] training loss: 1.611\n",
      "[1, 600] training loss: 1.596\n",
      "[2, 100] training loss: 1.485\n",
      "[2, 200] training loss: 1.509\n",
      "[2, 300] training loss: 1.484\n",
      "[2, 400] training loss: 1.441\n",
      "[2, 500] training loss: 1.444\n",
      "[2, 600] training loss: 1.424\n",
      "[3, 100] training loss: 1.382\n",
      "[3, 200] training loss: 1.362\n",
      "[3, 300] training loss: 1.372\n",
      "[3, 400] training loss: 1.389\n",
      "[3, 500] training loss: 1.340\n",
      "[3, 600] training loss: 1.333\n",
      "[4, 100] training loss: 1.302\n",
      "[4, 200] training loss: 1.276\n",
      "[4, 300] training loss: 1.280\n",
      "[4, 400] training loss: 1.265\n",
      "[4, 500] training loss: 1.252\n",
      "[4, 600] training loss: 1.265\n",
      "[5, 100] training loss: 1.240\n",
      "[5, 200] training loss: 1.218\n",
      "[5, 300] training loss: 1.228\n",
      "[5, 400] training loss: 1.244\n",
      "[5, 500] training loss: 1.196\n",
      "[5, 600] training loss: 1.207\n",
      "[6, 100] training loss: 1.197\n",
      "[6, 200] training loss: 1.182\n",
      "[6, 300] training loss: 1.202\n",
      "[6, 400] training loss: 1.178\n",
      "[6, 500] training loss: 1.169\n",
      "[6, 600] training loss: 1.158\n",
      "[7, 100] training loss: 1.158\n",
      "[7, 200] training loss: 1.132\n",
      "[7, 300] training loss: 1.149\n",
      "[7, 400] training loss: 1.137\n",
      "[7, 500] training loss: 1.121\n",
      "[7, 600] training loss: 1.092\n",
      "[8, 100] training loss: 1.121\n",
      "[8, 200] training loss: 1.092\n",
      "[8, 300] training loss: 1.078\n",
      "[8, 400] training loss: 1.127\n",
      "[8, 500] training loss: 1.119\n",
      "[8, 600] training loss: 1.094\n",
      "[9, 100] training loss: 1.073\n",
      "[9, 200] training loss: 1.089\n",
      "[9, 300] training loss: 1.050\n",
      "[9, 400] training loss: 1.090\n",
      "[9, 500] training loss: 1.092\n",
      "[9, 600] training loss: 1.054\n",
      "[10, 100] training loss: 1.055\n",
      "[10, 200] training loss: 1.051\n",
      "[10, 300] training loss: 1.046\n",
      "[10, 400] training loss: 1.061\n",
      "[10, 500] training loss: 1.058\n",
      "[10, 600] training loss: 1.082\n",
      "[11, 100] training loss: 1.043\n",
      "[11, 200] training loss: 1.037\n",
      "[11, 300] training loss: 1.044\n",
      "[11, 400] training loss: 1.057\n",
      "[11, 500] training loss: 1.043\n",
      "[11, 600] training loss: 1.018\n",
      "[12, 100] training loss: 1.059\n",
      "[12, 200] training loss: 1.023\n",
      "[12, 300] training loss: 1.004\n",
      "[12, 400] training loss: 1.003\n",
      "[12, 500] training loss: 1.030\n",
      "[12, 600] training loss: 1.020\n",
      "[13, 100] training loss: 1.000\n",
      "[13, 200] training loss: 1.015\n",
      "[13, 300] training loss: 1.005\n",
      "[13, 400] training loss: 1.003\n",
      "[13, 500] training loss: 1.013\n",
      "[13, 600] training loss: 0.988\n",
      "[14, 100] training loss: 1.017\n",
      "[14, 200] training loss: 1.007\n",
      "[14, 300] training loss: 0.997\n",
      "[14, 400] training loss: 1.023\n",
      "[14, 500] training loss: 0.983\n",
      "[14, 600] training loss: 0.972\n",
      "[15, 100] training loss: 1.006\n",
      "[15, 200] training loss: 0.990\n",
      "[15, 300] training loss: 0.992\n",
      "[15, 400] training loss: 1.020\n",
      "[15, 500] training loss: 0.950\n",
      "[15, 600] training loss: 1.024\n",
      "Training model with learning rate 0.1, num_epochs 15, and batch size 128\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1, 100] training loss: 2.824\n",
      "[1, 200] training loss: 1.828\n",
      "[1, 300] training loss: 1.652\n",
      "[2, 100] training loss: 1.537\n",
      "[2, 200] training loss: 1.470\n",
      "[2, 300] training loss: 1.427\n",
      "[3, 100] training loss: 1.371\n",
      "[3, 200] training loss: 1.348\n",
      "[3, 300] training loss: 1.339\n",
      "[4, 100] training loss: 1.287\n",
      "[4, 200] training loss: 1.249\n",
      "[4, 300] training loss: 1.250\n",
      "[5, 100] training loss: 1.225\n",
      "[5, 200] training loss: 1.216\n",
      "[5, 300] training loss: 1.166\n",
      "[6, 100] training loss: 1.185\n",
      "[6, 200] training loss: 1.178\n",
      "[6, 300] training loss: 1.145\n",
      "[7, 100] training loss: 1.155\n",
      "[7, 200] training loss: 1.117\n",
      "[7, 300] training loss: 1.119\n",
      "[8, 100] training loss: 1.097\n",
      "[8, 200] training loss: 1.075\n",
      "[8, 300] training loss: 1.100\n",
      "[9, 100] training loss: 1.087\n",
      "[9, 200] training loss: 1.094\n",
      "[9, 300] training loss: 1.067\n",
      "[10, 100] training loss: 1.076\n",
      "[10, 200] training loss: 1.031\n",
      "[10, 300] training loss: 1.031\n",
      "[11, 100] training loss: 1.036\n",
      "[11, 200] training loss: 1.042\n",
      "[11, 300] training loss: 1.015\n",
      "[12, 100] training loss: 1.001\n",
      "[12, 200] training loss: 1.007\n",
      "[12, 300] training loss: 1.016\n",
      "[13, 100] training loss: 0.998\n",
      "[13, 200] training loss: 0.990\n",
      "[13, 300] training loss: 0.981\n",
      "[14, 100] training loss: 0.981\n",
      "[14, 200] training loss: 0.975\n",
      "[14, 300] training loss: 0.976\n",
      "[15, 100] training loss: 0.969\n",
      "[15, 200] training loss: 0.952\n",
      "[15, 300] training loss: 0.960\n",
      "Files already downloaded and verified\n",
      "Best Hyperparameters : {'learning_rate': 0.001, 'num_epochs': 15, 'batch_size': 32}\n",
      "Best Validation Accuracy : 78.88%\n",
      "Test Accuracy using Best Model : 78.47%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def create_model(learning_rate, num_epochs, batch_size, trainloader, valloader):\n",
    "\n",
    "    class CNNModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(ComplexNet, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(64)\n",
    "            self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(128)\n",
    "            self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "            self.bn3 = nn.BatchNorm2d(256)\n",
    "            self.conv4 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "            self.bn4 = nn.BatchNorm2d(256)\n",
    "            self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "            self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.bn1(self.conv1(x)))\n",
    "            x = torch.max_pool2d(x, 2)\n",
    "            x = torch.relu(self.bn2(self.conv2(x)))\n",
    "            x = torch.max_pool2d(x, 2)\n",
    "            x = torch.relu(self.bn3(self.conv3(x)))\n",
    "            x = torch.relu(self.bn4(self.conv4(x)))\n",
    "            x = torch.max_pool2d(x, 2)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "\n",
    "    net = CNNModel()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        net.train()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print(f\"[{epoch + 1}, {i + 1}] training loss: {running_loss / 100:.3f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_loss_history.append(running_loss)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    return net, train_loss_history, train_accuracy_history\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def hyperparameter_tuning():\n",
    "    learning_rates = [0.001, 0.01, 0.1]\n",
    "    num_epochs_list = [5, 10, 15]\n",
    "    batch_sizes = [32, 64, 128]\n",
    "\n",
    "    best_model = None\n",
    "    best_val_accuracy = 0.0\n",
    "    best_hyperparameters = {}\n",
    "\n",
    "    for learning_rate in learning_rates:\n",
    "        for num_epochs in num_epochs_list:\n",
    "            for batch_size in batch_sizes:\n",
    "                print(f\"Training model with learning rate {learning_rate}, num_epochs {num_epochs}, and batch size {batch_size}\")\n",
    "                \n",
    "                transform = transforms.Compose([\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomCrop(32, padding=4),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ])\n",
    "                \n",
    "                trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "                valset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "                \n",
    "                train_size = int(0.8 * len(trainset))\n",
    "                val_size = len(trainset) - train_size\n",
    "                trainset, valset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "                \n",
    "                trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "                valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "                \n",
    "                model, train_loss, train_acc = create_model(learning_rate, num_epochs, batch_size, trainloader, valloader)\n",
    "                \n",
    "                val_accuracy = evaluate_model(model, valloader)\n",
    "                \n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_model = model\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    best_hyperparameters = {\n",
    "                        'learning_rate': learning_rate,\n",
    "                        'num_epochs': num_epochs,\n",
    "                        'batch_size': batch_size\n",
    "                    }\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=best_hyperparameters['batch_size'], shuffle=False, num_workers=2)\n",
    "    \n",
    "    test_accuracy = evaluate_model(best_model, testloader)\n",
    "    \n",
    "    print(f\"Best Hyperparameters : {best_hyperparameters}\")\n",
    "    print(f\"Best Validation Accuracy : {best_val_accuracy:.2f}%\")\n",
    "    print(f\"Test Accuracy using Best Model : {test_accuracy:.2f}%\")\n",
    "\n",
    "hyperparameter_tuning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Model Training with Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[1 - 100] Training Loss: 2.182\n",
      "[1 - 200] Training Loss: 1.761\n",
      "[1 - 300] Training Loss: 1.643\n",
      "[1 - 400] Training Loss: 1.553\n",
      "[1 - 500] Training Loss: 1.496\n",
      "[1 - 600] Training Loss: 1.483\n",
      "[1 - 700] Training Loss: 1.404\n",
      "[1 - 800] Training Loss: 1.395\n",
      "[1 - 900] Training Loss: 1.340\n",
      "[1 - 1000] Training Loss: 1.317\n",
      "[1 - 1100] Training Loss: 1.245\n",
      "[1 - 1200] Training Loss: 1.262\n",
      "[1 - 1300] Training Loss: 1.258\n",
      "[1 - 1400] Training Loss: 1.199\n",
      "[1 - 1500] Training Loss: 1.184\n",
      "Epoch 1 - Validation Loss: 393.009, Validation Accuracy: 54.86%\n",
      "[2 - 100] Training Loss: 1.111\n",
      "[2 - 200] Training Loss: 1.106\n",
      "[2 - 300] Training Loss: 1.107\n",
      "[2 - 400] Training Loss: 1.029\n",
      "[2 - 500] Training Loss: 1.059\n",
      "[2 - 600] Training Loss: 1.044\n",
      "[2 - 700] Training Loss: 1.009\n",
      "[2 - 800] Training Loss: 1.024\n",
      "[2 - 900] Training Loss: 0.990\n",
      "[2 - 1000] Training Loss: 0.987\n",
      "[2 - 1100] Training Loss: 0.973\n",
      "[2 - 1200] Training Loss: 0.904\n",
      "[2 - 1300] Training Loss: 0.930\n",
      "[2 - 1400] Training Loss: 0.923\n",
      "[2 - 1500] Training Loss: 0.964\n",
      "Epoch 2 - Validation Loss: 303.510, Validation Accuracy: 66.06%\n",
      "[3 - 100] Training Loss: 0.898\n",
      "[3 - 200] Training Loss: 0.854\n",
      "[3 - 300] Training Loss: 0.840\n",
      "[3 - 400] Training Loss: 0.881\n",
      "[3 - 500] Training Loss: 0.842\n",
      "[3 - 600] Training Loss: 0.812\n",
      "[3 - 700] Training Loss: 0.859\n",
      "[3 - 800] Training Loss: 0.848\n",
      "[3 - 900] Training Loss: 0.811\n",
      "[3 - 1000] Training Loss: 0.854\n",
      "[3 - 1100] Training Loss: 0.806\n",
      "[3 - 1200] Training Loss: 0.796\n",
      "[3 - 1300] Training Loss: 0.804\n",
      "[3 - 1400] Training Loss: 0.822\n",
      "[3 - 1500] Training Loss: 0.778\n",
      "Epoch 3 - Validation Loss: 244.821, Validation Accuracy: 72.55%\n",
      "[4 - 100] Training Loss: 0.738\n",
      "[4 - 200] Training Loss: 0.768\n",
      "[4 - 300] Training Loss: 0.782\n",
      "[4 - 400] Training Loss: 0.734\n",
      "[4 - 500] Training Loss: 0.703\n",
      "[4 - 600] Training Loss: 0.734\n",
      "[4 - 700] Training Loss: 0.740\n",
      "[4 - 800] Training Loss: 0.733\n",
      "[4 - 900] Training Loss: 0.699\n",
      "[4 - 1000] Training Loss: 0.737\n",
      "[4 - 1100] Training Loss: 0.724\n",
      "[4 - 1200] Training Loss: 0.709\n",
      "[4 - 1300] Training Loss: 0.726\n",
      "[4 - 1400] Training Loss: 0.710\n",
      "[4 - 1500] Training Loss: 0.675\n",
      "Epoch 4 - Validation Loss: 233.895, Validation Accuracy: 74.27%\n",
      "[5 - 100] Training Loss: 0.665\n",
      "[5 - 200] Training Loss: 0.666\n",
      "[5 - 300] Training Loss: 0.676\n",
      "[5 - 400] Training Loss: 0.656\n",
      "[5 - 500] Training Loss: 0.653\n",
      "[5 - 600] Training Loss: 0.659\n",
      "[5 - 700] Training Loss: 0.626\n",
      "[5 - 800] Training Loss: 0.665\n",
      "[5 - 900] Training Loss: 0.652\n",
      "[5 - 1000] Training Loss: 0.615\n",
      "[5 - 1100] Training Loss: 0.641\n",
      "[5 - 1200] Training Loss: 0.654\n",
      "[5 - 1300] Training Loss: 0.619\n",
      "[5 - 1400] Training Loss: 0.626\n",
      "[5 - 1500] Training Loss: 0.651\n",
      "Epoch 5 - Validation Loss: 206.641, Validation Accuracy: 77.54%\n",
      "[6 - 100] Training Loss: 0.578\n",
      "[6 - 200] Training Loss: 0.629\n",
      "[6 - 300] Training Loss: 0.610\n",
      "[6 - 400] Training Loss: 0.597\n",
      "[6 - 500] Training Loss: 0.574\n",
      "[6 - 600] Training Loss: 0.592\n",
      "[6 - 700] Training Loss: 0.587\n",
      "[6 - 800] Training Loss: 0.596\n",
      "[6 - 900] Training Loss: 0.568\n",
      "[6 - 1000] Training Loss: 0.565\n",
      "[6 - 1100] Training Loss: 0.589\n",
      "[6 - 1200] Training Loss: 0.606\n",
      "[6 - 1300] Training Loss: 0.581\n",
      "[6 - 1400] Training Loss: 0.617\n",
      "[6 - 1500] Training Loss: 0.545\n",
      "Epoch 6 - Validation Loss: 201.575, Validation Accuracy: 77.34%\n",
      "[7 - 100] Training Loss: 0.527\n",
      "[7 - 200] Training Loss: 0.545\n",
      "[7 - 300] Training Loss: 0.558\n",
      "[7 - 400] Training Loss: 0.526\n",
      "[7 - 500] Training Loss: 0.517\n",
      "[7 - 600] Training Loss: 0.527\n",
      "[7 - 700] Training Loss: 0.565\n",
      "[7 - 800] Training Loss: 0.521\n",
      "[7 - 900] Training Loss: 0.545\n",
      "[7 - 1000] Training Loss: 0.569\n",
      "[7 - 1100] Training Loss: 0.551\n",
      "[7 - 1200] Training Loss: 0.551\n",
      "[7 - 1300] Training Loss: 0.523\n",
      "[7 - 1400] Training Loss: 0.520\n",
      "[7 - 1500] Training Loss: 0.546\n",
      "Epoch 7 - Validation Loss: 182.600, Validation Accuracy: 80.27%\n",
      "[8 - 100] Training Loss: 0.514\n",
      "[8 - 200] Training Loss: 0.499\n",
      "[8 - 300] Training Loss: 0.489\n",
      "[8 - 400] Training Loss: 0.480\n",
      "[8 - 500] Training Loss: 0.502\n",
      "[8 - 600] Training Loss: 0.488\n",
      "[8 - 700] Training Loss: 0.521\n",
      "[8 - 800] Training Loss: 0.523\n",
      "[8 - 900] Training Loss: 0.486\n",
      "[8 - 1000] Training Loss: 0.506\n",
      "[8 - 1100] Training Loss: 0.472\n",
      "[8 - 1200] Training Loss: 0.503\n",
      "[8 - 1300] Training Loss: 0.487\n",
      "[8 - 1400] Training Loss: 0.495\n",
      "[8 - 1500] Training Loss: 0.518\n",
      "Epoch 8 - Validation Loss: 189.544, Validation Accuracy: 78.75%\n",
      "[9 - 100] Training Loss: 0.453\n",
      "[9 - 200] Training Loss: 0.485\n",
      "[9 - 300] Training Loss: 0.469\n",
      "[9 - 400] Training Loss: 0.456\n",
      "[9 - 500] Training Loss: 0.486\n",
      "[9 - 600] Training Loss: 0.457\n",
      "[9 - 700] Training Loss: 0.459\n",
      "[9 - 800] Training Loss: 0.446\n",
      "[9 - 900] Training Loss: 0.489\n",
      "[9 - 1000] Training Loss: 0.472\n",
      "[9 - 1100] Training Loss: 0.464\n",
      "[9 - 1200] Training Loss: 0.447\n",
      "[9 - 1300] Training Loss: 0.448\n",
      "[9 - 1400] Training Loss: 0.448\n",
      "[9 - 1500] Training Loss: 0.442\n",
      "Epoch 9 - Validation Loss: 188.261, Validation Accuracy: 80.19%\n",
      "[10 - 100] Training Loss: 0.421\n",
      "[10 - 200] Training Loss: 0.416\n",
      "[10 - 300] Training Loss: 0.420\n",
      "[10 - 400] Training Loss: 0.414\n",
      "[10 - 500] Training Loss: 0.456\n",
      "[10 - 600] Training Loss: 0.440\n",
      "[10 - 700] Training Loss: 0.435\n",
      "[10 - 800] Training Loss: 0.453\n",
      "[10 - 900] Training Loss: 0.425\n",
      "[10 - 1000] Training Loss: 0.410\n",
      "[10 - 1100] Training Loss: 0.407\n",
      "[10 - 1200] Training Loss: 0.437\n",
      "[10 - 1300] Training Loss: 0.446\n",
      "[10 - 1400] Training Loss: 0.438\n",
      "[10 - 1500] Training Loss: 0.433\n",
      "Epoch 10 - Validation Loss: 156.217, Validation Accuracy: 83.40%\n",
      "[11 - 100] Training Loss: 0.361\n",
      "[11 - 200] Training Loss: 0.399\n",
      "[11 - 300] Training Loss: 0.430\n",
      "[11 - 400] Training Loss: 0.395\n",
      "[11 - 500] Training Loss: 0.420\n",
      "[11 - 600] Training Loss: 0.372\n",
      "[11 - 700] Training Loss: 0.417\n",
      "[11 - 800] Training Loss: 0.388\n",
      "[11 - 900] Training Loss: 0.414\n",
      "[11 - 1000] Training Loss: 0.398\n",
      "[11 - 1100] Training Loss: 0.429\n",
      "[11 - 1200] Training Loss: 0.421\n",
      "[11 - 1300] Training Loss: 0.418\n",
      "[11 - 1400] Training Loss: 0.428\n",
      "[11 - 1500] Training Loss: 0.406\n",
      "Epoch 11 - Validation Loss: 151.166, Validation Accuracy: 83.63%\n",
      "[12 - 100] Training Loss: 0.376\n",
      "[12 - 200] Training Loss: 0.356\n",
      "[12 - 300] Training Loss: 0.377\n",
      "[12 - 400] Training Loss: 0.379\n",
      "[12 - 500] Training Loss: 0.395\n",
      "[12 - 600] Training Loss: 0.404\n",
      "[12 - 700] Training Loss: 0.397\n",
      "[12 - 800] Training Loss: 0.376\n",
      "[12 - 900] Training Loss: 0.375\n",
      "[12 - 1000] Training Loss: 0.375\n",
      "[12 - 1100] Training Loss: 0.385\n",
      "[12 - 1200] Training Loss: 0.377\n",
      "[12 - 1300] Training Loss: 0.380\n",
      "[12 - 1400] Training Loss: 0.401\n",
      "[12 - 1500] Training Loss: 0.425\n",
      "Epoch 12 - Validation Loss: 149.463, Validation Accuracy: 84.28%\n",
      "[13 - 100] Training Loss: 0.367\n",
      "[13 - 200] Training Loss: 0.336\n",
      "[13 - 300] Training Loss: 0.361\n",
      "[13 - 400] Training Loss: 0.364\n",
      "[13 - 500] Training Loss: 0.360\n",
      "[13 - 600] Training Loss: 0.363\n",
      "[13 - 700] Training Loss: 0.358\n",
      "[13 - 800] Training Loss: 0.351\n",
      "[13 - 900] Training Loss: 0.335\n",
      "[13 - 1000] Training Loss: 0.359\n",
      "[13 - 1100] Training Loss: 0.342\n",
      "[13 - 1200] Training Loss: 0.373\n",
      "[13 - 1300] Training Loss: 0.371\n",
      "[13 - 1400] Training Loss: 0.365\n",
      "[13 - 1500] Training Loss: 0.340\n",
      "Epoch 13 - Validation Loss: 147.449, Validation Accuracy: 83.87%\n",
      "[14 - 100] Training Loss: 0.343\n",
      "[14 - 200] Training Loss: 0.329\n",
      "[14 - 300] Training Loss: 0.322\n",
      "[14 - 400] Training Loss: 0.340\n",
      "[14 - 500] Training Loss: 0.338\n",
      "[14 - 600] Training Loss: 0.329\n",
      "[14 - 700] Training Loss: 0.342\n",
      "[14 - 800] Training Loss: 0.319\n",
      "[14 - 900] Training Loss: 0.332\n",
      "[14 - 1000] Training Loss: 0.333\n",
      "[14 - 1100] Training Loss: 0.347\n",
      "[14 - 1200] Training Loss: 0.331\n",
      "[14 - 1300] Training Loss: 0.354\n",
      "[14 - 1400] Training Loss: 0.354\n",
      "[14 - 1500] Training Loss: 0.306\n",
      "Epoch 14 - Validation Loss: 143.163, Validation Accuracy: 84.84%\n",
      "[15 - 100] Training Loss: 0.295\n",
      "[15 - 200] Training Loss: 0.324\n",
      "[15 - 300] Training Loss: 0.307\n",
      "[15 - 400] Training Loss: 0.305\n",
      "[15 - 500] Training Loss: 0.344\n",
      "[15 - 600] Training Loss: 0.312\n",
      "[15 - 700] Training Loss: 0.318\n",
      "[15 - 800] Training Loss: 0.319\n",
      "[15 - 900] Training Loss: 0.306\n",
      "[15 - 1000] Training Loss: 0.289\n",
      "[15 - 1100] Training Loss: 0.325\n",
      "[15 - 1200] Training Loss: 0.336\n",
      "[15 - 1300] Training Loss: 0.337\n",
      "[15 - 1400] Training Loss: 0.332\n",
      "[15 - 1500] Training Loss: 0.324\n",
      "Epoch 15 - Validation Loss: 149.230, Validation Accuracy: 84.79%\n",
      "[16 - 100] Training Loss: 0.277\n",
      "[16 - 200] Training Loss: 0.301\n",
      "[16 - 300] Training Loss: 0.309\n",
      "[16 - 400] Training Loss: 0.321\n",
      "[16 - 500] Training Loss: 0.288\n",
      "[16 - 600] Training Loss: 0.274\n",
      "[16 - 700] Training Loss: 0.295\n",
      "[16 - 800] Training Loss: 0.309\n",
      "[16 - 900] Training Loss: 0.300\n",
      "[16 - 1000] Training Loss: 0.305\n",
      "[16 - 1100] Training Loss: 0.309\n",
      "[16 - 1200] Training Loss: 0.299\n",
      "[16 - 1300] Training Loss: 0.332\n",
      "[16 - 1400] Training Loss: 0.312\n",
      "[16 - 1500] Training Loss: 0.304\n",
      "Epoch 16 - Validation Loss: 141.538, Validation Accuracy: 85.28%\n",
      "[17 - 100] Training Loss: 0.279\n",
      "[17 - 200] Training Loss: 0.281\n",
      "[17 - 300] Training Loss: 0.261\n",
      "[17 - 400] Training Loss: 0.279\n",
      "[17 - 500] Training Loss: 0.282\n",
      "[17 - 600] Training Loss: 0.262\n",
      "[17 - 700] Training Loss: 0.293\n",
      "[17 - 800] Training Loss: 0.298\n",
      "[17 - 900] Training Loss: 0.273\n",
      "[17 - 1000] Training Loss: 0.321\n",
      "[17 - 1100] Training Loss: 0.301\n",
      "[17 - 1200] Training Loss: 0.280\n",
      "[17 - 1300] Training Loss: 0.281\n",
      "[17 - 1400] Training Loss: 0.283\n",
      "[17 - 1500] Training Loss: 0.290\n",
      "Epoch 17 - Validation Loss: 156.281, Validation Accuracy: 84.13%\n",
      "[18 - 100] Training Loss: 0.264\n",
      "[18 - 200] Training Loss: 0.254\n",
      "[18 - 300] Training Loss: 0.248\n",
      "[18 - 400] Training Loss: 0.264\n",
      "[18 - 500] Training Loss: 0.282\n",
      "[18 - 600] Training Loss: 0.271\n",
      "[18 - 700] Training Loss: 0.255\n",
      "[18 - 800] Training Loss: 0.285\n",
      "[18 - 900] Training Loss: 0.281\n",
      "[18 - 1000] Training Loss: 0.260\n",
      "[18 - 1100] Training Loss: 0.293\n",
      "[18 - 1200] Training Loss: 0.275\n",
      "[18 - 1300] Training Loss: 0.279\n",
      "[18 - 1400] Training Loss: 0.271\n",
      "[18 - 1500] Training Loss: 0.273\n",
      "Epoch 18 - Validation Loss: 140.877, Validation Accuracy: 85.51%\n",
      "[19 - 100] Training Loss: 0.249\n",
      "[19 - 200] Training Loss: 0.252\n",
      "[19 - 300] Training Loss: 0.226\n",
      "[19 - 400] Training Loss: 0.265\n",
      "[19 - 500] Training Loss: 0.264\n",
      "[19 - 600] Training Loss: 0.282\n",
      "[19 - 700] Training Loss: 0.249\n",
      "[19 - 800] Training Loss: 0.263\n",
      "[19 - 900] Training Loss: 0.260\n",
      "[19 - 1000] Training Loss: 0.278\n",
      "[19 - 1100] Training Loss: 0.256\n",
      "[19 - 1200] Training Loss: 0.253\n",
      "[19 - 1300] Training Loss: 0.258\n",
      "[19 - 1400] Training Loss: 0.292\n",
      "[19 - 1500] Training Loss: 0.247\n",
      "Epoch 19 - Validation Loss: 141.241, Validation Accuracy: 85.38%\n",
      "[20 - 100] Training Loss: 0.242\n",
      "[20 - 200] Training Loss: 0.250\n",
      "[20 - 300] Training Loss: 0.256\n",
      "[20 - 400] Training Loss: 0.250\n",
      "[20 - 500] Training Loss: 0.254\n",
      "[20 - 600] Training Loss: 0.280\n",
      "[20 - 700] Training Loss: 0.252\n",
      "[20 - 800] Training Loss: 0.226\n",
      "[20 - 900] Training Loss: 0.234\n",
      "[20 - 1000] Training Loss: 0.246\n",
      "[20 - 1100] Training Loss: 0.269\n",
      "[20 - 1200] Training Loss: 0.272\n",
      "[20 - 1300] Training Loss: 0.258\n",
      "[20 - 1400] Training Loss: 0.230\n",
      "[20 - 1500] Training Loss: 0.244\n",
      "Epoch 20 - Validation Loss: 139.886, Validation Accuracy: 85.86%\n",
      "[21 - 100] Training Loss: 0.245\n",
      "[21 - 200] Training Loss: 0.231\n",
      "[21 - 300] Training Loss: 0.215\n",
      "[21 - 400] Training Loss: 0.247\n",
      "[21 - 500] Training Loss: 0.217\n",
      "[21 - 600] Training Loss: 0.233\n",
      "[21 - 700] Training Loss: 0.244\n",
      "[21 - 800] Training Loss: 0.238\n",
      "[21 - 900] Training Loss: 0.258\n",
      "[21 - 1000] Training Loss: 0.219\n",
      "[21 - 1100] Training Loss: 0.254\n",
      "[21 - 1200] Training Loss: 0.247\n",
      "[21 - 1300] Training Loss: 0.235\n",
      "[21 - 1400] Training Loss: 0.257\n",
      "[21 - 1500] Training Loss: 0.255\n",
      "Epoch 21 - Validation Loss: 141.924, Validation Accuracy: 85.48%\n",
      "[22 - 100] Training Loss: 0.203\n",
      "[22 - 200] Training Loss: 0.221\n",
      "[22 - 300] Training Loss: 0.206\n",
      "[22 - 400] Training Loss: 0.218\n",
      "[22 - 500] Training Loss: 0.211\n",
      "[22 - 600] Training Loss: 0.228\n",
      "[22 - 700] Training Loss: 0.250\n",
      "[22 - 800] Training Loss: 0.235\n",
      "[22 - 900] Training Loss: 0.230\n",
      "[22 - 1000] Training Loss: 0.244\n",
      "[22 - 1100] Training Loss: 0.228\n",
      "[22 - 1200] Training Loss: 0.235\n",
      "[22 - 1300] Training Loss: 0.242\n",
      "[22 - 1400] Training Loss: 0.243\n",
      "[22 - 1500] Training Loss: 0.239\n",
      "Epoch 22 - Validation Loss: 145.550, Validation Accuracy: 85.81%\n",
      "[23 - 100] Training Loss: 0.196\n",
      "[23 - 200] Training Loss: 0.190\n",
      "[23 - 300] Training Loss: 0.199\n",
      "[23 - 400] Training Loss: 0.218\n",
      "[23 - 500] Training Loss: 0.229\n",
      "[23 - 600] Training Loss: 0.201\n",
      "[23 - 700] Training Loss: 0.225\n",
      "[23 - 800] Training Loss: 0.200\n",
      "[23 - 900] Training Loss: 0.253\n",
      "[23 - 1000] Training Loss: 0.229\n",
      "[23 - 1100] Training Loss: 0.237\n",
      "[23 - 1200] Training Loss: 0.237\n",
      "[23 - 1300] Training Loss: 0.232\n",
      "[23 - 1400] Training Loss: 0.225\n",
      "[23 - 1500] Training Loss: 0.228\n",
      "Epoch 23 - Validation Loss: 145.853, Validation Accuracy: 85.55%\n",
      "[24 - 100] Training Loss: 0.193\n",
      "[24 - 200] Training Loss: 0.179\n",
      "[24 - 300] Training Loss: 0.207\n",
      "[24 - 400] Training Loss: 0.200\n",
      "[24 - 500] Training Loss: 0.219\n",
      "[24 - 600] Training Loss: 0.206\n",
      "[24 - 700] Training Loss: 0.237\n",
      "[24 - 800] Training Loss: 0.223\n",
      "[24 - 900] Training Loss: 0.225\n",
      "[24 - 1000] Training Loss: 0.196\n",
      "[24 - 1100] Training Loss: 0.210\n",
      "[24 - 1200] Training Loss: 0.209\n",
      "[24 - 1300] Training Loss: 0.208\n",
      "[24 - 1400] Training Loss: 0.212\n",
      "[24 - 1500] Training Loss: 0.194\n",
      "Epoch 24 - Validation Loss: 142.118, Validation Accuracy: 86.40%\n",
      "[25 - 100] Training Loss: 0.187\n",
      "[25 - 200] Training Loss: 0.190\n",
      "[25 - 300] Training Loss: 0.196\n",
      "[25 - 400] Training Loss: 0.197\n",
      "[25 - 500] Training Loss: 0.214\n",
      "[25 - 600] Training Loss: 0.203\n",
      "[25 - 700] Training Loss: 0.221\n",
      "[25 - 800] Training Loss: 0.187\n",
      "[25 - 900] Training Loss: 0.217\n",
      "[25 - 1000] Training Loss: 0.197\n",
      "[25 - 1100] Training Loss: 0.191\n",
      "[25 - 1200] Training Loss: 0.211\n",
      "[25 - 1300] Training Loss: 0.223\n",
      "[25 - 1400] Training Loss: 0.205\n",
      "[25 - 1500] Training Loss: 0.219\n",
      "Epoch 25 - Validation Loss: 141.251, Validation Accuracy: 85.88%\n",
      "[26 - 100] Training Loss: 0.182\n",
      "[26 - 200] Training Loss: 0.187\n",
      "[26 - 300] Training Loss: 0.192\n",
      "[26 - 400] Training Loss: 0.204\n",
      "[26 - 500] Training Loss: 0.189\n",
      "[26 - 600] Training Loss: 0.201\n",
      "[26 - 700] Training Loss: 0.192\n",
      "[26 - 800] Training Loss: 0.182\n",
      "[26 - 900] Training Loss: 0.196\n",
      "[26 - 1000] Training Loss: 0.211\n",
      "[26 - 1100] Training Loss: 0.201\n",
      "[26 - 1200] Training Loss: 0.208\n",
      "[26 - 1300] Training Loss: 0.218\n",
      "[26 - 1400] Training Loss: 0.198\n",
      "[26 - 1500] Training Loss: 0.216\n",
      "Epoch 26 - Validation Loss: 143.318, Validation Accuracy: 85.93%\n",
      "[27 - 100] Training Loss: 0.178\n",
      "[27 - 200] Training Loss: 0.185\n",
      "[27 - 300] Training Loss: 0.185\n",
      "[27 - 400] Training Loss: 0.174\n",
      "[27 - 500] Training Loss: 0.175\n",
      "[27 - 600] Training Loss: 0.193\n",
      "[27 - 700] Training Loss: 0.204\n",
      "[27 - 800] Training Loss: 0.166\n",
      "[27 - 900] Training Loss: 0.184\n",
      "[27 - 1000] Training Loss: 0.198\n",
      "[27 - 1100] Training Loss: 0.206\n",
      "[27 - 1200] Training Loss: 0.185\n",
      "[27 - 1300] Training Loss: 0.192\n",
      "[27 - 1400] Training Loss: 0.196\n",
      "[27 - 1500] Training Loss: 0.215\n",
      "Epoch 27 - Validation Loss: 146.711, Validation Accuracy: 85.92%\n",
      "[28 - 100] Training Loss: 0.178\n",
      "[28 - 200] Training Loss: 0.170\n",
      "[28 - 300] Training Loss: 0.174\n",
      "[28 - 400] Training Loss: 0.192\n",
      "[28 - 500] Training Loss: 0.174\n",
      "[28 - 600] Training Loss: 0.178\n",
      "[28 - 700] Training Loss: 0.183\n",
      "[28 - 800] Training Loss: 0.177\n",
      "[28 - 900] Training Loss: 0.176\n",
      "[28 - 1000] Training Loss: 0.177\n",
      "[28 - 1100] Training Loss: 0.166\n",
      "[28 - 1200] Training Loss: 0.174\n",
      "[28 - 1300] Training Loss: 0.190\n",
      "[28 - 1400] Training Loss: 0.182\n",
      "[28 - 1500] Training Loss: 0.186\n",
      "Epoch 28 - Validation Loss: 149.289, Validation Accuracy: 85.64%\n",
      "[29 - 100] Training Loss: 0.170\n",
      "[29 - 200] Training Loss: 0.180\n",
      "[29 - 300] Training Loss: 0.159\n",
      "[29 - 400] Training Loss: 0.182\n",
      "[29 - 500] Training Loss: 0.166\n",
      "[29 - 600] Training Loss: 0.155\n",
      "[29 - 700] Training Loss: 0.191\n",
      "[29 - 800] Training Loss: 0.186\n",
      "[29 - 900] Training Loss: 0.180\n",
      "[29 - 1000] Training Loss: 0.171\n",
      "[29 - 1100] Training Loss: 0.185\n",
      "[29 - 1200] Training Loss: 0.177\n",
      "[29 - 1300] Training Loss: 0.180\n",
      "[29 - 1400] Training Loss: 0.195\n",
      "[29 - 1500] Training Loss: 0.185\n",
      "Epoch 29 - Validation Loss: 148.294, Validation Accuracy: 85.89%\n",
      "[30 - 100] Training Loss: 0.170\n",
      "[30 - 200] Training Loss: 0.158\n",
      "[30 - 300] Training Loss: 0.153\n",
      "[30 - 400] Training Loss: 0.157\n",
      "[30 - 500] Training Loss: 0.159\n",
      "[30 - 600] Training Loss: 0.155\n",
      "[30 - 700] Training Loss: 0.158\n",
      "[30 - 800] Training Loss: 0.168\n",
      "[30 - 900] Training Loss: 0.180\n",
      "[30 - 1000] Training Loss: 0.178\n",
      "[30 - 1100] Training Loss: 0.174\n",
      "[30 - 1200] Training Loss: 0.198\n",
      "[30 - 1300] Training Loss: 0.168\n",
      "[30 - 1400] Training Loss: 0.173\n",
      "[30 - 1500] Training Loss: 0.194\n",
      "Epoch 30 - Validation Loss: 144.785, Validation Accuracy: 86.22%\n",
      "[31 - 100] Training Loss: 0.143\n",
      "[31 - 200] Training Loss: 0.144\n",
      "[31 - 300] Training Loss: 0.140\n",
      "[31 - 400] Training Loss: 0.153\n",
      "[31 - 500] Training Loss: 0.166\n",
      "[31 - 600] Training Loss: 0.160\n",
      "[31 - 700] Training Loss: 0.181\n",
      "[31 - 800] Training Loss: 0.176\n",
      "[31 - 900] Training Loss: 0.165\n",
      "[31 - 1000] Training Loss: 0.190\n",
      "[31 - 1100] Training Loss: 0.163\n",
      "[31 - 1200] Training Loss: 0.169\n",
      "[31 - 1300] Training Loss: 0.176\n",
      "[31 - 1400] Training Loss: 0.174\n",
      "[31 - 1500] Training Loss: 0.189\n",
      "Epoch 31 - Validation Loss: 151.832, Validation Accuracy: 86.32%\n",
      "[32 - 100] Training Loss: 0.159\n",
      "[32 - 200] Training Loss: 0.131\n",
      "[32 - 300] Training Loss: 0.151\n",
      "[32 - 400] Training Loss: 0.158\n",
      "[32 - 500] Training Loss: 0.146\n",
      "[32 - 600] Training Loss: 0.151\n",
      "[32 - 700] Training Loss: 0.153\n",
      "[32 - 800] Training Loss: 0.141\n",
      "[32 - 900] Training Loss: 0.178\n",
      "[32 - 1000] Training Loss: 0.179\n",
      "[32 - 1100] Training Loss: 0.167\n",
      "[32 - 1200] Training Loss: 0.158\n",
      "[32 - 1300] Training Loss: 0.170\n",
      "[32 - 1400] Training Loss: 0.161\n",
      "[32 - 1500] Training Loss: 0.166\n",
      "Epoch 32 - Validation Loss: 149.985, Validation Accuracy: 86.31%\n",
      "[33 - 100] Training Loss: 0.144\n",
      "[33 - 200] Training Loss: 0.144\n",
      "[33 - 300] Training Loss: 0.142\n",
      "[33 - 400] Training Loss: 0.162\n",
      "[33 - 500] Training Loss: 0.143\n",
      "[33 - 600] Training Loss: 0.158\n",
      "[33 - 700] Training Loss: 0.164\n",
      "[33 - 800] Training Loss: 0.145\n",
      "[33 - 900] Training Loss: 0.130\n",
      "[33 - 1000] Training Loss: 0.184\n",
      "[33 - 1100] Training Loss: 0.161\n",
      "[33 - 1200] Training Loss: 0.146\n",
      "[33 - 1300] Training Loss: 0.148\n",
      "[33 - 1400] Training Loss: 0.146\n",
      "[33 - 1500] Training Loss: 0.173\n",
      "Epoch 33 - Validation Loss: 151.026, Validation Accuracy: 86.35%\n",
      "[34 - 100] Training Loss: 0.141\n",
      "[34 - 200] Training Loss: 0.133\n",
      "[34 - 300] Training Loss: 0.142\n",
      "[34 - 400] Training Loss: 0.159\n",
      "[34 - 500] Training Loss: 0.128\n",
      "[34 - 600] Training Loss: 0.153\n",
      "[34 - 700] Training Loss: 0.164\n",
      "[34 - 800] Training Loss: 0.141\n",
      "[34 - 900] Training Loss: 0.160\n",
      "[34 - 1000] Training Loss: 0.159\n",
      "[34 - 1100] Training Loss: 0.189\n",
      "[34 - 1200] Training Loss: 0.152\n",
      "[34 - 1300] Training Loss: 0.167\n",
      "[34 - 1400] Training Loss: 0.169\n",
      "[34 - 1500] Training Loss: 0.164\n",
      "Epoch 34 - Validation Loss: 143.723, Validation Accuracy: 86.61%\n",
      "[35 - 100] Training Loss: 0.121\n",
      "[35 - 200] Training Loss: 0.141\n",
      "[35 - 300] Training Loss: 0.142\n",
      "[35 - 400] Training Loss: 0.156\n",
      "[35 - 500] Training Loss: 0.145\n",
      "[35 - 600] Training Loss: 0.135\n",
      "[35 - 700] Training Loss: 0.151\n",
      "[35 - 800] Training Loss: 0.145\n",
      "[35 - 900] Training Loss: 0.159\n",
      "[35 - 1000] Training Loss: 0.143\n",
      "[35 - 1100] Training Loss: 0.138\n",
      "[35 - 1200] Training Loss: 0.161\n",
      "[35 - 1300] Training Loss: 0.147\n",
      "[35 - 1400] Training Loss: 0.163\n",
      "[35 - 1500] Training Loss: 0.163\n",
      "Epoch 35 - Validation Loss: 146.729, Validation Accuracy: 86.85%\n",
      "[36 - 100] Training Loss: 0.128\n",
      "[36 - 200] Training Loss: 0.129\n",
      "[36 - 300] Training Loss: 0.126\n",
      "[36 - 400] Training Loss: 0.126\n",
      "[36 - 500] Training Loss: 0.131\n",
      "[36 - 600] Training Loss: 0.145\n",
      "[36 - 700] Training Loss: 0.134\n",
      "[36 - 800] Training Loss: 0.144\n",
      "[36 - 900] Training Loss: 0.140\n",
      "[36 - 1000] Training Loss: 0.158\n",
      "[36 - 1100] Training Loss: 0.140\n",
      "[36 - 1200] Training Loss: 0.165\n",
      "[36 - 1300] Training Loss: 0.158\n",
      "[36 - 1400] Training Loss: 0.160\n",
      "[36 - 1500] Training Loss: 0.166\n",
      "Epoch 36 - Validation Loss: 160.007, Validation Accuracy: 85.77%\n",
      "[37 - 100] Training Loss: 0.132\n",
      "[37 - 200] Training Loss: 0.124\n",
      "[37 - 300] Training Loss: 0.120\n",
      "[37 - 400] Training Loss: 0.137\n",
      "[37 - 500] Training Loss: 0.118\n",
      "[37 - 600] Training Loss: 0.125\n",
      "[37 - 700] Training Loss: 0.133\n",
      "[37 - 800] Training Loss: 0.135\n",
      "[37 - 900] Training Loss: 0.161\n",
      "[37 - 1000] Training Loss: 0.168\n",
      "[37 - 1100] Training Loss: 0.160\n",
      "[37 - 1200] Training Loss: 0.151\n",
      "[37 - 1300] Training Loss: 0.134\n",
      "[37 - 1400] Training Loss: 0.146\n",
      "[37 - 1500] Training Loss: 0.144\n",
      "Epoch 37 - Validation Loss: 163.168, Validation Accuracy: 85.50%\n",
      "[38 - 100] Training Loss: 0.119\n",
      "[38 - 200] Training Loss: 0.128\n",
      "[38 - 300] Training Loss: 0.143\n",
      "[38 - 400] Training Loss: 0.137\n",
      "[38 - 500] Training Loss: 0.141\n",
      "[38 - 600] Training Loss: 0.139\n",
      "[38 - 700] Training Loss: 0.133\n",
      "[38 - 800] Training Loss: 0.128\n",
      "[38 - 900] Training Loss: 0.151\n",
      "[38 - 1000] Training Loss: 0.147\n",
      "[38 - 1100] Training Loss: 0.131\n",
      "[38 - 1200] Training Loss: 0.139\n",
      "[38 - 1300] Training Loss: 0.143\n",
      "[38 - 1400] Training Loss: 0.152\n",
      "[38 - 1500] Training Loss: 0.117\n",
      "Epoch 38 - Validation Loss: 161.176, Validation Accuracy: 86.19%\n",
      "[39 - 100] Training Loss: 0.118\n",
      "[39 - 200] Training Loss: 0.144\n",
      "[39 - 300] Training Loss: 0.122\n",
      "[39 - 400] Training Loss: 0.137\n",
      "[39 - 500] Training Loss: 0.142\n",
      "[39 - 600] Training Loss: 0.139\n",
      "[39 - 700] Training Loss: 0.121\n",
      "[39 - 800] Training Loss: 0.130\n",
      "[39 - 900] Training Loss: 0.129\n",
      "[39 - 1000] Training Loss: 0.131\n",
      "[39 - 1100] Training Loss: 0.141\n",
      "[39 - 1200] Training Loss: 0.126\n",
      "[39 - 1300] Training Loss: 0.139\n",
      "[39 - 1400] Training Loss: 0.147\n",
      "[39 - 1500] Training Loss: 0.125\n",
      "Epoch 39 - Validation Loss: 155.512, Validation Accuracy: 86.16%\n",
      "[40 - 100] Training Loss: 0.116\n",
      "[40 - 200] Training Loss: 0.108\n",
      "[40 - 300] Training Loss: 0.110\n",
      "[40 - 400] Training Loss: 0.120\n",
      "[40 - 500] Training Loss: 0.138\n",
      "[40 - 600] Training Loss: 0.126\n",
      "[40 - 700] Training Loss: 0.131\n",
      "[40 - 800] Training Loss: 0.145\n",
      "[40 - 900] Training Loss: 0.117\n",
      "[40 - 1000] Training Loss: 0.137\n",
      "[40 - 1100] Training Loss: 0.113\n",
      "[40 - 1200] Training Loss: 0.135\n",
      "[40 - 1300] Training Loss: 0.146\n",
      "[40 - 1400] Training Loss: 0.151\n",
      "[40 - 1500] Training Loss: 0.142\n",
      "Epoch 40 - Validation Loss: 168.236, Validation Accuracy: 85.78%\n",
      "[41 - 100] Training Loss: 0.109\n",
      "[41 - 200] Training Loss: 0.115\n",
      "[41 - 300] Training Loss: 0.107\n",
      "[41 - 400] Training Loss: 0.129\n",
      "[41 - 500] Training Loss: 0.136\n",
      "[41 - 600] Training Loss: 0.134\n",
      "[41 - 700] Training Loss: 0.113\n",
      "[41 - 800] Training Loss: 0.123\n",
      "[41 - 900] Training Loss: 0.114\n",
      "[41 - 1000] Training Loss: 0.129\n",
      "[41 - 1100] Training Loss: 0.136\n",
      "[41 - 1200] Training Loss: 0.140\n",
      "[41 - 1300] Training Loss: 0.142\n",
      "[41 - 1400] Training Loss: 0.145\n",
      "[41 - 1500] Training Loss: 0.133\n",
      "Epoch 41 - Validation Loss: 155.924, Validation Accuracy: 86.52%\n",
      "[42 - 100] Training Loss: 0.104\n",
      "[42 - 200] Training Loss: 0.099\n",
      "[42 - 300] Training Loss: 0.122\n",
      "[42 - 400] Training Loss: 0.122\n",
      "[42 - 500] Training Loss: 0.129\n",
      "[42 - 600] Training Loss: 0.113\n",
      "[42 - 700] Training Loss: 0.126\n",
      "[42 - 800] Training Loss: 0.147\n",
      "[42 - 900] Training Loss: 0.122\n",
      "[42 - 1000] Training Loss: 0.128\n",
      "[42 - 1100] Training Loss: 0.101\n",
      "[42 - 1200] Training Loss: 0.117\n",
      "[42 - 1300] Training Loss: 0.131\n",
      "[42 - 1400] Training Loss: 0.139\n",
      "[42 - 1500] Training Loss: 0.114\n",
      "Epoch 42 - Validation Loss: 157.364, Validation Accuracy: 86.81%\n",
      "[43 - 100] Training Loss: 0.119\n",
      "[43 - 200] Training Loss: 0.118\n",
      "[43 - 300] Training Loss: 0.123\n",
      "[43 - 400] Training Loss: 0.110\n",
      "[43 - 500] Training Loss: 0.120\n",
      "[43 - 600] Training Loss: 0.110\n",
      "[43 - 700] Training Loss: 0.118\n",
      "[43 - 800] Training Loss: 0.129\n",
      "[43 - 900] Training Loss: 0.140\n",
      "[43 - 1000] Training Loss: 0.122\n",
      "[43 - 1100] Training Loss: 0.113\n",
      "[43 - 1200] Training Loss: 0.131\n",
      "[43 - 1300] Training Loss: 0.122\n",
      "[43 - 1400] Training Loss: 0.132\n",
      "[43 - 1500] Training Loss: 0.148\n",
      "Epoch 43 - Validation Loss: 165.385, Validation Accuracy: 86.63%\n",
      "[44 - 100] Training Loss: 0.101\n",
      "[44 - 200] Training Loss: 0.107\n",
      "[44 - 300] Training Loss: 0.100\n",
      "[44 - 400] Training Loss: 0.125\n",
      "[44 - 500] Training Loss: 0.102\n",
      "[44 - 600] Training Loss: 0.125\n",
      "[44 - 700] Training Loss: 0.126\n",
      "[44 - 800] Training Loss: 0.113\n",
      "[44 - 900] Training Loss: 0.128\n",
      "[44 - 1000] Training Loss: 0.132\n",
      "[44 - 1100] Training Loss: 0.107\n",
      "[44 - 1200] Training Loss: 0.118\n",
      "[44 - 1300] Training Loss: 0.118\n",
      "[44 - 1400] Training Loss: 0.132\n",
      "[44 - 1500] Training Loss: 0.125\n",
      "Epoch 44 - Validation Loss: 165.715, Validation Accuracy: 86.26%\n",
      "[45 - 100] Training Loss: 0.124\n",
      "[45 - 200] Training Loss: 0.101\n",
      "[45 - 300] Training Loss: 0.123\n",
      "[45 - 400] Training Loss: 0.115\n",
      "[45 - 500] Training Loss: 0.123\n",
      "[45 - 600] Training Loss: 0.130\n",
      "[45 - 700] Training Loss: 0.112\n",
      "[45 - 800] Training Loss: 0.126\n",
      "[45 - 900] Training Loss: 0.131\n",
      "[45 - 1000] Training Loss: 0.128\n",
      "[45 - 1100] Training Loss: 0.120\n",
      "[45 - 1200] Training Loss: 0.103\n",
      "[45 - 1300] Training Loss: 0.118\n",
      "[45 - 1400] Training Loss: 0.107\n",
      "[45 - 1500] Training Loss: 0.126\n",
      "Epoch 45 - Validation Loss: 160.442, Validation Accuracy: 86.35%\n",
      "[46 - 100] Training Loss: 0.082\n",
      "[46 - 200] Training Loss: 0.101\n",
      "[46 - 300] Training Loss: 0.114\n",
      "[46 - 400] Training Loss: 0.106\n",
      "[46 - 500] Training Loss: 0.112\n",
      "[46 - 600] Training Loss: 0.117\n",
      "[46 - 700] Training Loss: 0.113\n",
      "[46 - 800] Training Loss: 0.118\n",
      "[46 - 900] Training Loss: 0.110\n",
      "[46 - 1000] Training Loss: 0.118\n",
      "[46 - 1100] Training Loss: 0.119\n",
      "[46 - 1200] Training Loss: 0.117\n",
      "[46 - 1300] Training Loss: 0.108\n",
      "[46 - 1400] Training Loss: 0.121\n",
      "[46 - 1500] Training Loss: 0.115\n",
      "Epoch 46 - Validation Loss: 169.633, Validation Accuracy: 86.15%\n",
      "[47 - 100] Training Loss: 0.107\n",
      "[47 - 200] Training Loss: 0.116\n",
      "[47 - 300] Training Loss: 0.108\n",
      "[47 - 400] Training Loss: 0.112\n",
      "[47 - 500] Training Loss: 0.106\n",
      "[47 - 600] Training Loss: 0.133\n",
      "[47 - 700] Training Loss: 0.108\n",
      "[47 - 800] Training Loss: 0.121\n",
      "[47 - 900] Training Loss: 0.131\n",
      "[47 - 1000] Training Loss: 0.100\n",
      "[47 - 1100] Training Loss: 0.116\n",
      "[47 - 1200] Training Loss: 0.104\n",
      "[47 - 1300] Training Loss: 0.102\n",
      "[47 - 1400] Training Loss: 0.113\n",
      "[47 - 1500] Training Loss: 0.112\n",
      "Epoch 47 - Validation Loss: 164.637, Validation Accuracy: 85.95%\n",
      "[48 - 100] Training Loss: 0.108\n",
      "[48 - 200] Training Loss: 0.105\n",
      "[48 - 300] Training Loss: 0.097\n",
      "[48 - 400] Training Loss: 0.104\n",
      "[48 - 500] Training Loss: 0.104\n",
      "[48 - 600] Training Loss: 0.123\n",
      "[48 - 700] Training Loss: 0.110\n",
      "[48 - 800] Training Loss: 0.111\n",
      "[48 - 900] Training Loss: 0.110\n",
      "[48 - 1000] Training Loss: 0.125\n",
      "[48 - 1100] Training Loss: 0.101\n",
      "[48 - 1200] Training Loss: 0.106\n",
      "[48 - 1300] Training Loss: 0.093\n",
      "[48 - 1400] Training Loss: 0.102\n",
      "[48 - 1500] Training Loss: 0.118\n",
      "Epoch 48 - Validation Loss: 162.718, Validation Accuracy: 86.86%\n",
      "[49 - 100] Training Loss: 0.101\n",
      "[49 - 200] Training Loss: 0.098\n",
      "[49 - 300] Training Loss: 0.108\n",
      "[49 - 400] Training Loss: 0.106\n",
      "[49 - 500] Training Loss: 0.114\n",
      "[49 - 600] Training Loss: 0.107\n",
      "[49 - 700] Training Loss: 0.107\n",
      "[49 - 800] Training Loss: 0.112\n",
      "[49 - 900] Training Loss: 0.105\n",
      "[49 - 1000] Training Loss: 0.117\n",
      "[49 - 1100] Training Loss: 0.134\n",
      "[49 - 1200] Training Loss: 0.121\n",
      "[49 - 1300] Training Loss: 0.109\n",
      "[49 - 1400] Training Loss: 0.105\n",
      "[49 - 1500] Training Loss: 0.098\n",
      "Epoch 49 - Validation Loss: 163.673, Validation Accuracy: 86.68%\n",
      "[50 - 100] Training Loss: 0.091\n",
      "[50 - 200] Training Loss: 0.099\n",
      "[50 - 300] Training Loss: 0.093\n",
      "[50 - 400] Training Loss: 0.110\n",
      "[50 - 500] Training Loss: 0.105\n",
      "[50 - 600] Training Loss: 0.111\n",
      "[50 - 700] Training Loss: 0.093\n",
      "[50 - 800] Training Loss: 0.113\n",
      "[50 - 900] Training Loss: 0.108\n",
      "[50 - 1000] Training Loss: 0.113\n",
      "[50 - 1100] Training Loss: 0.093\n",
      "[50 - 1200] Training Loss: 0.110\n",
      "[50 - 1300] Training Loss: 0.109\n",
      "[50 - 1400] Training Loss: 0.112\n",
      "[50 - 1500] Training Loss: 0.100\n",
      "Epoch 50 - Validation Loss: 173.745, Validation Accuracy: 86.41%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 86.75%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Load the training, validation, and test datasets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Validation dataset and data loader\n",
    "valset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "class ComplexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = ComplexNet()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_loss_history = []\n",
    "train_accuracy_history = []\n",
    "val_loss_history = []\n",
    "val_accuracy_history = []\n",
    "\n",
    "for epoch in range(50):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1} - {i + 1}] Training Loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_loss_history.append(running_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    net.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            val_images, val_labels = data\n",
    "            val_outputs = net(val_images)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            val_running_loss += val_loss.item()\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    val_loss_history.append(val_running_loss)\n",
    "    val_accuracy_history.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - Validation Loss: {val_loss_history[-1]:.3f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Plot training and validation loss and accuracy curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy_history, label='Training Accuracy')\n",
    "plt.plot(val_accuracy_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Test the model on the test dataset for evaluation\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy : {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training known image classification models with CIFAR-10 data set and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a transform to preprocess the CIFAR-10 images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Loading CIFAR-10 data set\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "def train_model(model, trainloader, optimizer, criterion, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / (i + 1):.4f}\")\n",
    "\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "def evaluate_model(model):\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy : {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3060\n",
      "Epoch 2, Loss: 2.3034\n",
      "Epoch 3, Loss: 2.3033\n",
      "Model training finished\n",
      "Test Accuracy : 10.00%\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained AlexNet model\n",
    "model_alexnet = torchvision.models.alexnet(weights='DEFAULT')\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in CIFAR-10\n",
    "num_classes = 10\n",
    "model_alexnet.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_alexnet.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model using the training data set\n",
    "train_model(model_alexnet, trainloader, optimizer, criterion, num_epochs=3)\n",
    "\n",
    "# Test the model using the test data set\n",
    "evaluate_model(model_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3394\n",
      "Epoch 2, Loss: 0.8089\n",
      "Epoch 3, Loss: 0.6095\n",
      "Model training finished\n",
      "Test Accuracy : 79.78%\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet-18 model\n",
    "model_resnet18 = torchvision.models.resnet18()\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes in CIFAR-10\n",
    "num_classes = 10\n",
    "model_resnet18.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model using the training data set\n",
    "train_model(model_resnet18, trainloader, optimizer, criterion, num_epochs=3)\n",
    "\n",
    "# Test the model using the test data set\n",
    "evaluate_model(model_resnet18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
